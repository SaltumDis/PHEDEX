#!/usr/bin/env perl

##H Route files towards a set of destination nodes by assigning next
##H transfer hop assignments.
##H
##H This agent considers the file destinations for given set of nodes
##H and compares those with available replicas.  If the files have not
##H yet arrived at the destination, it finds the best available replica
##H and routes it toward the destination node, provided no existing
##H transfer assignment already exists.
##H
##H Usage:
##H   FileRouter
##H      -state DIRECTORY -node NAME -nodes PATTERN[,PATTERN...]
##H      -db FILE[:SECTION] [-wait SECS]
##H
##H -state     agent state directory
##H -node      the node where this agent runs
##H -nodes     comma-separated list of node name patterns to route for;
##H            pattern wildcards are '%' (any string) and '_' (any character)
##H -db        database connection configuration parameter file
##H -wait      time to wait in seconds between work scans

BEGIN {
  use strict; use warnings;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../../Toolkit/Common";
  unshift(@INC, $home);
}

######################################################################
use UtilsHelp;
my %args;
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-wait' && scalar @ARGV > 1)
    { shift (@ARGV); $args{WAITTIME} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-state' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DROPDIR} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-db' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBCONFIG} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-node' && scalar @ARGV > 1)
    { shift (@ARGV); $args{MYNODE} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-nodes' && scalar @ARGV > 1)
    { shift (@ARGV); push(@{$args{NODES}}, split(/,/, shift(@ARGV))); }
    elsif ($ARGV[0] eq '-h')
    { &usage(); }
    else
    { last; }
}

if (@ARGV || !$args{DROPDIR} || !$args{MYNODE} || !$args{NODES} || !$args{DBCONFIG})
{
    die "Insufficient parameters, use -h for help.\n";
}

(new FileRouter (%args))->process();

######################################################################
# Routines for this agent.
package FileRouter; use strict; use warnings; use base 'UtilsAgent';
use UtilsCommand;
use UtilsLogging;
use UtilsTiming;
use UtilsDB;

sub new
{
    my $proto = shift;
    my $class = ref($proto) || $proto;
    my $self = $class->SUPER::new(@_);
    my %params = (DBCONFIG => undef,		# Database configuration file
		  MYNODE => undef,		# My node name
		  NODES => [],			# Nodes to route for
		  INFINITY => 1000,		# Avoid replicas this far away
		  SUSPEND_ROUTING => 0,		# Internal cool-off
	  	  AGENTID => "Router");		# Identity for activity logs
    my %args = (@_);
    map { $self->{$_} = $args{$_} || $params{$_} } keys %params;
    bless $self, $class;
    return $self;
}

# Called by agent main routine before sleeping.  Pick up work
# assignments from the database here and pass them to slaves.
sub idle
{
    my ($self, @pending) = @_;
    my $dbh = undef;
    eval
    {
	# Connect to the database.
	$dbh = &connectToDatabase ($self) or die "failed to connect";

	# Route all files not yet at destination.
	my $start = 0;
	my $routes = undef;
	foreach my $nodepat (@{$self->{NODES}})
	{
	    my $nrouted = 0;
	    my $nincomplete = 0;
	    my $startnode = &mytimeofday ();
	    foreach my $file (@{$self->pendingFiles ($dbh, $nodepat)})
	    {
		# Read new routing table if necessary.  If the routing table
		# looks obsolete, bail out -- this will happen for instance if
		# the agents have been down and NodeRouter and FileRouter are
		# started simultaneously, and all routes will appear "old".
		my $now = &mytimeofday ();
		do { $routes = $self->currentRoutes ($dbh); $start = $now; }
		    if ($now - $start > 10*60);
		do { &logmsg ("$file->{DEST}: neighbour routes are down, waiting"
			      . " for node routing to restore links"); last }
	      	    if ! grep($_->{FROM} eq $file->{DEST}
			      && $_->{TO} eq $_->{GATEWAY}
			      && $_->{TIME} >= $now - 30*60,
			      map { values %$_ } values %$routes);

		++$nincomplete;
		++$nrouted if $self->routeNextHop ($dbh, $file, $routes);

		# If we've routed too many files, take a breather to avoid
		# getting the database too overloaded.
		do { $self->{SUSPEND_ROUTING} = &mytimeofday() + 120; last }
		    if $nrouted > 4000;
	    }

	    &logmsg ("$nodepat: considered $nincomplete destinations,"
		     . " $nrouted routes created in"
		     . " @{[sprintf '%.1f', &mytimeofday() - $startnode]} seconds")
	        if $nincomplete;
	
	    # If we suspended routing, bail out.
	    do { &logmsg ("$nodepat: routing suspended, taking a breather"); last }
		if ($self->{SUSPEND_ROUTING} > &mytimeofday());

	    $self->maybeStop();
	}

	# Clear SQL statement cache
	undef $self->{STMT_CACHE};
    };
    do { &alert ("database error: $@");
	 eval { $dbh->rollback() } if $dbh; } if $@;

    # Disconnect from the database
    &disconnectFromDatabase ($self, $dbh);

    # Check children are still running and then wait
    $self->nap ($self->{WAITTIME});
}

# Read routing table into memory.  This avoids having to go to the
# database each time around for each file.  Returns a hash table
# representing the routing information.
sub currentRoutes
{
    my ($self, $dbh) = @_;
    my $routes = {};
    my $stmt = &dbexec ($dbh, qq{
	select from_node, to_node, gateway, hops, timestamp from t_routing});
    while (my ($from, $to, $gw, $hops, $time) = $stmt->fetchrow ())
    {
	$routes->{$from}{$to} = {
	    FROM	=> $from,
	    TO		=> $to,
	    GATEWAY	=> $gw,
	    HOPS	=> $hops,
	    TIME	=> $time
    	};
    }
    return $routes;
}


# Determine which files destined for nodes matching PATTERN are not
# yet at the destination and thus still require routing.
sub pendingFiles
{
    my ($self, $dbh, $pattern) = @_;
    my $result = [];
    
    my @blocklist = ();
    my $bquery = $self->{STMT_CACHE}{BDEST} ||= &dbprep ($dbh, qq{
	select name, node from t_block_destination
	where completed is null and node like :pattern});
    my $fquery = $self->{STMT_CACHE}{FDEST} ||= &dbprep ($dbh, qq{
	select guid from t_file where inblock = :block});
    &dbbindexec ($bquery, ":pattern" => $pattern);
    while (my ($block, $dest) = $bquery->fetchrow())
    {
	my $info = undef;
	&dbbindexec ($fquery, ":block" => $block);
	while (my ($guid) = $fquery->fetchrow())
	{
	    push (@$result, { GUID => $guid, DEST => $dest });
	}
    }

    return $result;
}

# Check if we should try routing FILE.  Currently always returns true.
# To be amended to recall last routing decision (pending transfer edge)
# and to quickly check if that one is completed; there is no point in
# further routing until replicas and transfers change.  Routing data
# will be purged periodically to allow database to override.
sub shouldRouteFile
{
    my ($self, $dbh, $file) = @_;
    return 1;
}

# Route file to the next hop.
sub routeNextHop
{
    my ($self, $dbh, $file, $routes) = @_;
    my $guid = $file->{GUID};
    my $dest = $file->{DEST};
    my $now = &mytimeofday ();
    my $oldroute = $now - 15*60;
    my %transfers = ();
    my %replicas = ();

    # Do a quick check if we should be routing this file
    # return 0 if ! $self->shouldRouteFile ($dbh, $file);

    # Get statements we need
    my $tstmt = $self->{STMT_CACHE}{TS} ||= &dbprep ($dbh, qq{
	select to_node from t_transfer_state where guid = :guid});
    my $rstmt = $self->{STMT_CACHE}{RS} ||= &dbprep ($dbh, qq{
	select node from t_replica_state where guid = :guid});
    my $istmt = $self->{STMT_CACHE}{INS} ||= &dbprep ($dbh, qq{
	insert into t_transfer_state
	(timestamp, guid, to_node, to_state, to_timestamp,
	 from_node, from_state, from_timestamp)
	values (:now, :guid, :to_node, 0, :now, :from_node, 0, :now)});

    # Determine replicas and transfers for this file.  Note that the
    # order is significant here: transfers first, then replicas, due
    # to a race condition with FileDownload agent.  Download agents
    # create a new replica, then remove a transfer state.  It does
    # happen that the download transaction is committed in the split
    # moment between the two queries below, in which case it is very
    # important we get the information the "harmless" way around.
    # Namely, if we get transfers first then replicas, we may end up
    # with an extra transfer but do pick up the new replica, which is
    # harmless for us.  The other way around we may actually lose
    # both the replica (not yet created) and the transfer (already
    # deleted), and reschedule the transfer, causing a constraint
    # violation in FileDownload later on.  We don't want to do any
    # locking here that we can avoid to prevent performance impact.
    &dbbindexec ($tstmt, ":guid" => $guid);
    while (my ($node) = $tstmt->fetchrow()) {
	return 0 if $node eq $dest;
	$transfers{$node} = 1;
    }
    $tstmt->finish ();

    &dbbindexec ($rstmt, ":guid" => $guid);
    while (my ($node) = $rstmt->fetchrow()) {
	return 0 if $node eq $dest;
	$replicas{$node} = 1;
    }
    $rstmt->finish ();

    # Determine nearest replica
    my @best = sort { $a->{HOPS} <=> $b->{HOPS} }
    	       map { $routes->{$_}{$dest} }
    	       grep (exists $routes->{$_}{$dest},
		     keys %replicas);

    # Check the routes are valid
    while (@best)
    {
	my $route = shift (@best);

	# Done if there is an existing transfer already.
	return 0 if exists $transfers{$route->{GATEWAY}};

	# Ignore this one if the route is too old or infinite
	my $age = sprintf ('%.1f', $now - $route->{TIME});
	if ($route->{HOPS} >= $self->{INFINITY})
	{
	    &warn ("$dest $guid: best replica at $route->{FROM}"
		   . " ($route->{HOPS} away via $route->{GATEWAY})"
		   . " is on a dead route, route is $age seconds old")
	        if ! $self->{WARNINGS}{ROUTE}{$guid}{$dest}{$route->{FROM}}{$route->{GATEWAY}};
	    $self->{WARNINGS}{ROUTE}{$guid}{$dest}{$route->{FROM}}{$route->{GATEWAY}} = 1;
	    next;
    	}
	elsif ($route->{TIME} < $oldroute)
	{
	    &warn ("$dest $guid: best replica at $route->{FROM}"
		   . " ($route->{HOPS} hops away via $route->{GATEWAY})"
		   . " is unreachable, route is $age seconds old")
	        if ! $self->{WARNINGS}{ROUTE}{$guid}{$dest}{$route->{FROM}}{$route->{GATEWAY}};
	    $self->{WARNINGS}{ROUTE}{$guid}{$dest}{$route->{FROM}}{$route->{GATEWAY}} = 1;
	    next;
	}

	# Make sure no replica exists at destination
	if (exists $replicas{$route->{GATEWAY}})
	{
	    &warn ("$dest $guid: best replica at $route->{FROM}"
		   . " ($route->{HOPS} hops away via $route->{GATEWAY})"
		   . " is untransferrable, destination replica exists")
	        if ! $self->{WARNINGS}{ROUTE}{$guid}{$dest}{$route->{FROM}}{$route->{GATEWAY}};
	    $self->{WARNINGS}{ROUTE}{$guid}{$dest}{$route->{FROM}}{$route->{GATEWAY}} = 1;
	    next;
	}

	# OK, usable route
	&logmsg ("routing $guid to $dest from $route->{FROM} via $route->{GATEWAY}"
	         . " ($route->{HOPS} hops, $age seconds ago)");

	&dbbindexec ($istmt,
		     ":now" => $now,
		     ":guid" => $guid,
		     ":from_node" => $route->{FROM},
		     ":to_node" => $route->{GATEWAY});

	delete $self->{WARNINGS}{ROUTE}{$guid}{$dest};
	delete $self->{WARNINGS}{UNAVAILABLE}{$guid}{$dest};
	delete $self->{WARNINGS}{NO_ROUTE}{$guid}{$dest};
	$dbh->commit ();
	return 1;
    }

    # Oops, something went wrong.  Diagnose.
    if (! keys %replicas)
    {
	&alert ("$dest $guid: no source replica available")
	    if ! $self->{WARNINGS}{UNAVAILABLE}{$guid}{$dest};
	$self->{WARNINGS}{UNAVAILABLE}{$guid}{$dest} = 1;
    }
    else
    {
	&alert ("$dest $guid: no replica routable to destination")
	    if ! $self->{WARNINGS}{NO_ROUTE}{$guid}{$dest};
	$self->{WARNINGS}{NO_ROUTE}{$guid}{$dest} = 1;
    }

    return 0;
}
