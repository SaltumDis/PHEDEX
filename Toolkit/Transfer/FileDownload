#!/usr/bin/perl

## This is an example transfer agent.
##
## This agent demonstrates how to write a parallel transfer agent.
## It monitors TMDB for files assigned to the agent, creates drop
## box tasks for them internally, and keeps a configurable number
## of transfers going on in parallel.
##
## In implementation, this is a combined drop box and database
## agent.  The TMDB monitoring is done in the &idle() routine,
## which is called whenever there is nothing to be done to the
## drops any more, which is most of the time.  The idle routine
## assigns files to idle workers.  Once the slave worker agent
## has completed the transfer, whether successfully or not, it
## moves the drop to the *inbox* of this agent, where this agent
## collects the status information and updates the database to
## reflect transfer progress.  In other words, the drops cycle
## from the idle routine into the inbox of a slave, to the work
## area of a slave, to inbox of the main agent, to its work area,
## and finally udpated back to the database and destroyed.  Never
## add data from outside this agent into its inbox!
##
## The copies this agent does are pure globus-url-copy operations
## for demonstration purpose.  This makes this agent fully capable
## LCG SE transfer agent.

BEGIN { use strict; use warnings; }
$me = $0; $me =~ s|.*/||;
$home = $0; $home =~ s|/[^/]+$||; $home ||= ".";
unshift(@INC, $home);

######################################################################
my %args = (WORKERPROG => "$home/FileDownloadSlave", NWORKERS => 1,
	    DBITYPE => "Oracle");
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-db' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBNAME} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-dbi' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBITYPE} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-dbuser' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBUSER} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-dbpass' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBPASS} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-node' && scalar @ARGV > 1)
    { shift (@ARGV); $args{MYNODE} = shift(@ARGV); }

    elsif ($ARGV[0] eq '-pfndest' && scalar @ARGV > 1)
    { shift (@ARGV); $args{PFNSCRIPT} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-wanted' && scalar @ARGV > 1)
    { shift (@ARGV); $args{WANT_LIMIT} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-worker' && scalar @ARGV > 1)
    { shift (@ARGV); $args{WORKERPROG} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-pass' && scalar @ARGV > 1)
    { shift (@ARGV); push (@{$args{WORKERARGS}},
		    	   map { s/\\,/,/g; $_ }
			   split (/(?<!\\),/, shift(@ARGV))); }
    elsif ($ARGV[0] eq '-state' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DROPDIR} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-wait' && scalar @ARGV > 1)
    { shift (@ARGV); $args{WAITTIME} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-workers' && scalar @ARGV > 1)
    { shift (@ARGV); $args{NWORKERS} = shift(@ARGV); }
    else
    { last; }
}
	
if ($args{WANT_LIMIT} && $args{WANT_LIMIT} =~ /^(\d+)([kMGT])$/)
{
    my %scale = ('k' => 1024, 'M' => 1024**2, 'G' => 1024**3, 'T' => 1024**4);
    $args{WANT_LIMIT} = $1 * $scale{$2};
}

if (scalar @ARGV || !$args{DROPDIR} || !$args{DBNAME} || !$args{DBUSER}
    || !$args{DBPASS} || !$args{DBITYPE} || !$args{MYNODE}
    || !$args{WANT_LIMIT} || !$args{PFNSCRIPT} || !$args{NWORKERS})
{
    print STDERR
	"usage: $me -state IN-DROP-BOX\n",
	"    -db NAME -dbuser USER -dbpass PASSWORD [-dbitype TYPE]\n",
	"    -node NODE-NAME -pfndest PROGRAM -wanted SIZE[kMGT]\n",
	"    [-worker WORKER-PROGRAM] [-pass OPTIONS,TO,WORKER]\n",
	"    [-wait SECS-TO-WAIT] [-workers NUM-WORKERS]\n";
    exit (1);
}

my $agent = new FileDownload (%args);
# Recapture interrupt signal, oracle swallows it.
$SIG{INT} = sub { system "touch $agent->{STOPFLAG}"; $agent->maybeStop (); };
$agent->process ();

######################################################################
# Routines specific to this agent.
package FileDownload; use strict; use warnings; use base 'UtilsAgent';
use File::Path;
use Data::Dumper;
use UtilsCommand;
use UtilsLogging;
use UtilsTiming;
use UtilsCatalogue;
use UtilsDB;

sub new
{
    my $proto = shift;
    my $class = ref($proto) || $proto;
    my $self = $class->SUPER::new(@_);
    my %params = (DBITYPE => undef,	# Database driver binding
    		  DBNAME => undef,	# Database name
	  	  DBUSER => undef,	# Database user name
	  	  DBPASS => undef,	# Database user password
	  	  MYNODE => undef,	# My TMDB node name
		  PFNSCRIPT => undef,	# Program to determine destination path
		  WANT_LIMIT => undef,	# Amount of data to prefetch
		  WORKERPROG => undef,	# Custom slave worker program
		  WORKERARGS => []);	# Custom options to workers
    my %args = (@_);
    map { $self->{$_} = $args{$_} || $params{$_} } keys %params;
    bless $self, $class;
    return $self;
}

# Start a worker
sub startWorker
{
    my ($self, $i) = @_;
    my $workerdir = "$self->{DROPDIR}/worker-$i";
    &mkpath ($workerdir) if ! -d $workerdir;

    my $pid = undef;
    while (1)
    {
	last if defined ($pid = fork ());
        &logmsg ("cannot fork: $!; trying again in 10 seconds");
	sleep (10);
    }

    # Return child pid in parent;
    return $pid if $pid;

    # Child.
    my @args = ($self->{WORKERPROG},
		"-in", $workerdir, "-out", $self->{DROPDIR}, "-wait", "7",
		@{$self->{WORKERARGS}});

    exec { $args[0] } @args;
    die "Cannot start worker: $!\n";
}

######################################################################
# A slave has finished with a transfer.  Complete the job by logging
# the status into the database, and if the transfer was successful,
# update the file state also.  Returns non-zero if the drop status
# for successfully entered into the database and the drop can be
# disposed.
sub completeOne
{
    my ($self, $drop, $report) = @_;

    # Dig out the report.  If transfer failed, revert the file back
    # to state 1 (allocated) and give it back the timestamp it was
    # originally posted to state 1 so logging will be accurate. Also
    # log the error message to our output.
    my $guid = $report->{GUID};
    my $from_node = $report->{FROM_NODE};
    my $to_node = $report->{TO_NODE};
    my $now = time();
    my $to_state = 3;
    my $dbh = undef;
    if ($report->{FAILURE})
    {
	&logmsg ("failed to transfer $guid: $report->{FAILURE}");
	$now = $report->{TIME_ALLOC};
	$to_state = 1;
    }

    eval
    {
	$dbh = &connectToDatabase ($self, 0);
	$dbh->do (qq{
	  update t_transfer_state
	  set to_state = $to_state, to_time_stamp = $now
	  where guid = '$guid'
	    and to_node = '$to_node'
	    and from_node = '$from_node'});

	$dbh->do (qq{
	  insert into t_replica_state values
	  ('$guid', '$to_node', 0, $now, 0, $now)})
	    if ! $report->{FAILURE};

	$dbh->commit ();
    };

    if ($@)
    {
	&alert ("failed to update $guid transferred: $@");
	$dbh->rollback() if $dbh;
	return 0;
    }

    # Disconnect from the database
    $dbh->disconnect if $dbh;
    undef $dbh;

    # Mark drop done so it will be nuked
    &touch ("$self->{WORKDIR}/$drop/done");

    # Log transfer delay stats
    $now = &mytimeofday ();
    my $dalloc = $now - $report->{TIME_ALLOC};
    my $dtransfer = $now - $report->{TIME_START};
    &logmsg ("xstats: $guid $to_node $to_state "
	     . sprintf('%.2f %.2f', $dalloc, $dtransfer));

    return 1;
}

# Actually process a drop.  Note that the only way we end up here is
# when a slave has finished with a file transfer and transfers it to
# our inbox.  Collect the transfer status and update the database to
# reflect the state.  Note that the slaves never mark drops bad, they
# just update the state information in the drop appropriately.  We
# only mark drops bad only if the drop itself is corrupted; normally
# we just flag transfers failed in the database and try again later.
# There is no downstream drop box agent, so the drops are destroyed
# once we've successfully entered the information into the database.
sub processDrop
{
    my ($self, $drop, $left) = @_;

    # Sanity checking
    return if (! $self->inspectDrop ($drop));
    delete $self->{BAD}{$drop};
    &timeStart($self->{STARTTIME});

    # Read back the state
    my $report = do { no strict "vars"; eval &input ("$self->{WORKDIR}/$drop/packet") };
    if ($@ || ! $report || ! $report->{GUID})
    {
	&alert ("corrupt packet in $drop");
	$self->markBad ($drop);
	return;
    }

    # Update database
    return if ! $self->completeOne ($drop, $report);

    # OK, got far enough to nuke and log it
    $self->relayDrop ($drop);
    &logmsg("stats: $drop @{[&formatElapsedTime($self->{STARTTIME})]} success");
}

######################################################################
# Begin transferring a file.  Fetches the file information and creates
# a new drop for the file in a worker.  If the drop is successfully
# created, marks the file in transfer in the database and returns
# non-zero.  Otherwise returns non-zero to indicate another attempt
# should be made at a later time to initiate the transfer.
sub startOne
{
    my ($self, $dbh,
	$guid, $timestamp, $from_node, $from_catalogue, $from_host,
	$to_catalogue, $attrs) = @_;

    # Get the PFN for the GUID and map it to destination PFN.
    # (FIXME: Can we not get these from TMDB?)
    my $from_pfn = &guidToPFN ($guid, $from_catalogue, $from_host);
    do { &alert ("failed to look up pfn for $guid"); return 0; } if ! $from_pfn;

    my $from_lfn = &guidToLFN ($guid, $from_catalogue);
    do { &alert ("failed to look up lfn for $guid"); return 0; } if ! $from_lfn;

    my $pfnargs = join(" ",
		   "guid=$guid", "pfn=$from_pfn", "lfn=$from_lfn",
		   map { "$_=$attrs->{$_}" } sort keys %$attrs);
    my $to_pfn = qx($self->{PFNSCRIPT} $pfnargs); chomp ($to_pfn);
    do { &alert ("no destination pfn for $guid"); return 0; } if ! $to_pfn;

    # Find an idle worker
    my $now = time();
    my $worker = $self->pickWorker();

    # Create a pending drop in the inbox of the selected worker
    my $slavein = "$self->{DROPDIR}/worker-$worker/inbox/$guid";
    do { &alert ("$slavein already exists"); return 0; } if -d $slavein;
    my $transfer = { GUID		=> $guid,
		     TIME_ALLOC		=> $timestamp,
		     TIME_START		=> &mytimeofday(),
		     FROM_NODE		=> $from_node,
		     FROM_PFN		=> $from_pfn,
		     FROM_LFN		=> $from_lfn,
		     FROM_CATALOGUE	=> $from_catalogue,
		     FROM_HOST		=> $from_host,
		     TO_NODE		=> $self->{MYNODE},
		     TO_PFN		=> $to_pfn,
		     TO_LFN		=> $from_lfn,
		     TO_CATALOGUE	=> $to_catalogue,
		     ATTRS		=> $attrs };

    do { &alert ("failed to create transfer packet for $guid"); &rmtree ($slavein); return 0; }
	if (! &mkpath ($slavein)
	    || ! &output ("$slavein/packet", Dumper ($transfer))
	    || ! &touch ("$slavein/go.pending"));

    # Mark the transfer started in the database.  Delete drop and
    # retry later on failure.
    eval
    {
	my $mynode = $self->{MYNODE};
	$dbh->do (qq{
	  update t_transfer_state
	  set to_state = 2, to_time_stamp = $now
	  where guid = '$guid'
	    and to_node = '$mynode'
	    and from_node = '$from_node'});
	$dbh->commit();
    };

    if ($@)
    {
	&alert ("failed to mark $guid in transfer: $@");
	&rmtree ($slavein);
	$dbh->rollback();
	return 0;
    }

    # OK, kick it go
    &warning ("could not kick $worker to start $guid")
	if ! &mv ("$slavein/go.pending", "$slavein/go");

    return 1;
}

# Update wanted status on files in the database.
sub markFilesWanted
{
    my ($self, $dbh) = @_;
    eval
    {
	my $mynode = $self->{MYNODE};

	# Keep wanted time stamp at most ten minutes old.
	my $now = time();
	my $old = $now - 600;
	$dbh->do(qq{
		update t_transfer_state
		set to_time_stamp = $now
		where to_node = '$mynode'
		  and to_state = 1
	  	  and to_time_stamp < $old});

  	# Check how much we already marked wanted.  Only mark new
	# files wanted if we drop below 75% of our limit.
	my $row = $dbh->selectrow_arrayref(qq{
		select sum(m.value)
		from t_transfer_state ts
		left join t_replica_metadata m
		  on ts.guid = m.guid and m.attribute = 'filesize'
		where ts.to_node = '$mynode' and ts.to_state = 1});
	return if (! defined $row || ($row->[0] || 0) > .75 * $self->{WANT_LIMIT});

	# Mark more files wanted.  Select the best new files, keeping
	# track of accumulated size and stopping at our limit.  The
	# ordering criteria here is decreasing day and the job-id
	# (FIXME: CMS/COBRA specific!).  We pick the newest files first
	# -- if we are moving files in streaming mode and fall behind,
	# it's better to keep up with the stream the best we can rather
	# than disrupt everyone else trying to slug our way through the
	# old files.  (FIXME: Custom file priority rules?)
	my $total = $row->[0] || 0;
	my $stmt = $dbh->prepare(qq{
		select ts.guid, m1.value
		from t_transfer_state ts
		left join t_replica_metadata m1
		  on ts.guid = m1.guid and m1.attribute = 'filesize'
		left join t_replica_metadata m2
		  on ts.guid = m2.guid and m2.attribute = 'POOL_jobid'
		where ts.to_node = '$mynode' and ts.to_state = 0
		order by trunc (ts.to_time_stamp/86400) desc, m2.value});
	$stmt->execute();
	while (my $file = $stmt->fetchrow_arrayref())
        {
	    my ($guid, $size) = @$file;

	    $total += $size;
	    last if ($total > $self->{WANT_LIMIT});

	    $dbh->do(qq{
		update t_transfer_state
		set to_state = 1, to_time_stamp = $now
		where guid = '$guid' and to_node = '$mynode'});
  	}

	$dbh->commit();
    };

    do { &alert ("failed to mark files wanted: $@"); $dbh->rollback() } if $@;
}

# Get the list of N guids that should be transferred next.  Returns
# a list of arrays with members GUID, ALLOC_TIMESTAMP, FROM_NODE,
# FROM_CATALOGUE, TO_CATALOGUE plus a hash of POOL file attributes.
sub nextFiles
{
    my ($self, $dbh, $n) = @_;

    # FIXME: sort by filegroup, descending time?
    # FIXME: also select files that have been in transfer for too long?
    my @result = ();
    eval
    {
	my $mynode = $self->{MYNODE};
	my $stmt = $dbh->prepare (qq{
		select ts.guid,
		       ts.from_time_stamp,
		       ts.from_node,
		       n1.catalogue_contact,
		       n1.host_string,
		       n2.catalogue_contact
		from t_transfer_state ts
		left join t_nodes n1
		  on n1.node_name = ts.from_node
		left join t_nodes n2
		  on n2.node_name = ts.to_node
		where ts.to_node = '$mynode'
		  and ts.to_state < 2
	  	  and ts.from_state = 1});
        $stmt->execute();
	while (my $row = $stmt->fetchrow_arrayref())
	{
	    last if ! $n--;
	    my $attrs = {};
	    foreach my $m (@{$dbh->selectall_arrayref(qq{
				select m.attribute, m.value
				from t_replica_metadata m
				where m.guid = '$row->[0]'
				  and m.attribute like 'POOL%'})})
	    {
		my ($key, $value) = @$m;
		$key =~ s/^POOL_//;
		$attrs->{$key} = $value;
	    }

	    push(@result, [ @$row, $attrs ]);
	}
    };
    &alert ("failed to select files for transfer: $@") if $@;
    return @result;
}

# Pick up files to download from the database
sub idle
{
    my ($self, @pending) = @_;
    if (my $dbh = &connectToDatabase ($self))
    {
        # FIXME: Pick up and process messages to me

        # Request some more files
        $self->markFilesWanted ($dbh);

        # Pump more files while there are idle workers.  Keep going
	# just a little more files than the number of workers to stay
	# ahead of worker wait times.
        my @files = ();
        my $ndone = 0;
        my $basedir = $self->{DROPDIR};
	my $maxload = scalar @{$self->{WORKERS}} * 4;
	my $maxfiles = scalar @{$self->{WORKERS}} * 10;
        while (scalar @{[<$basedir/worker-*/{inbox,work}/*>]} < $maxload)
        {
	    # Guarantee to collect results from slaves quickly enough
	    last if (++$ndone >= $maxfiles);

	    # Get more files if necessary
	    @files = $self->nextFiles ($dbh, $maxload) if ! @files;

	    # Create a drop for this file
	    last if ! @files || ! $self->startOne ($dbh, @{shift @files});
        }

        # Disconnect from the database
        $dbh->disconnect if $dbh;
        undef $dbh;
    }

    # Check children are still running and then wait
    $self->maybeStop ();
    $self->checkWorkers ();
    sleep ($self->{WAITTIME});
}
