#! /usr/bin/env perl

##H Recycle transferred files.  Never run on a production system!
##H
##H This agent removes previously transferred files to make space
##H for new ones.  It deletes anything older than a specified age,
##H plus more files if running out of disk space.  Use this in
##H an environment where you want to exercise the system.  Do not
##H use if you actually want to keep your files!
##H
##H Files are removed both from TMDB and the disk.
##H
##H Usage:
##H   FileRecycler
##H      -state DIRECTORY -node NAME -db FILE[:SECTION] [-log OUT]
##H      -storagemap PATH [-protocol NAME] [-keep PATTERN] [-delay HOURS]
##H	 [-check PROGRAM[,ARG...]] -rm PROGRAM[,ARG...]
##H
##H -state         agent state directory
##H -node          the node where this agent runs
##H -db            database connection configuration parameter file
##H -log           where to redirect logging information
##H -storagemap    storage mapping catalogue
##H -protocol      protocol to use with storage map, by default "direct"
##H -keep          file name pattern to not delete
##H -delay         hours to wait before deleting a replica (default: 48)
##H -check         script to check whether storage needs cleaning up
##H -rm            command to remove files

BEGIN
{
  use warnings; use strict; $^W=1;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../../Toolkit/Common";
  unshift(@INC, $home);
}

######################################################################
my %args;
use Getopt::Long;
use UtilsHelp;
&GetOptions ("state=s"		=> \$args{DROPDIR},
	     "log=s"		=> \$args{LOGFILE},
	     "db=s"		=> \$args{DBCONFIG},
	     "node=s"		=> \$args{MYNODE},
	     "storagemap=s"	=> \$args{STORAGEMAP},
	     "protocol=s"	=> \$args{PROTOCOL},
	     "keep=s"		=> sub { push(@{$args{KEEP}}, $_[1]) },
	     "delay=f"		=> sub { $args{DELAY} = $_[1] * 3600 },
	     "check=s"		=> sub { push(@{$args{CMD_CHECK}}, split(/,/, $_[1])) },
	     "rm=s"		=> sub { push(@{$args{CMD_RM}}, split(/,/, $_[1])) },
	     "help|h"		=> sub { &usage() });

if (@ARGV || !$args{MYNODE} || !$args{DROPDIR} || !$args{DBCONFIG}
    || !$args{STORAGEMAP} || !$args{CMD_RM})
{
    die "Insufficient parameters, use -h for help.\n";
}

(new FileRecycler (%args))->process();

################################################
package FileRecycler; use strict; use warnings; use base 'UtilsAgent';
use File::Path;
use UtilsCommand;
use UtilsLogging;
use UtilsTiming;
use UtilsCatalogue;
use UtilsDB;

sub new
{
    my $proto = shift;
    my $class = ref($proto) || $proto;
    my $self = $class->SUPER::new(@_);
    my %params = (DBCONFIG => undef,		# Database configuration file
	  	  MYNODE => undef,		# My TMDB node name
	  	  AGENTID => "FileCleaner",     # Identity for activity logs
		  WAITTIME => 50 + rand(10),	# Agent activity cycle
		  DELETING => undef,		# Are we deleting files now?
		  DELAY => 48 * 3600,		# Time delay prior to purging
		  STORAGEMAP => undef,		# Storage path mapping rules
		  PROTOCOL => "direct",         # File access protocol
		  KEEP => [],                   # File patterns to not delete
		  CMD_CHECK => undef,           # Command to check for free space
		  CMD_RM => undef);             # Command to remove files

    my %args = (@_);
    map { $$self{$_} = $args{$_} || $params{$_} } keys %params;
    bless $self, $class;
    return $self;
}

# Delete a file.  We are not too sensitive about the exit codes here, this
# should really just work, and the files may get deleted for other reasons
# by site admins so it's unwise to error out here.
sub deleteFile
{
    my ($self, $dbh, $fileid, $pfn) = @_;
    my $status;

    # Remove outbound transfers.  We just lost the file...
    &dbexec ($dbh, qq{
	delete from t_xfer_state where fileid = :fileid and from_node = :node},
	":fileid" => $fileid, ":node" => $$self{ID_MYNODE});

    # Remove replica
    &dbexec ($dbh, qq{
	delete from t_xfer_replica where fileid = :fileid and node = :node},
	":fileid" => $fileid, ":node" => $$self{ID_MYNODE});

    # Remove from the disk
    ($status = &runcmd (@{$$self{CMD_RM}}, $pfn))
	and &warn ("exit code @{[&runerror($status)]} from @{$$self{CMD_RM}} $pfn");
}

# Pick up work from the database.
sub idle
{
    my ($self, @pending) = @_;
    my $dbh = undef;

    eval
    {
	$dbh = &connectToDatabase ($self);

	# Check if the site wants to release some disk space.  If we
	# have no script to check, we always delete files.
	if ($$self{CMD_CHECK} && @{$$self{CMD_CHECK}})
	{
	    if ($$self{DELETING} && ! &runcmd (@{$$self{CMD_CHECK}}, "min-free"))
	    {
	        undef $$self{DELETING};
	    }
	    elsif (! $$self{DELETING} && &runcmd (@{$$self{CMD_CHECK}}, "max-fill"))
            {
	        $$self{DELETING} = 1;
	    }
	    return if ! $$self{DELETING};
	}

	# Start a sweep cycle.  Find files good to be deleted. This is
	# everything existing at this node longer than DELAY_PURGE, or
	# if $diskfull, a bunch of files from oldest first.  We delete
	# files at this node even for those with pending outbound
	# transfers because this is test disk space recycling -- the
	# main difference between this and the normal disk cleaner.
	my $now = &mytimeofday();
	my $old = $now - $$self{DELAY};
        my $q = &dbexec($dbh,qq{
	    select xr.fileid, f.logical_name, xr.time_create
	    from t_xfer_replica xr
	      join t_xfer_file f on f.id = xr.fileid
            where xr.node = :mynode
	      and not exists (select 1 from t_xfer_state xs
                              where xs.from_replica = xr.id
			        and xs.to_state = 2)
            order by xr.time_create asc},
    	    ":mynode" => $$self{ID_MYNODE});
        while (my ($id, $lfn, $time) = $q->fetchrow())
        {
	    next if grep($lfn =~ /$_/, @{$$self{KEEP}});
	    last if $time > $old && ! $$self{DELETING};
	    my $pfn = &pfnLookup ($lfn, $$self{PROTOCOL}, $$self{MYNODE},
				  $$self{STORAGEMAP});
	    do { &alert ("no pfn for $lfn"); next } if ! $pfn;
	    $self->deleteFile ($dbh, $id, $pfn);
	    $dbh->commit();
	    last if &mytimeofday() - $now > 600;
        }

	# Done, commit
	$dbh->commit ();
    };

    do { chomp ($@); &alert ("database error: $@");
	 eval { $dbh->rollback() } if $dbh } if $@;

    # Disconnect from the database
    &disconnectFromDatabase ($self, $dbh);

    # Have a little nap
    $self->nap ($$self{WAITTIME});
}

1;
