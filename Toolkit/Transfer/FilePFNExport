#!/usr/bin/env perl

##H Produce transfer file names (TURLs) for exported files.
##H
##H This agent generates the export file name for outbound file
##H transfers.  It monitors the database for wanted or staged
##H files that do not yet have a transfer name, and generates
##H one.
##H
##H A site-specific script is used to actually generate the
##H the file name.  The script is passed a list of GUIDs and
##H is expected to produce a list of "GUID PFN" lines.  A
##H number of such query jobs can be executed in parallel.
##H The arguments passed to the command are described in more
##H detail in the manual.
##H
##H Usage:
##H   FilePFNExport
##H      -state DIRECTORY -node NAME -db FILE[:SECTION]
##H      [-ignore NODE[,NODE...]] [-accept NODE[,NODE...]]
##H      -pfnquery CMD[,ARGS...] -protocols PROTO[,PROTO...]
##H
##H -state     agent state directory
##H -node      the node where this agent runs
##H -db        database connection configuration parameter file
##H -ignore    comma-separated list of nodes to ignore transfers from
##H -accept    comma-separated list of nodes to accept transfers from
##H -pfnquery  the command for querying export names
##H -protocols comma-separated list of protocols to accept

BEGIN {
  use strict; use warnings; $^W=1;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../../Toolkit/Common";
  unshift(@INC, $home);
}

######################################################################
use UtilsHelp;
my %args = (NJOBS => 20, WAITTIME => 50 + rand(20), TIMEOUT => 600);
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-state' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DROPDIR} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-db' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBCONFIG} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-node' && scalar @ARGV > 1)
    { shift (@ARGV); $args{MYNODE} = shift(@ARGV); }

    elsif ($ARGV[0] eq '-ignore' && scalar @ARGV > 1)
    { shift (@ARGV); push (@{$args{IGNORE_NODES}}, split(/,/, shift (@ARGV))); }
    elsif ($ARGV[0] eq '-accept' && scalar @ARGV > 1)
    { shift (@ARGV); push (@{$args{ACCEPT_NODES}}, split(/,/, shift (@ARGV))); }
    elsif ($ARGV[0] eq '-pfnquery' && scalar @ARGV > 1)
    { shift (@ARGV); @{$args{PFN_QUERY}} = split(/,/, shift(@ARGV)); }
    elsif ($ARGV[0] eq '-protocols' && scalar @ARGV > 1)
    { shift (@ARGV); @{$args{PROTOCOLS}} = split(/,/, shift(@ARGV)); }
    elsif ($ARGV[0] eq '-h')
    { &usage(); }
    else
    { last; }
}

if (@ARGV || !$args{DROPDIR} || !$args{MYNODE} || !$args{DBCONFIG}
    || !$args{PFN_QUERY} || !$args{NJOBS} || !$args{PROTOCOLS})
{
    die "Insufficient parameters, use -h for help.\n";
}

(new FilePFNExport (%args))->process();

######################################################################
# Routines specific to this agent.
package FilePFNExport; use strict; use warnings; use base 'UtilsAgent';
use UtilsCommand;
use UtilsLogging;
use UtilsTiming;
use UtilsDB;

sub new
{
    my $proto = shift;
    my $class = ref($proto) || $proto;
    my $self = $class->SUPER::new(@_);
    my %params = (DBCONFIG => undef,		# Database configuration file
	  	  MYNODE => undef,		# My TMDB node name
	  	  IGNORE_NODES => [],		# TMDB nodes to ignore
	  	  ACCEPT_NODES => [],		# TMDB nodes to accept
		  PFN_QUERY => undef,		# PFN query script
		  PROTOCOLS => undef);		# Protocols to accept
    my %args = (@_);
    map { $$self{$_} = $args{$_} || $params{$_} } keys %params;
    bless $self, $class;
    return $self;
}

######################################################################
# Collect result from site query script glue
sub reapPFNs
{
    my ($self, $dbh, $files, $lfnfile, $outfile, $start, $job) = @_;
    my $output = &input ($outfile);
    unlink ($outfile);
    unlink ($lfnfile);

    my %lfn2pfn = map { split(/\s+/, $_) } split('\n', $output || '');
    foreach my $file (@$files)
    {
	my $to = $$file{TO_NODE};
	my $proto = $$file{PROTOCOL};
	my $lfn = $$file{LOGICAL_NAME};
	my $pfn = $lfn2pfn{$lfn};
	if (! $pfn)
	{
	    # Whine for lack of output, and put to cool as penalty.
	    &warn ("no turl for $lfn to $to with $proto (exit code $$job{STATUS})");
	    $$self{BACKOFF}{$lfn}{$to} = &mytimeofday() + 1200*(1 + rand(2));
	    next;
	}

	&dbexec($dbh, qq{
	    update t_xfer_state
	    set from_pfn = :pfn
	    where fileid = :fileid
      	      and to_node = :toid
      	      and from_pfn is null},
      	    ":pfn" => $pfn,
	    ":fileid" => $$file{FILEID},
	    ":toid" => $$file{TO_NODE_ID});
        $dbh->commit();
	&logmsg ("xstats: $$self{MYNODE} $to $proto "
		 . sprintf('%.2fs', &mytimeofday() - $start)
		 . " $lfn $pfn");
    }
}

# Pick up files that need PFN from database
sub idle
{
    my ($self, @pending) = @_;
    my $dbh = undef;
    eval
    {
    	$dbh = &connectToDatabase ($self) or die "failed to connect";
	$$dbh{FetchHashKeyName} = "NAME_uc";

	# If there are no pending jobs, delete old temp files.
	if (! @{$$self{JOBS}})
	{
	    my $tmpdir = $$self{WORKDIR};
	    unlink <$tmpdir/*.turl>, <$tmpdir/*.lfns>;
        }

	# Create jobs for computing TURLs for files.
	my $now = &mytimeofday();
	my $query = &dbexec($dbh,qq{
	    select
	      xr.fileid, f.logical_name, xs.to_node to_node_id,
	      nd.name to_node, xs.to_protocols
	    from t_xfer_replica xr
	      join t_file f
	        on f.id = xr.fileid
	      join t_xfer_state xs
	        on xs.from_replica = xr.id
	      join t_node nd
	        on nd.id = xs.to_node
	    where xr.node = :node
      	      and xs.errors < 5
	      and xs.time_request >= :old
	      and xs.time_expire > :now
      	      and xs.to_protocols is not null
      	      and xs.from_pfn is null},
            ":node" => $$self{ID_MYNODE}, ":now" => $now, ":old" => $now - 15*60);

    	my ($n, %todo) = 0;
	my %myprotos = map { $_ => 1 } @{$$self{PROTOCOLS}};
        while (my $file = $query->fetchrow_hashref())
	{
	    my $lfn = $$file{LOGICAL_NAME};
	    my $to = $$file{TO_NODE};
	    my $protos = $$file{TO_PROTOCOLS};

	    # Process only if not filtered.
	    next if grep($_ eq $to, @{$$self{IGNORE_NODES}});
	    next if (@{$$self{ACCEPT_NODES}}
		     && ! grep ($_ eq $to, @{$$self{ACCEPT_NODES}}));

	    # If we failed to generate TURL or determine protocol for
	    # this file recently, ignore it until back-off time passes.
	    next if ($$self{BACKOFF}{$lfn}{$to} || $now-1) > $now;
	    delete $$self{BACKOFF}{$lfn}{$to};

	    # Determine which protocl we can use
	    my $proto = (grep(exists $myprotos{$_}, split(/,/, $protos)))[0];
	    if (! defined $proto)
	    {
		&alert ("$lfn: no available protocol for destination $to"
		        . " (available protocols:"
			. " $$self{MYNODE}=" . join(',', @{$$self{PROTOCOLS}})
			. " vs. $to=$protos)");
	    	$$self{BACKOFF}{$lfn}{$to} = $now + 1200*(1 + rand(2));
		next;
	    }

	    # Record as something we need to do
	    $$file{PROTOCOL} = $proto;
	    push (@{$todo{$to}{$proto}}, $file);

	    # Give up if we are picking too much work
	    last if ++$n >= 5000;
	}

	# Now process all the jobs.  For each destination and protocol,
	# start batches of subprocesses to query the file paths.  The
	# site glue script is handed the protocol, node and file list.
	foreach my $to (sort keys %todo)
	{
	    foreach my $proto (sort keys %{$todo{$to}})
	    {
		my $files = $todo{$to}{$proto};
		my $lfnfile = "$$self{WORKDIR}/$to.$proto.lfns";
	        my $outfile = "$$self{WORKDIR}/$to.$proto.turl";
		&output ($lfnfile, join("", map { "$$_{LOGICAL_NAME}\n" } @$files));
	        $self->addJob (
		    sub { $self->reapPFNs ($dbh, $files, $lfnfile, $outfile, $now, @_) },
		    {}, "sh", "-c", "@{$$self{PFN_QUERY}} -g -r $lfnfile $proto $to > $outfile");

	    	# Keep old jobs running while we are generating new jobs.
	    	$self->maybeStop ();
	    	$self->pumpJobs ();
	   }
        }

	# Wait till all jobs exit
	while (@{$$self{JOBS}})
	{
	    $self->maybeStop ();
	    $self->pumpJobs ();
	    select (undef, undef, undef, .1);
	}
    };
    do { chomp ($@); &alert ("database error: $@");
	 eval { $dbh->rollback() } if $dbh; } if $@;

    # Disconnect from the database
    &disconnectFromDatabase ($self, $dbh);

    # Have a little nap
    $self->nap ($$self{WAITTIME});
}
