#!/usr/bin/env perl

##H Produce transfer file names (TURLs) for exported files.
##H
##H This agent generates the export file name for outbound file
##H transfers.  It monitors the database for wanted or staged
##H files that do not yet have a transfer name, and generates
##H one.
##H
##H A site-specific script is used to actually generate the
##H the file name.  The script is passed a list of GUIDs and
##H is expected to produce a list of "GUID PFN" lines.  A
##H number of such query jobs can be executed in parallel.
##H The arguments passed to the command are described in more
##H detail in the manual.
##H
##H Usage:
##H   FilePFNExport
##H      -state DIRECTORY -node NAME -dbconfig FILE [-wait SECS]
##H      -pfnquery CMD[,ARGS...] [-jobs NJOBS] [-timeout SECS]
##H      [-ignore NODE[,NODE...]] [-accept NODE[,NODE...]]
##H
##H -state     agent state directory
##H -node      the node where this agent runs
##H -dbconfig  database connection configuration parameter file
##H -wait      time to wait in seconds between work scans
##H -pfnquery  the command for querying export names
##H -jobs      number of parallel -pfnquery jobs to execute (default: 20)
##H -timeout   time after which to terminate -pfnquery jobs (default: never)
##H -ignore    comma-separated list of nodes to ignore transfers from
##H -accept    comma-separated list of nodes to accept transfers from

BEGIN {
  use strict; use warnings;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../../Toolkit/Common";
  unshift(@INC, $home);
}

######################################################################
use UtilsHelp;
my %args = (NJOBS => 20);
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-dbconfig' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBCONFIG} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-node' && scalar @ARGV > 1)
    { shift (@ARGV); $args{MYNODE} = shift(@ARGV); }

    elsif ($ARGV[0] eq '-jobs' && scalar @ARGV > 1)
    { shift (@ARGV); $args{NJOBS} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-timeout' && scalar @ARGV > 1)
    { shift (@ARGV); $args{TIMEOUT} = shift (@ARGV); }
    elsif ($ARGV[0] eq '-state' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DROPDIR} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-wait' && scalar @ARGV > 1)
    { shift (@ARGV); $args{WAITTIME} = shift(@ARGV); }

    elsif ($ARGV[0] eq '-pfnquery' && scalar @ARGV > 1)
    { shift (@ARGV); @{$args{PFN_QUERY}} = split(/,/, shift(@ARGV)); }
    elsif ($ARGV[0] eq '-ignore' && scalar @ARGV > 1)
    { shift (@ARGV); push (@{$args{IGNORE_NODES}}, split(/,/, shift (@ARGV))); }
    elsif ($ARGV[0] eq '-accept' && scalar @ARGV > 1)
    { shift (@ARGV); push (@{$args{ACCEPT_NODES}}, split(/,/, shift (@ARGV))); }
    elsif ($ARGV[0] eq '-h')
    { &usage(); }
    else
    { last; }
}

if (@ARGV || !$args{DROPDIR} || !$args{MYNODE} || !$args{DBCONFIG}
    || !$args{PFN_QUERY} || !$args{NJOBS})
{
    die "Insufficient parameters, use -h for help.\n";
}

my $agent = new FilePFNExport (%args);
# Recapture interrupt signal, oracle swallows it.
$SIG{INT} = sub { system "touch $agent->{STOPFLAG}"; $agent->maybeStop (); };
$agent->process ();

######################################################################
# Routines specific to this agent.
package FilePFNExport; use strict; use warnings; use base 'UtilsAgent';
use File::Path;
use UtilsCommand;
use UtilsLogging;
use UtilsTiming;
use UtilsDB;

sub new
{
    my $proto = shift;
    my $class = ref($proto) || $proto;
    my $self = $class->SUPER::new(@_);
    my %params = (DBCONFIG => undef,		# Database configuration file
	  	  MYNODE => undef,		# My TMDB node name
	  	  IGNORE_NODES => [],		# TMDB nodes to ignore
	  	  ACCEPT_NODES => [],		# TMDB nodes to accept
		  PFN_QUERY => undef,		# PFN query script
	  	  AGENTID => "PFNExport");	# Identity for activity logs
    my %args = (@_);
    map { $self->{$_} = $args{$_} || $params{$_} } keys %params;
    bless $self, $class;
    return $self;
}

######################################################################
# Collect result from site query script glue
sub reapPFNs
{
    my ($self, $dbh, $guids, $to, $proto, $output, $start, $job) = @_;
    my %guid2pfn = map { split(/\s+/, $_) } split('\n', &input ($output) || '');
    unlink ($output);

    foreach my $guid (@$guids)
    {
	my $pfn = $guid2pfn{$guid};
	if (! $pfn)
	{
	    # No output for this guid.  Whine.  Assign back-off time as a penalty.
	    &warn ("no turl for $guid to $to with $proto (exit code $job->{STATUS})");
	    $self->{BACKOFF}{$guid}{$to} = &mytimeofday() + 3600*(4 + rand(2));
	    next;
	}

	&dbexec($dbh, qq{
	    update t_transfer_state
	    set from_pfn = :pfn
	    where guid = :guid
      	      and to_node = :tonode
	      and from_node = :mynode
      	      and from_pfn is null},
      	    ":pfn" => $pfn,
	    ":guid" => $guid,
	    ":mynode" => $self->{MYNODE},
	    ":tonode" => $to);
        $dbh->commit();
	&logmsg ("xstats: $guid $self->{MYNODE} $to "
		 . sprintf('%.2f', &mytimeofday() - $start)
		 . " $pfn");
    }
}

# Pick up files that need PFN from database
sub idle
{
    my ($self, @pending) = @_;
    my $dbh = undef;
    eval
    {
    	$dbh = &connectToDatabase ($self) or die "failed to connect";
        # FIXME: Pick up and process messages to me

	# If there are no pending jobs, delete old temp files.
	if (! @{$self->{JOBS}})
	{
	    my $tmpdir = $self->{WORKDIR};
	    unlink <$tmpdir/*.turl>;
        }

	# Create jobs for computing TURLs for files.
	my %protos = ();
	my $nfiles = 0;
	my $now = &mytimeofday();

	my $query = &dbexec($dbh,qq{
	    select ts.guid, ts.to_node
	    from t_transfer_state ts
	    left join t_replica_state rs
	      on rs.guid = ts.guid
	     and rs.node = ts.from_node
	    where ((ts.to_state = 1
      	            and ts.to_timestamp > :old)
		   or rs.state = 1)
	      and ts.from_node = :node
	      and ts.from_pfn is null},
      	    ":node" => $self->{MYNODE},
	    ":old" => $now - 15*60);

        my $pquery = &dbprep($dbh,qq{
	    select i.protocol
	    from t_node_import i, t_node_export e
	    where e.protocol = i.protocol
	      and e.node = :exportnode
	      and i.node = :importnode
	    order by i.priority asc});

        my %todo = ();
        while (my ($guid, $to) = $query->fetchrow())
	{
	    # Process only if not filtered.
	    next if grep($_ eq $to, @{$self->{IGNORE_NODES}});
	    next if (@{$self->{ACCEPT_NODES}}
		     && ! grep ($_ eq $to, @{$self->{ACCEPT_NODES}}));

	    # If we failed to generate TURL or determine protocol for
	    # this file recently, ignore it until back-off time passes.
	    next if ($self->{BACKOFF}{$guid}{$to} || $now) > $now;

	    # Use cached protocol for $to, or cache one now.  We get
	    # the first compatible protocol, sorted by importer's
	    # priority order, as the download protocol.
	    if (! defined $protos{$to})
	    {
		&dbbindexec($pquery,
			    ":exportnode" => $self->{MYNODE},
			    ":importnode" => $to);
		$protos{$to} = ($pquery->fetchrow())[0];
	    }

	    # If there is no protocol compatible with me and $to, warn
	    # about this guid and punish with back-off time.
	    if (! defined $protos{$to})
	    {
		&alert ("$guid: no protocol matches $self->{MYNODE} and $to");
	    	$self->{BACKOFF}{$guid}{$to} = $now + 3600*(4 + rand(2));
		next;
	    }
	    delete $self->{BACKOFF}{$guid}{$to};

	    # Record as something we need to do
	    push (@{$todo{$to}{$protos{$to}}}, $guid);
	}

	# Now process all the jobs
	foreach my $to (sort keys %todo)
	{
	    foreach my $proto (sort keys %{$todo{$to}})
	    {
		my $guids = $todo{$to}{$proto};

		# Ok, start sub-processes to generate TURLs for the guids.
		# We do this in batches of many guids at a time.  The site
		# glue script gets from us the arguments protocol, node and
	        # a guid list.  Generally the script just queries the
		# catalogue and generates a gridftp name or alike.
		while (@$guids)
		{
		    my @batch = splice (@$guids, 0, 500);
	            my $output = "$self->{WORKDIR}/$batch[0].$to.turl";
	            $self->addJob (
			sub { $self->reapPFNs ($dbh, \@batch, $to, $proto, $output, $now, @_) },
		        {}, "sh", "-c", "@{$self->{PFN_QUERY}} -g $proto $to @batch > $output");

	    	    # Keep old jobs running while we are generating new jobs.
	    	    $self->maybeStop ();
	    	    $self->pumpJobs ();
		}
	    }
        }

	# Wait till all jobs exit
	while (@{$self->{JOBS}})
	{
	    $self->maybeStop ();
	    $self->pumpJobs ();
	    select (undef, undef, undef, .1);
	}
    };
    do { &alert ("database error: $@"); $dbh->rollback() if $dbh; } if $@;

    # Disconnect from the database
    &disconnectFromDatabase ($self, $dbh);

    # Have a little nap
    $self->nap ($self->{WAITTIME});
}
