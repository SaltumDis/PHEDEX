#! /usr/bin/env perl

##H Clear up files to make more download space in the storage.
##H
##H This agent is meant for sites with an MSS node for long term
##H storage plus an intermediate disk buffer buffer not shared with
##H the MSS for download imports and exports.  The agent periodically
##H checks wither the buffer reaches high-water mark in fullness, and
##H clears oldest files until the space drops below a low-water mark.
##H The maximum-fill high-water mark could be for example 90%, and the
##H minimum-free low-water mark could be for example 50%.
##H
##H The agent doesn't actually know anything about the storage, it
##H invokes an external site script with "min-free" or "max-fill" as
##H an argument, and takes non-zero exit code from the script as an
##H indication the condition is not met, and more files should be
##H deleteed.
##H
##H Files on buffer without outbound transfers are candidates for
##H clearing up.  Files are removed oldest first, first from the
##H TMDB replica table, then physically from disk.  File removal
##H may be a real removal, or simply ejection of the file from
##H stager disk but not permanently removed from tape.
##H
##H Usage:
##H   FileDiskCleaner
##H      -state DIRECTORY -node NAME -db FILE[:SECTION] [-log OUT]
##H      -storagemap FILE [-protocol NAME] -check COMMAND[,ARG...]
##H      -rm COMMAND[,ARG...]
##H
##H -state         agent state directory
##H -node          the node where this agent runs
##H -db            database connection configuration parameter file
##H -storagemap    storage mapping catalogue
##H -protocol      protocol to use with storage map, by default "direct"
##H -check         script to check whether storage needs cleaning up
##H -rm            command to remove files
##H -log           where to redirect logging information

# Example for clearing normal disk buffers:
#   FileDiskCleaner -node ... -db ... -log ... -storagemap ...
#     -check .../myscript -rm rm
#
#   myscript:
#     #!/usr/bin/perl
#     $pctused = (split(/\s+/, qx(df /da/path | tail -1)))[4];
#     $pctused =~ s/[^\d.]//g;
#     if ($ARGV[0] eq 'min-free') { exit (int($pctused) < 50 ? 0 : 1) }
#     if ($ARGV[0] eq 'max-fill') { exit (int($pctused) > 90 ? 0 : 1) }
#     exit(0);
#
# Example for clearing RFIO buffers:
#   FileDiskCleaner -node ... -db ... -log ... -storagemap ...
#     -check .../myscript -rm stageclr,-remove_from_hsm,-M
#     (or: -rm rfrm)
#
#   myscript:
#     #!/usr/bin/perl
#     $pctfree = (split(/\s+/, qx(stageqry -s | grep FREE | head -1)))[5];
#     $pctfree =~ s/[^\d.]//g;
#     if ($ARGV[0] eq 'min-free') { exit (int($pctfree) >= 50 ? 0 : 1) }
#     if ($ARGV[0] eq 'max-fill') { exit (int($pctfree) <= 10 ? 0 : 1) }
#     exit(0);
#
# Example for clearing SRM buffers:
#   FileDiskCleaner -node ... -db ... -log ... -storagemap ...
#     -protocol srm -check .../myscript -rm srm-advisory-delete
#
#   myscript:
#     #!/usr/bin/perl
#     $storage = "https://cmssrm.fnal.gov:8443/srm/infoProvider1_0.wsdl";
#     ($total, $used, $avail) = map { chomp; s/.*=\s*//; s/\s.*//; }
#       grep(/Space.*=/, qx(srm-storage-element-info $storage 2>&1));
#     $pctused = ($total ? 100.0 * $used/$total : 0);
#     if ($ARGV[0] eq 'min-free') { exit (int($pctused) < 50 ? 0 : 1) }
#     if ($ARGV[0] eq 'max-fill') { exit (int($pctused) > 90 ? 0 : 1) }
#     exit(0);

BEGIN
{
  use warnings; use strict; $^W=1;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../../Toolkit/Common";
  unshift(@INC, $home);
}


######################################################################
use Getopt::Long;
use UtilsHelp;

&GetOptions ("state=s"		=> \$args{DROPDIR},
	     "log=s"		=> \$args{LOGFILE},
	     "db=s"		=> \$args{DBCONFIG},
	     "node=s"		=> \$args{MYNODE},
	     "storagemap=s"	=> \$args{STORAGEMAP},
	     "protocol=s"	=> \$args{PROTOCOL},
	     "check=s"		=> sub { push(@{$args{CMD_CHECK}}, split(/,/, $_[1])) },
	     "rm=s"		=> sub { push(@{$args{CMD_RM}}, split(/,/, $_[1])) },
	     "help|h"		=> sub { &usage() });

if (@ARGV || !$args{MYNODE} || !$args{DROPDIR} || !$args{DBCONFIG}
    || !$args{STORAGEMAP} || !$args{CMD_CHECK} || !$args{CMD_RM})
{
    die "Insufficient parameters, use -h for help.\n";
}

(new FileDiskCleaner (%args))->process();

################################################
package FileDiskCleaner; use strict; use warnings; use base 'UtilsAgent';
use File::Path;
use Data::Dumper;
use UtilsCommand;
use UtilsLogging;
use UtilsTiming;
use UtilsCatalogue;
use UtilsDB;
use DBI;
use UtilsRFIO;

sub new
{
    my $proto = shift;
    my $class = ref($proto) || $proto;
    my $self = $class->SUPER::new(@_);
    my %params = (DBCONFIG => undef,		# Database configuration file
	  	  MYNODE => undef,		# My TMDB node name
		  WAITTIME => 120 + rand(20),	# Agent activity cycle
	  	  AGENTID => "FileCleaner",     # Identity for activity logs
		  DELETING => undef,		# Are we deleting files now?
		  STORAGEMAP => undef,		# Storage path mapping rules
		  PROTOCOL => "direct",         # File access protocol
		  CMD_CHECK => undef,           # Command to check for free space
		  CMD_RM => undef);             # Command to remove files

    my %args = (@_);
    map { $$self{$_} = $args{$_} || $params{$_} } keys %params;
    bless $self, $class;
    return $self;
}

# Delete a file.  We do one step at a time; if the step fails, we just
# tell the caller to come back here again at a more opportune time.
# The steps are ordered such that they are safe to execute several
# times if we have to give for one reason or another.
sub deleteOneFile
{
    my ($self, $drop, $file) = @_;
    my $dbh = undef;
    my $status = eval {
	$dbh = &connectToDatabase ($self, 0);
	
	# Make sure the file is still safe to delete.  More transfers
	# out might have been created for this file while we were not
	# minding this particular file (sleeping or deleting things).
	my ($npending) = &dbexec($dbh, qq{
	    select count(fileid) from t_xfer_state
	    where from_node = :node and fileid = :fileid},
	    ":node" => $$self{ID_MYNODE},
	    ":fileid" => $$file{FILEID})
    	    ->fetchrow();
	if ($npending)
	{
	    &warn ("not removing $$file{LFN}, $npending pending transfers");
	    return 1;
	}

	# Now delete the replica entry to avoid new transfer edges.
	&dbexec($dbh, qq{
	    delete from t_xfer_replica where fileid = :fileid and node = :node},
	    ":fileid" => $$file{FILEID}, ":node" => $$self{ID_MYNODE});
	$dbh->commit();

	# Remove file from disk now.
	if (my $rc = &runcmd (@{$$self{CMD_RM}}, $$file{PFN}))
	{
	    &warn ("failed to remove $$file{PFN}: exit code "
		   . &runerror($rc));
	    return 0;
        }

	# Job done!
	&logmsg ("removed file $$file{FILEID}, $$file{LFN} => $$file{PFN}");
	return 1;
    };

    do { chomp ($@); &alert ("database error: $@");
	 eval { $dbh->rollback() } if $dbh;
	 $status = 0 } if $@;
    
    # Disconnect from the database
    &disconnectFromDatabase ($self, $dbh);

    # Return status code to caller
    return $status;
}

sub processDrop
{
    my ($self, $drop) = @_;

    # Sanity checking
    return if (! $self->inspectDrop ($drop));
    delete $$self{BAD}{$drop};
    &timeStart($$self{STARTTIME});

    # Read back file information
    my $dropdir = "$$self{WORKDIR}/$drop";
    my $file = do { no strict "vars"; eval &input ("$dropdir/packet") };
    if ($@ || !$file || !$$file{FILEID} || !$$file{LFN} || !$$file{PFN} || !$$file{TIME_START})
    {
	&alert ("corrupt packet in $drop");
	$self->markBad ($drop);
	return;
    }

    # Try deleting this file.  If something fails, keep this drop as
    # is, we'll come back to it later.
    return if ! $self->deleteOneFile ($drop, $file);

    # Mark drop done so it will be nuked
    &touch ("$dropdir/done");

    # Log transfer delay stats
    my $dtransfer = &mytimeofday() - $$file{TIME_START};
    &logmsg ("xstats: $$self{MYNODE} " . sprintf('%.2fs', $dtransfer)
	     . " $$file{LFN} => $$file{PFN}");

    # OK, got far enough to nuke and log it
    $self->relayDrop ($drop);
    &logmsg("stats: $drop @{[&formatElapsedTime($$self{STARTTIME})]} success");
}

# Get a list of files to delete.
sub filesToDelete
{
    my ($self, $dbh, $limit) = @_;

    # Find all the files that we are allowed to delete: everything
    # transferred out of this node where the transfer is completed
    # (TableCleaner removed t_xfer_state entries).
    # We take the files oldest first.
    my @result;
    my %files = ();
    my $q = &dbexec($dbh,qq{
	select xr.fileid, f.logical_name
	from t_xfer_replica xr
	  join t_xfer_file f on f.id = xr.fileid
	  left join t_xfer_state xs on xs.from_replica = xr.id
	where node = :node and xs.fileid is null
	order by time_state asc},
        ":node" => $$self{ID_MYNODE});
    while (my ($id, $lfn) = $q->fetchrow())
    {
	$files{$lfn} = $id;
	last if scalar keys %files >= $limit;
    }

    # Now get PFNs for all those files.
    my $pfns = &pfnLookup ([ keys %files ], $$self{PROTOCOL},
	    		   "local", $$self{STORAGEMAP});
    while (my ($lfn, $pfn) = each %$pfns)
    {
	do { &alert ("no pfn for $lfn"); next } if ! $pfn;
	push (@result, { LFN => $lfn, PFN => $pfn, FILEID => $files{$lfn},
			 TIME_START => &mytimeofday() });
    }

    return @result;
}

# Create a drop for deleting a file.  We create a drop for ourselves,
# i.e. in our own inbox, and then process the file in "processDrop".
# This way we have a permanent record of where we are with deleting
# the file, in case we have to give up some operation for temporary
# failures.
sub startOne
{
    my ($self, $file) = @_;

    # Create a pending drop in my inbox
    my $drop = "$$self{DROPDIR}/inbox/$$file{FILEID}";
    do { &alert ("$drop already exists"); return 0; } if -d $drop;
    do { &alert ("failed to submit $$file{FILEID}"); &rmtree ($drop); return 0; }
	if (! &mkpath ($drop)
	    || ! &output ("$drop/packet", Dumper ($file))
	    || ! &touch ("$drop/go.pending"));

    # OK, kick it go
    &warn ("failed to mark $$file{FILEID} ready to go")
	if ! &mv ("$drop/go.pending", "$drop/go");

    return 1;
}

# Pick up work from the database.
sub idle
{
    my ($self, @pending) = @_;
    my $dbh = undef;

    eval
    {
	$dbh = &connectToDatabase ($self);

	# Check whether there's enough disk space.  If yes, bail out.
	if ($$self{DELETING} && ! &runcmd (@{$$self{CMD_CHECK}}, "min-free"))
	{
	    undef $$self{DELETING};
	}
	elsif (! $$self{DELETING} && &runcmd (@{$$self{CMD_CHECK}}, "max-fill"))
        {
	    $$self{DELETING} = 1;
	}

	return if ! $$self{DELETING};

	# Not enough space.  Get a list of victims to evict.
	&logmsg ("disk is full, starting to clear files");
	foreach my $file ($self->filesToDelete ($dbh, 100))
	{
	    # If we are already processing this file, ignore it
	    next if grep ($_ eq $$file{FILEID}, @pending);

	    # Otherwise initiate destruction and doom
	    $self->startOne ($file);
	}

	$dbh->commit();
    };
    do { chomp ($@); &alert ("database error: $@");
	 eval { $dbh->rollback() } if $dbh } if $@;

    # Disconnect from the database
    &disconnectFromDatabase ($self, $dbh);

    # Have a little nap
    $self->nap ($$self{WAITTIME});
}

1;
