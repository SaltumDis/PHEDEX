#!/usr/bin/env perl

##H Continually injects new files which are renamed from a previous injection
##H
##H Usage:
##H   LoadTestInjector -state DIRECTORY -node NAME -db FILE[:SECTION]
##H               [-once] [-log OUT]
##H
##H -state     agent state directory
##H -node      the node where this agent runs
##H -db        database connection configuration parameter file
##H -once      run the alogrithm once, then quit -- don't go into daemon mode
##H -log       where to redirect logging information

BEGIN {
  use strict; use warnings; $^W=1;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../../Toolkit/Common";
  unshift(@INC, $home);
}

######################################################################
my %args;
use Getopt::Long;
use POSIX;
use UtilsHelp;

&GetOptions ("state=s"     => \$args{DROPDIR},
	     "log=s"       => \$args{LOGFILE},
             "db=s"        => \$args{DBCONFIG},
             "node=s"      => \$args{MYNODE},
             "once"        => \$args{ONCE},
	     "help|h"      => sub { &usage() });

if (@ARGV || !$args{DROPDIR} || !$args{MYNODE} || !$args{DBCONFIG})
{
    die "Insufficient parameters, use -h for help.\n";
}

(new LoadTestInjector (%args))->process();

######################################################################
# Routines for this agent.
package LoadTestInjector; use strict; use warnings; use base 'UtilsAgent';
use UtilsLogging;
use UtilsTiming;
use UtilsDB;
use Data::Dumper;  # XXX

sub new
{
    my $proto = shift;
    my $class = ref($proto) || $proto;
    my $self = $class->SUPER::new(@_);
    my %params = (DBCONFIG => undef,		# Database configuration file
		  MYNODE => undef,		# My TMDB node
		  ONCE => 0,			# Quit after one run
		  WAITTIME => 60*20 );	        # Agent cycle time
    my %args = (@_);
    map { $$self{$_} = $args{$_} || $params{$_} } keys %params;
    bless $self, $class;
    return $self;
}

# Called by agent main routine before sleeping.  Do some work.
sub idle
{
    my ($self, @pending) = @_;
    
    &logmsg("starting injections");

    &connectToDatabase ($self);
	
    # Get the LoadTest parameters for every link
    my $qparam = &dbexec($$self{DBH}, qq{
	select lp.src_dataset, ds.name src_dataset_name,
	lp.dest_dataset, dd.name dest_dataset_name,
	lp.dest_node, dn.name dest_node_name,
	lp.is_active, lp.dataset_size, lp.dataset_close,
	lp.block_size, lp.block_close,
	lp.rate, lp.inject_now,
	lp.throttle_node, tn.name throttle_node_name,
	lp.time_inject
	    from t_loadtest_param lp
	    join t_dps_dataset ds on ds.id = lp.src_dataset
	    join t_dps_dataset dd on dd.id = lp.dest_dataset
	    join t_adm_node dn on dn.id = lp.dest_node
	    left join t_adm_node tn on tn.id = lp.throttle_node
	});
    
    my $uparam = &dbprep($$self{DBH}, qq{
       update t_loadtest_param set inject_now = 0, time_inject = :time_inject
        where src_dataset = :src_dataset
	  and dest_dataset = :dest_dataset
          and dest_node = :dest_node});
             
    my $total_inject = 0;
    while (my $params = $qparam->fetchrow_hashref()) {
	$$params{NOW} = &mytimeofday();
#	print "params:  ", Dumper($params), "\n"; # XXX

	next if $$params{IS_ACTIVE} eq 'n';
	next if $self->datasetFull($params);
	
	my $n_files = 0;
	if ($$params{INJECT_NOW}) {
	    $n_files = $$params{INJECT_NOW};
	} elsif ($$params{RATE}) {
	    my $t_files = $self->throttleNodeFiles($params);
	    $n_files = $self->calculateRateInjection($params);
	    next if $t_files >= $n_files; # Throttle node has enough to do
	} else {
	    next; # Nothing to do
	}
	
	# Transaction per dataset.  Rollback and continue in case of any errors
	eval
	{
#	    &logmsg("going to insert $n_files into $$params{DEST_DATASET_NAME}");  # XXX
	    my $n_inject = $self->injectFiles($params, $n_files);
	    if ($n_inject) {
		&dbbindexec($uparam, 
			    ':time_inject' => $$params{NOW},
			    ':src_dataset' => $$params{SRC_DATASET},
			    ':dest_dataset' => $$params{DEST_DATASET},
			    ':dest_node' => $$params{DEST_NODE}
			    );
#		&logmsg("committing"); # XXX
		$$self{DBH}->commit();
		&logmsg("injected $n_inject files to dataset ",
			"$$params{DEST_DATASET_NAME} at $$params{DEST_NODE_NAME}");
		$total_inject += $n_inject;
	    } else {
		$$self{DBH}->rollback();
		die "no files injected to dataset $$params{DEST_DATASET_NAME} at ",
		"$$params{DEST_NODE_NAME}, tried to inject $n_files\n";
	    }
	};
	if ($@) {
	    &alert($@);
	    $$self{DBH}->rollback();
	}
    }

    &logmsg("finished injections:  $total_inject files injected");

    # Disconnect from the database
    &disconnectFromDatabase ($self, $$self{DBH});

    # Have a nap.
    $self->doStop() if $$self{ONCE};
    $self->nap ($$self{WAITTIME});
}


sub datasetFull
{
    my ($self, $params) = @_;

    my $ds_size = defined $$params{DATASET_SIZE} ? $$params{DATASET_SIZE} : POSIX::FLT_MAX;

    my $info = &dbexec($$self{DBH}, qq{
	select ds.id, ds.is_open, count(b.id) n_blocks
          from t_dps_dataset ds
     left join t_dps_block b on b.dataset = ds.id
         where ds.id = :dataset
         group by ds.id, ds.is_open},
    ':dataset' => $$params{DEST_DATASET})->fetchrow_hashref();

    # Full if the dataset is closed or the number of blocks is more than the limit
    return 1 if ($$info{IS_OPEN} eq 'n' || $$info{N_BLOCKS} > $ds_size);
		       
    # If we are at the limit, we need to check if the last block is full
    if ($$info{N_BLOCKS} == $ds_size) {
	my $n = $self->lastBlockSpace($params);
	return 1 if (defined $n && $n == 0);
    }

    return 0;  # Dataset isn't full
}

sub getLastBlock
{
    my ($self, $params) = @_;

    # Query the last block, being careful only to get blocks with the LoadTest syntax
    # Also parses and returns the block number (e.g. /foo/bar/blah#123 is block number 123)
    my $info = &dbexec($$self{DBH}, q{
	select b.id, b.name, b.is_open, b.files, regexp_replace(b.name, '.*#(\d+)$', '\1') block_number from (
	  select * from t_dps_block where dataset = :dataset and regexp_like(name, '#\d+$')
           order by id desc ) b where rownum = 1
       }, ':dataset' => $$params{DEST_DATASET})->fetchrow_hashref();

#    &logmsg("last block $$info{ID} has name $$info{NAME} and has $$info{FILES} files and open=$$info{IS_OPEN}"); # XXX

    return $info;
}

sub lastBlockSpace
{
    my ($self, $params, $lock) = @_;

    my $info = $self->getLastBlock($params);

    # !!! Possible race condition here...  is there a way to select
    # the last block and lock it at the same time?  "for update" not
    # allowed in above query
    &dbexec($$self{DBH}, qq{ select id from t_dps_block where id = :block for update },
	    ':block' => $$info{ID}) if exists $$info{ID} && $lock;

    my $n_left = 0;
    if (!exists $$info{ID}) {
	# Return 0 if there is no last block
#	&logmsg('warning!  no last block!'); # XXX
	return 0;
    } elsif ($$info{IS_OPEN} eq 'n') {
	# Return 0 if the last block is closed
	$n_left = 0;
    } elsif (!defined $$params{BLOCK_SIZE}) {
	# Return a huge number if the blocks can be of infinite size
	$n_left = POSIX::DBL_MAX;
    } else {
	# Return how much there is left
	$n_left = $$params{BLOCK_SIZE} - $$info{FILES};
    }
    
    $n_left = 0 if $n_left < 0;

    return wantarray ? ($n_left, $$info{ID}) : $n_left;
}

sub throttleNodeFiles
{
    my ($self, $params) = @_;
    return 0 unless ($$params{THROTTLE_NODE});
    my ($t_files) = &dbexec($$self{DBH}, qq{
      select sum(b.files) - sum(nvl(br.node_files,0))
        from t_dps_dataset ds 
        join t_dps_block b on b.dataset = ds.id
   left join t_dps_block_replica br on br.block = b.id
   where ds.id = :dataset and br.node = :throttle_node },
			    ':dataset' => $$params{DEST_DATASET},
			    ':throttle_node' => $$params{THROTTLE_NODE})->fetchrow();
    
    return $t_files || 0;
}

sub calculateRateInjection
{
    my ($self, $params) = @_;

    # If this is the first injection, inject one file
    if (!$$params{TIME_INJECT}) {
	return 1;
    }

    my $delta_t = $$params{NOW} - $$params{TIME_INJECT};

    # If it has been over 1 day since our last injection, don't try to
    # "catch-up" the rate.  Just insert one file and we'll continue
    # the rate from there
    if ($delta_t > (3600 * 24)) {
	return 1;
    } 
    # Get the average size of the source sample
    my ($size) = &dbexec($$self{DBH}, qq{
	select avg(f.filesize) from t_dps_file f
	    join t_dps_block b on b.id = f.inblock
	    join t_dps_dataset ds on ds.id = b.dataset
	    where ds.id = :dataset },
			 ':dataset' => $$params{SRC_DATASET})->fetchrow();
    unless ($size) {
	&alert("dataset=$$params{SRC_DATASET} has no files");
	return 0;
    }
    
    my $n_files = ($delta_t * $$params{RATE}) / $size;
    return POSIX::ceil($n_files);
}

sub injectFiles
{
    my ($self, $params, $n_files) = @_;

    my $src_lfns = $self->getSourceLFNs($params);

    my $n_inject = 0;
    do {
	# get the space left in the last block
	my ($b_space, $block) = $self->lastBlockSpace($params, 1); # also locks block
#	&logmsg("$n_files left to inject, block $block has room for $b_space files");  # XXX

	# fill the last block until full
	my @files;
	while ($b_space > 0 && $n_files > 0) {
	    my $file = $self->pickNewLFN($params, $src_lfns);
	    $$file{BLOCK} = $block;
	    $$file{SOURCE} = $$params{DEST_NODE};
	    $$file{TIME_CREATE} = $$params{NOW};
	    push @files, $file;
	    $n_inject++; $b_space--; $n_files--;
	}
	$self->insertFileArray(\@files);

        # (maybe) close the last block
	$self->closeBlock($block) if $b_space == 0 && $$params{BLOCK_CLOSE};

	# create a new block if the dataset is not yet full
	if (!$self->datasetFull($params)) {
	    $self->createNewBlock($params) if $n_files > 0;
	} else {
	    $self->closeDataset($$params{DEST_DATASET}) if $$params{DATASET_CLOSE};
	}
    } while ($n_files > 0);

    return $n_inject;
}

sub closeBlock
{
    my ($self, $block) = @_;
    return unless defined $block;

    &dbexec($$self{DBH}, qq{
	update t_dps_block set is_open = 'n' where id = :block },
	    ':block' => $block);
}

sub closeDataset
{
    my ($self, $dataset) = @_;
    return unless defined $dataset;

    &dbexec($$self{DBH}, qq{
	update t_dps_dataset set is_open = 'n' where id = :dataset },
	    ':dataset' => $dataset);
}

sub createNewBlock
{
    my ($self, $params) = @_;

    my $info = $self->getLastBlock($params);
    my $n = exists $$info{BLOCK_NUMBER} ? $$info{BLOCK_NUMBER} + 1 : 0;
    my $name = $$params{DEST_DATASET_NAME} . "#" . $n;

    my $block;
    &dbexec($$self{DBH}, qq{
	insert into t_dps_block (id, dataset, name, files, bytes, is_open, time_create)
	values (seq_dps_block.nextval, :dataset, :name, 0, 0, 'y', :now)
	returning id into :id },
	    ':id' => \$block,
	    ':dataset' => $$params{DEST_DATASET},
	    ':name' => $name,
	    ':now' => $$params{NOW});
    
#    &logmsg("Created new block $name with id $block\n");  # XXX
    
    return $block;
}

sub insertFileArray
{
    my ($self, $files) = @_;
    
#    &logmsg("received ",scalar @$files, " files to inject");  # XXX
    return unless @$files;
    
    # TODO:  Copied from TMDBInject with minor modifications.  Consolidate into a common module?

    my $idps = &dbprep($$self{DBH}, qq{
	insert into t_dps_file
	    (id, node, inblock, logical_name, checksum, filesize, time_create)
	    values (seq_dps_file.nextval, ?, ?, ?, ?, ?, ?)});
    my $ixfer = &dbprep($$self{DBH}, qq{
	insert into t_xfer_file
	    (id, inblock, logical_name, checksum, filesize)
	    (select id, inblock, logical_name, checksum, filesize
	     from t_dps_file where logical_name = ?)});
    my $ixr = &dbprep($$self{DBH}, qq{
	insert into t_xfer_replica
	    (id, fileid, node, state, time_create, time_state)
	    (select seq_xfer_replica.nextval, id, ?, 0, ?, ?
	     from t_xfer_file where logical_name = ?)});

    my (%dps, %xfer, %xr);
    foreach my $file (@$files)
    {
	my $n = 1;
	push(@{$dps{$n++}}, $$file{SOURCE});
	push(@{$dps{$n++}}, $$file{BLOCK});
	push(@{$dps{$n++}}, $$file{LFN});
	push(@{$dps{$n++}}, $$file{CHECKSUM});
	push(@{$dps{$n++}}, $$file{FILESIZE});
	push(@{$dps{$n++}}, $$file{TIME_CREATE});
	
	$n = 1;
	push(@{$xfer{$n++}}, $$file{LFN});

	$n = 1;
	push(@{$xr{$n++}}, $$file{SOURCE});
	push(@{$xr{$n++}}, $$file{TIME_CREATE});
	push(@{$xr{$n++}}, $$file{TIME_CREATE});
	push(@{$xr{$n++}}, $$file{LFN});		
    }
    
    &dbbindexec($idps, %dps);
    &dbbindexec($ixfer, %xfer);
    &dbbindexec($ixr, %xr);
    
}

sub getSourceLFNs
{
    my ($self, $params) = @_;

    # Get LFNs which are only really in the source and at the node.
    # We have to check also for collapsed blocks because the source
    # datasets may not have moved for a long time
    my $q = &dbexec($$self{DBH}, qq{
	select xf.id, xf.logical_name lfn, xf.filesize, xf.checksum
	 from t_xfer_file xf
         join t_xfer_replica xr on xr.fileid = xf.id
	 join t_dps_block b on b.id = xf.inblock
	 join t_dps_dataset ds on ds.id = b.dataset
        where ds.id = :dataset1 and xr.node = :node1
        union
       select f.id, f.logical_name lfn, f.filesize, f.checksum
         from t_dps_file f
         join t_dps_block b on b.id = f.inblock
         join t_dps_block_replica br on br.block = b.id
         join t_dps_dataset ds on ds.id = b.dataset
        where ds.id = :dataset2 and br.node = :node2
	and br.is_active = 'n' },
		    ':dataset1' => $$params{SRC_DATASET},
		    ':dataset2' => $$params{SRC_DATASET},
		    ':node1' => $$params{DEST_NODE},
		    ':node2' => $$params{DEST_NODE});
    
    my $lfns = [];
    while (my $lfn = $q->fetchrow_hashref()) {
	push @$lfns, $lfn;
    }
	 
    &alert("source dataset=$$params{SRC_DATASET} has no files at node=$$params{DEST_NODE}") unless @$lfns;
    return $lfns;
}

sub pickNewLFN
{
    my ($self, $params, $src_lfns) = @_;
    
    # Pick a random LFN from the source set
    my $lfn = $$src_lfns[ int(rand @$src_lfns) ];
    $lfn = { %$lfn }; # copy

    # Add Source and GUID to name
    $$lfn{LFN} .= join(".", ".LTgenerated", $$params{DEST_NODE_NAME}, &makeGUID());

    return $lfn;
}


sub makeGUID
{
    my @chars = ( "A" .. "Z", "a" .. "z", 0 .. 9);
    return join("", @chars[ map { rand @chars } ( 1 .. 16 )]);
}
