#!/usr/bin/perl

## This is part of the T0 agent to merge files in the Global
## Distribution Buffer (GDB) Castor pool as they arrive from
## reconstruction.  In particular, this is a worker "thread"
## that receives files from the main funnel, extracts them
## from GDB and actually creates the zip.

BEGIN { use strict; $^W = 1; }
my ($dropdir, @nextdir, $inbox, $workdir, $outdir, $stopflag, $pidfile);
my $maindir;			# Main merger $dropdir

my @startTime;
my $waittime = 7;		# Seconds to sleep between inbox checks
my %bad = ();			# Drops we've warned are bad
my %junk = ();			# Drops we've warned are junk in inbox

my $dryrun = 0;			# Flag to indicate zip creation or logging only
my $clean = 0;			# Flag to indicate if we should remove originals
my $output = undef;		# Path for output zips
my $stagehost = "stagecmsdc04";	# Castor stage host
my $stagepool = "gdb";		# Castor stage pool

my $nrfcp = 5;			# Number of parallel rfcp copies

my $me = $0; $me =~ s|.*/||;
my $home = $0; $home =~ s|/[^/]+$||; $home ||= ".";

use File::Path;
eval qx(cat "$home/UtilsCommand.pm"); die $@ if $@;
eval qx(cat "$home/UtilsTiming.pm"); die $@ if $@;
eval qx(cat "$home/UtilsLogging.pm"); die $@ if $@;
eval qx(cat "$home/UtilsRFIO.pm"); die $@ if $@;
eval qx(cat "$home/UtilsAgent.pm"); die $@ if $@;

######################################################################
# Routines specific to this agent.

# Utility to log and cleanup from failed flush attempt
sub flushFailed
{
    my ($stats, $time, $msg, $dirs, $remote) = @_;

    # Try clean up RFIO file if there is one
    if ($remote)
    {
        my $attempts = 1;
        while ($attempts <= 10)
        {
	    last if &rfrm ($remote);
	    last if !&rfstat ($remote);
	    &alert ("failed to remove $remote (attempt $attempts), trying again in 10 seconds");
	    sleep (10);
	    $attempts++;
	}
    }

    # Get rid of temporary directories
    &rmtree ($dirs);

    # Log messages
    &alert ($msg);
    &logmsg ("$stats @{[&formatElapsedTime($time)]} failed");

    # Indicate failure
    return 0;
}

# Ensure all files for the queue have been fetched.
sub fetchQueueFiles
{
    my ($queue, $data) = @_;
    my $timing = [];
    &timeStart ($timing);

    my $basedir = "$workdir/$queue";
    my $predir = "$basedir/prefetch";
    my $filesdir = "$basedir/files";
    my $stats = "prefetch: $queue";

    # Create upload directory if necessary
    eval { &mkpath ([$predir, $filesdir]); };
    return &flushFailed ($stats, $timing, "could not create working directories: $@",
			 [$predir, $filesdir])
	if $@;

    # Download and validate files.
    my %copy = ();
    foreach my $member (values %{$data->{MEMBERS}})
    {
	my $pfn = $member->{CATALOG}{PFN}[0];
	my $lfn = $member->{CATALOG}{LFN}[0];

	next if -f "$filesdir/$lfn";
	if ($dryrun) {
	    &touch ("$predir/$lfn");
	} else {
	    $copy{$pfn} = "$predir/$lfn";
	}
    }

    my %copied = &rfcpmany ($nrfcp, %copy);
    my @failed = grep ($copied{$_}, keys %copied);
    return &flushFailed ($stats, $timing, "failed to copy @{[scalar @failed]} files", $predir)
        if @failed;

    foreach my $member (values %{$data->{MEMBERS}})
    {
	my $pfn = $member->{CATALOG}{PFN}[0];
	my $lfn = $member->{CATALOG}{LFN}[0];

	next if ! -f "$predir/$lfn" && -f "$filesdir/$lfn";

	return &flushFailed ($stats, $timing, "file size mismatch for $lfn", $predir)
	    if ((stat("$predir/$lfn"))[7] != $member->{CHECKSUM}[1]);

	unlink ("$filesdir/$lfn");
	return &flushFailed ($stats, $timing, "failed to move $lfn into files",
			     [ $predir, $filesdir ])
	    if ! &mv ("$predir/$lfn", "$filesdir/$lfn");
    }

    &logmsg ("$stats @{[&formatElapsedTime($timing)]} success") if keys %copied;
    return 1;
}

# Flush a queue.  Copy all the data from the castor pool, generate
# a zip archive, XML fragments and checksum files for both in the
# zip and the zip itself, templates for T1 agents for registering
# all the files.  Then copy the file back into castor and to send
# it to the next agent.  Optionally remove original files from castor.
sub flushQueue
{
    my ($queue, $data) = @_;

    my $timing = [];
    &timeStart($timing);

    my $time = ($queue =~ /(\d+)$/)[0];
    my $zipname = "$queue.zip";
    my $xfragname = "XMLCatFragment.$queue.txt";
    my $cksumname = "CheckSum.$queue.txt";
    my $ctcksumname = "CheckSum.Contents$queue.txt";
    my $replicamap = "ReplicaMap.txt";

    my $storeddir = $output;
    my $stored = $output && "$storeddir/$zipname";
    my $basedir = "$workdir/$queue";
    my $filesdir = "$basedir/files";
    my $dropin = $nextdir[0] && "$nextdir[0]/inbox/$queue";
    my $stats = "zipstats: $queue";

    # If the output already exists, complain and assume something went
    # awfully wrong, and require operator intervention.
    if (! $dryrun && $output && &rfstat ($stored))
    {
	&alert ("zip already exists: $stored");
	return 0;
    }

    # Create new working area, first clean up from previous failed
    # attempts; assume errors are transient.
    my @stamps
        = map { "$maindir/work/$_->{DROP}/QUEUEDONE.$_->{GUID}.$data->{NAME}" }
	  values %{$data->{MEMBERS}};

    my $erase = [ @stamps, map { "$basedir/$_" } ($xfragname, $cksumname, $zipname) ];
    &rmtree ($erase);
    push (@$erase, $filesdir);

    eval { &mkpath ($filesdir); };
    return &flushFailed ($stats, $timing, "could not create working directories: $@", $erase) if $@;

    # Download, checksum and validate checksum for files.
    return 0 if ! &fetchQueueFiles ($queue, $data);
    my $checksum = map { "$_\n" } map { join(" ", @{$_->{CHECKSUM}}) } values %{$data->{MEMBERS}};

    # Generate XML preamble/trailer
    my $xmlpreamble = ("<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\" ?>\n"
	               . "<!DOCTYPE POOLFILECATALOG SYSTEM \"InMemory\"><POOLFILECATALOG>\n"
		       . '  <META name="Content" type="string"/>' . "\n"
		       . '  <META name="DBoid" type="string"/>' . "\n"
		       . '  <META name="DataType" type="string"/>' . "\n"
		       . '  <META name="FileCategory" type="string"/>' . "\n"
		       . '  <META name="Flags" type="string"/>' . "\n"
		       . '  <META name="dataset" type="string"/>' . "\n"
		       . '  <META name="jobid" type="string"/>' . "\n"
		       . '  <META name="owner" type="string"/>' . "\n"
		       . '  <META name="runid" type="string"/>' . "\n");
    my $xmltrailer = "</POOLFILECATALOG>\n"; 

    # Generate XML fragment or the archive itself
    my $uuid = qx(uuidgen | tr '[a-f]' '[A-F]');
    chomp ($uuid);
    return &flushFailed ($stats, $timing, "failed to generate uuid", $erase) if ! $uuid;

    my $mainstream = ($data->{STREAM} eq 'MAIN');
    my $owner = ($mainstream ? $data->{OWNER} : "$data->{OWNER}-C-$data->{DATASET}");
    my $dataset = ($mainstream ? $data->{DATASET} : $data->{STREAM});
    my $xmldata = <<EOF;
<File ID="$uuid">
  <physical>
    <pfn filetype="zip" name="\@ZIPPFN\@"/>
  </physical>
  <logical>
    <lfn name="$zipname"/>
  </logical>
  <metadata att_name="Content" att_value="Zipped$data->{TYPE}"/>
  <metadata att_name="DBoid" att_value=""/>
  <metadata att_name="DataType" att_value="Zipped$data->{TYPE}"/>
  <metadata att_name="FileCategory" att_value="Zipped$data->{CATEGORY}"/>
  <metadata att_name="Flags" att_value=""/>
  <metadata att_name="dataset" att_value="$dataset"/>
  <metadata att_name="jobid" att_value="$time"/>
  <metadata att_name="owner" att_value="$owner"/>
  <metadata att_name="runid" att_value=""/>
</File>
EOF

    # Generate template XML fragment for archive contents
    my $replicas = "";
    foreach $member (values %{$data->{MEMBERS}})
    {
	my $lfn = $member->{CATALOG}{LFN}[0];
	my $pfn = "zip-member:\@ZIPPFN\@#$lfn";
	$replicas .= "$member->{GUID} $pfn\n";

	$xmldata .= "<File ID=\"$member->{GUID}\">\n";
	$xmldata .= "  <physical>\n";
	$xmldata .= "    <pfn filetype=\"ROOT_All\" name=\"$pfn\"/>\n";
	$xmldata .= "  </physical>\n";
	$xmldata .= "  <logical>\n";
	$xmldata .= "    <lfn name=\"$lfn\"/>\n";
	$xmldata .= "  </logical>\n";
	while (my ($meta, $value) = each %{$member->{CATALOG}{META}})
	{
	    $xmldata .= "  <metadata att_name=\"$meta\" att_value=\"$value\"/>\n";
	}
	$xmldata .= "</File>\n";
    }

    # Output XML fragment
    return &flushFailed ($stats, $timing, "failed to write member xml catalog", $erase)
        if (! &output ("$filesdir/$xfragname", $xmlpreamble . $xmldata . $xmltrailer));

    # Generate checksum file for archive contents
    return &flushFailed ($stats, $timing, "failed to write archive contents checksum", $erase)
        if (! &output ("$filesdir/$ctcksumname", $checksum));

    # Generate replica map template for T1 agents
    return &flushFailed ($stats, $timing, "failed to write replica map", $erase)
        if (! &output ("$filesdir/$replicamap", $replicas));

    # Pack it up and generate another checksum for the archive for transfer
    return &flushFailed ($stats, $timing, "failed to generate the zip archive", $erase)
        if (&runcmd ("zip", "-q", "-0", "-j", "$basedir/$zipname", glob("$filesdir/*")));

    # $checksum = &cksum ($basedir, $zipname);
    $checksum = "0 " . (stat("$basedir/$zipname"))[7] . " $zipname\n";
    return &flushFailed ($stats, $timing, "failed to write archive checksum", $erase)
        if (! $checksum || ! &output ("$basedir/$cksumname", $checksum));

    # Make XML fragment concrete for the drop
    my $replacement = $stored || $zipname;
    $xmldata =~ s/\@ZIPPFN\@/$replacement/g;
    return &flushFailed ($stats, $timing, "failed to write archive xml catalog", $erase)
        if (! &output ("$basedir/$xfragname", $xmlpreamble . $xmldata . $xmltrailer));

    # Transfer onwards
    if (! $dryrun && $output)
    {
        # Put it back on GDB
        return &flushFailed ($stats, $timing, "failed to create target rfio directory $storeddir", $erase)
            if (! &rfmkpath ($storeddir));

        return &flushFailed ($stats, $timing, "failed to copy file to pool", $erase, $stored)
            if (! &rfcp ("$basedir/$zipname", $stored));
    }

    return &flushFailed ($stats, $timing, "failed to remove zip", $erase, $stored)
        if (! unlink ("$basedir/$zipname"));

    # Mark all the member files done.
    return &flushFailed ($stats, $timing, "could not stamp members done: $!", $erase, $stored)
        if ! &touch (@stamps);

    # Mark drop itself done
    return &flushFailed ($stats, $timing, "could not mark drop done: $!", $erase, $stored)
	if ! &touch ("$basedir/done");

    # Zap extra files
    &rmtree ([ "$basedir/files", "$basedir/prefetch", "$basedir/START", "$basedir/state"]);

    # Remove original members
    if (! $dryrun && $output && $clean)
    {
	foreach my $pfn (map { @{$_->{CATALOG}{PFN}} } values %{$data->{MEMBERS}})
	{
            my $attempts = 1;
            while ($attempts < 10)
            {
	        last if &rfrm ($pfn);
	        &alert ("failed to clean member $pfn (attempt $attempts), trying again in 10 seconds");
	        sleep (10);
	    }
        }
    }

    return 1;
}

# Process a flushed queue.
sub processDrop
{
    my ($drop) = @_;

    # Sanity checking
    return if (! &inspectDrop ($drop));
    delete $bad{$drop};
    &timeStart();

    # Get data
    if (! -f "$workdir/$drop/state")
    {
	&alert ("no data in $drop");
	&markBad ($drop);
	return;
    }

    my $data = eval &input ("$workdir/$drop/state");
    if ($@)
    {
	&alert ("corrupted drop data: $@");
	&markBad ($drop);
	return;
    }
    
    # Flush it
    return if ! &flushQueue ($drop, $data);
    &relayDrop ($drop);
    &logmsg ("stats: $drop @{[&formatElapsedTime()]} success");
}

######################################################################
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-main' && scalar @ARGV > 1)
    { shift (@ARGV); $maindir = shift(@ARGV); }
    elsif ($ARGV[0] eq '-in' && scalar @ARGV > 1)
    { shift (@ARGV); $dropdir = shift(@ARGV); }
    elsif ($ARGV[0] eq '-out' && scalar @ARGV > 1)
    { shift (@ARGV); push(@nextdir, shift(@ARGV)); }
    elsif ($ARGV[0] eq '-dryrun')
    { shift (@ARGV); $dryrun = 1; }
    elsif ($ARGV[0] eq '-remove')
    { shift (@ARGV); $clean = 1; }
    elsif ($ARGV[0] eq '-store' && scalar @ARGV > 1)
    { shift (@ARGV); $output = shift(@ARGV); }
    elsif ($ARGV[0] eq '-stagehost' && scalar @ARGV > 1)
    { shift (@ARGV); $stagehost = shift(@ARGV); }
    elsif ($ARGV[0] eq '-stagepool' && scalar @ARGV > 1)
    { shift (@ARGV); $stagepool = shift(@ARGV); }
    elsif ($ARGV[0] eq '-rfcp' && scalar @ARGV > 1)
    { shift (@ARGV); $nrfcp = shift(@ARGV); }
    elsif ($ARGV[0] eq '-wait' && scalar @ARGV > 1)
    { shift (@ARGV); $waittime = shift(@ARGV); }
    else
    { last; }
}
	
if (scalar @ARGV || !$maindir || !$dropdir || !$stagehost || !$stagepool
    || ($dryrun && $clean))
{
    print STDERR
	"usage: $me -main MAIN-DROP-BOX -in IN-DROP-BOX\n",
	"    { [-dryrun] | [-remove] [-store RFIO-OUTPUT-PATH] }\n",
	"    [-stagehost STAGE-HOST] [-stagepool POOL]\n",
	"    [-out NEXT-DROP-BOX] [-wait SECS-TO-WAIT]\n",
	"    [-rfcp N-PARALLEL-DOWNLOADS]\n";
    exit (1);
}

$ENV{STAGE_HOST} = $stagehost;
$ENV{STAGE_POOL} = $stagepool;
&process();
