#!/usr/bin/perl

## This is part of the T0 agent to merge files in the Global
## Distribution Buffer (GDB) Castor pool as they arrive from
## reconstruction.  In particular, this is a worker "thread"
## that receives files from the main funnel, extracts them
## from GDB and actually creates the zip.

BEGIN {
  use strict; use warnings;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../Common";
  unshift(@INC, $home);
}

######################################################################
$ENV{STAGE_HOST} ||= "stagecmsprod";	# Castor stage host
$ENV{STAGE_POOL} ||= "cms_prod2";	# Castor stage pool
my %args;
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-in' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DROPDIR}= shift(@ARGV); }
    elsif ($ARGV[0] eq '-out' && scalar @ARGV > 1)
    { shift (@ARGV); push (@{$args{NEXTDIR}}, shift(@ARGV)); }
    elsif ($ARGV[0] eq '-dryrun')
    { shift (@ARGV); $args{DRYRUN} = 1; }
    elsif ($ARGV[0] eq '-remove')
    { shift (@ARGV); $args{CLEAN} = 1; }
    elsif ($ARGV[0] eq '-store' && scalar @ARGV > 1)
    { shift (@ARGV); $args{OUTPUT} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-stagehost' && scalar @ARGV > 1)
    { shift (@ARGV); $ENV{STAGE_HOST} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-stagepool' && scalar @ARGV > 1)
    { shift (@ARGV); $ENV{STAGE_POOL} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-main' && scalar @ARGV > 1)
    { shift (@ARGV); $args{MAINDIR} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-rfcp' && scalar @ARGV > 1)
    { shift (@ARGV); $args{NRFCP} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-wait' && scalar @ARGV > 1)
    { shift (@ARGV); $args{WAITTIME} = shift(@ARGV); }
    else
    { last; }
}
	
if (scalar @ARGV || !$args{DROPDIR} || !$ENV{STAGE_HOST} || !$ENV{STAGE_POOL}
    || !$args{MAINDIR} || ($args{DRYRUN} && $args{CLEAN}))
{
    print STDERR
	"usage: $me -main MAIN-DROP-BOX -in IN-DROP-BOX\n",
	"    { [-dryrun] | [-remove] [-store RFIO-OUTPUT-PATH] }\n",
	"    [-stagehost STAGE-HOST] [-stagepool POOL]\n",
	"    [-out NEXT-DROP-BOX] [-wait SECS-TO-WAIT]\n",
	"    [-rfcp N-PARALLEL-DOWNLOADS]\n";
    exit (1);
}

(new DropFunnelWorker (%args))->process();

######################################################################
# Routines specific to this agent.
package DropFunnelWorker; use strict; use warnings; use base 'UtilsAgent';
use File::Path;
use UtilsCommand;
use UtilsLogging;
use UtilsTiming;
use UtilsWriters;
use UtilsFunnel;

sub new
{
    my $proto = shift;
    my $class = ref($proto) || $proto;
    my $self = $class->SUPER::new(@_);
    my %params = (MAINDIR => undef,	# Main merger state directory
	    	  DRYRUN => 1,		# Flag to indicate zip creation or logging only
		  CLEAN  => 0,		# Flag to indicate if we should remove originals
		  OUTPUT => undef,	# Path for output zips
		  NRFCP => 5);		# Number of parallel rfcp jobs
    my %args = (@_);
    map { $self->{$_} = $args{$_} || $params{$_} } keys %params;
    bless $self, $class;
    return $self;
}

# Flush a queue.  Copy all the data from the castor pool, generate
# a zip archive, XML fragments and checksum files for both in the
# zip and the zip itself, templates for T1 agents for registering
# all the files.  Then copy the file back into castor and to send
# it to the next agent.  Optionally remove original files from castor.
sub flushQueue
{
    my ($self, $queue, $data) = @_;

    my $timing = [];
    &timeStart($timing);

    my $time = ($queue =~ /(\d+)$/)[0];
    my $zipname = "$queue.zip";
    my $xfragname = "XMLCatFragment.$queue.txt";
    my $cksumname = "CheckSum.$queue.txt";
    my $ctcksumname = "CheckSum.Contents$queue.txt";
    my $replicamap = "ReplicaMap.txt";

    my $storeddir = $self->{OUTPUT};
    my $stored = $storeddir && "$storeddir/$zipname";
    my $basedir = "$self->{WORKDIR}/$queue";
    my $filesdir = "$basedir/files";
    my $stats = "zipstats: $queue";

    # If the output already exists, complain and assume something went
    # awfully wrong, and require operator intervention.
    if (! $self->{DRYRUN} && $self->{OUTPUT} && &rfstatmode ($stored))
    {
	&alert ("zip already exists: $stored");
	return 0;
    }

    # Create new working area, first clean up from previous failed
    # attempts; assume errors are transient.
    my @stamps
        = map { "$self->{MAINDIR}/work/$_->{DROP}/QUEUEDONE.$_->{FILE}{GUID}.$data->{NAME}" }
	  values %{$data->{MEMBERS}};

    my $erase = [ @stamps, map { "$basedir/$_" } ($xfragname, $cksumname, $zipname) ];
    &rmtree ($erase);
    push (@$erase, $filesdir);

    eval { &mkpath ($filesdir); };
    return &flushFailed ($stats, $timing, "could not create working directories: $@", $erase) if $@;

    # Download, checksum and validate checksum for files.
    return 0 if ! &fetchQueueFiles ($self, "$self->{WORKDIR}/$queue", $data);
    my $checksum = join ("",
			 map { "$_\n" }
			 map { join(" ", @{$_->{FILE}{CHECKSUM}}) }
			 grep (defined $_->{FILE}{CHECKSUM}, values %{$data->{MEMBERS}}));

    # Generate XML fragment or the archive itself
    my $uuid = qx(uuidgen | tr '[a-f]' '[A-F]');
    chomp ($uuid);
    return &flushFailed ($stats, $timing, "failed to generate uuid", $erase) if ! $uuid;

    my $mainstream = ($data->{STREAM} eq 'MAIN');
    my $owner = ($mainstream ? $data->{OWNER} : "$data->{OWNER}-C-$data->{DATASET}");
    my $dataset = ($mainstream ? $data->{DATASET} : $data->{STREAM});
    my $xmldata = <<EOF;
<File ID="$uuid">
  <physical>
    <pfn filetype="zip" name="\@ZIPPFN\@"/>
  </physical>
  <logical>
    <lfn name="$zipname"/>
  </logical>
  <metadata att_name="Content" att_value="Zipped$data->{TYPE}"/>
  <metadata att_name="DBoid" att_value=""/>
  <metadata att_name="DataType" att_value="Zipped$data->{TYPE}"/>
  <metadata att_name="FileCategory" att_value="Zipped$data->{CATEGORY}"/>
  <metadata att_name="Flags" att_value=""/>
  <metadata att_name="dataset" att_value="$dataset"/>
  <metadata att_name="jobid" att_value="$time"/>
  <metadata att_name="owner" att_value="$owner"/>
  <metadata att_name="runid" att_value=""/>
</File>
EOF

    # Generate template XML fragment for archive contents
    my $replicas = "";
    foreach my $member (values %{$data->{MEMBERS}})
    {
	my $lfn = $member->{FILE}{LFN};
	my $pfn = "zip-member:\@ZIPPFN\@#$lfn";
	$replicas .= "$member->{FILE}{GUID} $pfn\n";

	$xmldata .= "<File ID=\"$member->{FILE}{GUID}\">\n";
	$xmldata .= "  <physical>\n";
	$xmldata .= "    <pfn filetype=\"ROOT_All\" name=\"$pfn\"/>\n";
	$xmldata .= "  </physical>\n";
	$xmldata .= "  <logical>\n";
	$xmldata .= "    <lfn name=\"$lfn\"/>\n";
	$xmldata .= "  </logical>\n";
	while (my ($meta, $value) = each %{$member->{FILE}{META}})
	{
	    $xmldata .= "  <metadata att_name=\"$meta\" att_value=\"$value\"/>\n";
	}
	$xmldata .= "</File>\n";
    }

    # Output XML fragment
    return &flushFailed ($stats, $timing, "failed to write member xml catalog", $erase)
        if (! &outputCatalog ("$filesdir/$xfragname", $xmldata));

    # Generate checksum file for archive contents
    return &flushFailed ($stats, $timing, "failed to write archive contents checksum", $erase)
        if (! &output ("$filesdir/$ctcksumname", $checksum));

    # Generate replica map template for T1 agents
    return &flushFailed ($stats, $timing, "failed to write replica map", $erase)
        if (! &output ("$filesdir/$replicamap", $replicas));

    # Pack it up and generate another checksum for the archive for transfer
    return &flushFailed ($stats, $timing, "failed to generate the zip archive", $erase)
        if (&runcmd ("zip", "-q", "-0", "-j", "$basedir/$zipname", glob("$filesdir/*")));

    # $checksum = &cksum ($basedir, $zipname);
    $checksum = "0 " . (stat("$basedir/$zipname"))[7] . " $zipname\n";
    return &flushFailed ($stats, $timing, "failed to write archive checksum", $erase)
        if (! $checksum || ! &output ("$basedir/$cksumname", $checksum));

    # Make XML fragment concrete for the drop
    my $replacement = $stored || $zipname;
    $xmldata =~ s/\@ZIPPFN\@/$replacement/g;
    return &flushFailed ($stats, $timing, "failed to write archive xml catalog", $erase)
        if (! &outputCatalog ("$basedir/$xfragname", $xmldata));

    # Transfer onwards
    if (! $self->{DRYRUN} && $self->{OUTPUT})
    {
        # Put it back on GDB
        return &flushFailed ($stats, $timing, "failed to create target rfio directory $storeddir", $erase)
            if (! &rfmkpath ($storeddir));

        return &flushFailed ($stats, $timing, "failed to copy file to pool", $erase, $stored)
            if (! &rfcp ("$basedir/$zipname", $stored));
    }

    return &flushFailed ($stats, $timing, "failed to remove zip", $erase, $stored)
        if (! unlink ("$basedir/$zipname"));

    # Mark all the member files done.
    return &flushFailed ($stats, $timing, "could not stamp members done: $!", $erase, $stored)
        if ! &touch (@stamps);

    # Mark drop itself done
    return &flushFailed ($stats, $timing, "could not mark drop done: $!", $erase, $stored)
	if ! &touch ("$basedir/done");

    # Zap extra files
    &rmtree ([ "$basedir/files", "$basedir/prefetch", "$basedir/START", "$basedir/state"]);

    # Remove original members
    if (! $self->{DRYRUN} && $self->{OUTPUT} && $self->{CLEAN})
    {
	foreach my $pfn (map { $_->{FILE}{PFN} } values %{$data->{MEMBERS}})
	{
            my $attempts = 1;
            while ($attempts < 10)
            {
	        last if &rfrm ($pfn);
	        &alert ("failed to clean member $pfn (attempt $attempts), trying again in 10 seconds");
	        sleep (10);
	    }
        }
    }

    return 1;
}

# Process a flushed queue.
sub processDrop
{
    my ($self, $drop) = @_;

    # Sanity checking
    return if (! $self->inspectDrop ($drop));
    delete $self->{BAD}{$drop};
    &timeStart($self->{STARTTIME});

    # Get data
    if (! -f "$self->{WORKDIR}/$drop/state")
    {
	&alert ("no data in $drop");
	$self->markBad ($drop);
	return;
    }

    my $data = do { no strict "vars"; eval &input ("$self->{WORKDIR}/$drop/state") };
    if ($@)
    {
	&alert ("corrupted drop data: $@");
	$self->markBad ($drop);
	return;
    }
    
    # Flush it
    return if ! $self->flushQueue ($drop, $data);

    $self->relayDrop ($drop);
    &logmsg ("stats: $drop @{[&formatElapsedTime($self->{STARTTIME})]} success");
}
