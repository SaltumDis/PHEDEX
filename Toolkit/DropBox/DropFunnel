#!/usr/bin/perl

## This drop-box agent merges files.  It is meant to be run on sites
## injecting data before the files are exposed to the transfer system.
##
## Due to various reasons, jobs running on the reconstruction farm
## produce each their own files.  Logically the output of the whole
## farm could be merged into a number of queues based on the type
## of the data; there is no non-technical reason to split the output
## into many small chunks.  This agent does the merging.  It doesn't
## matter whether the files arrive from a farm, or from other source,
## for instance the RefDB.
##
## Files are assembled into larger chunks based on the data type.
## Each such queue has user-configurable size and time limit.
## When either limit expires, the files collected so far are
## merged into a bigger file and sent downstream.
##
## Files are merged into uncompressed zip archives; individual files
## in the archive retain their identity, the rest of the system
## continues to see them as individual files.  Only they have a
## strange URL such as "zip-member:rfio:/.../foo.zip#member-name".
## COBRA has means to read such "sub-files" directly, redirecting
## the file access into a sub-byte-range inside the archive.

BEGIN { use strict; use warnings; }
$me = $0; $me =~ s|.*/||;
$home = $0; $home =~ s|/[^/]+$||; $home ||= ".";
unshift(@INC, $home);

######################################################################
my %args = (NWORKERS => 2);
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-in' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DROPDIR}= shift(@ARGV); }
    elsif ($ARGV[0] eq '-out' && scalar @ARGV > 1)
    { shift (@ARGV); push (@{$args{NEXTDIR}}, shift(@ARGV)); }
    elsif ($ARGV[0] eq '-dryrun')
    { shift (@ARGV); $args{DRYRUN} = 1; }
    elsif ($ARGV[0] eq '-remove')
    { shift (@ARGV); $args{CLEAN} = 1; }
    elsif ($ARGV[0] eq '-prefetch')
    { shift (@ARGV); $args{PREFETCH} = 1; }
    elsif ($ARGV[0] eq '-store' && scalar @ARGV > 1)
    { shift (@ARGV); $args{OUTPUT} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-stagehost' && scalar @ARGV > 1)
    { shift (@ARGV); $ENV{STAGE_HOST} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-stagepool' && scalar @ARGV > 1)
    { shift (@ARGV); $ENV{STAGE_POOL} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-wait' && scalar @ARGV > 1)
    { shift (@ARGV); $args{WAITTIME} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-workers' && scalar @ARGV > 1)
    { shift (@ARGV); $args{NWORKERS} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-rfcp' && scalar @ARGV > 1)
    { shift (@ARGV); $args{NRFCP} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-queue' && scalar @ARGV > 2)
    { shift (@ARGV); push (@{$args{QUEUECONFS}}, [ $ARGV[0], $ARGV[1], $ARGV[2] ]);
      shift (@ARGV); shift (@ARGV); shift (@ARGV); }
    else
    { last; }
}
	
if (scalar @ARGV || !$args{DROPDIR} || !$ENV{STAGE_HOST} || !$ENV{STAGE_POOL}
    || ($args{DRYRUN} && $args{CLEAN}))
{
    print STDERR
	"usage: $me -in IN-DROP-BOX\n",
	"    [-queue NAME TIME-LIMIT SIZE-LIMIT]...\n",
	"    { [-dryrun] | [-remove] [-store RFIO-OUTPUT-PATH] }\n",
	"    [-stagehost STAGE-HOST] [-stagepool POOL]\n",
	"    [-out NEXT-DROP-BOX] [-wait SECS-TO-WAIT]\n",
	"    [-rfcp N-PARALLEL-DOWNLOADS]\n",
	"    [-workers NUM-WORKERS] [-prefetch]\n";
    exit (1);
}

(new DropFunnel (%args))->process();

######################################################################
# Routines specific to this agent.
package DropFunnel; use strict; use warnings; use base 'UtilsAgent';
use Data::Dumper;
use File::Path;
use UtilsCommand;
use UtilsLogging;
use UtilsTiming;
use UtilsReaders;
use UtilsRFIO;
use UtilsFunnel;
use UtilsCache;

sub new
{
    my $proto = shift;
    my $class = ref($proto) || $proto;
    my $self = $class->SUPER::new(@_);
    my %params = (QUEUECONFS => [],	# Queue configuration
	    	  DRYRUN => 1,		# Flag to indicate zip creation or logging only
		  CLEAN  => 0,		# Flag to indicate if we should remove originals
		  OUTPUT => undef,	# Path for output zips
		  PREFETCH => 0,	# Flag for prefetching files when idle
		  NRFCP => 5,		# Number of parallel rfcp jobs
		  QUEUES => {});	# Queue status
    my %args = (@_);
    map { $self->{$_} = $args{$_} || $params{$_} } keys %params;
    bless $self, $class;
    return $self;
}

# Compute the attributes of a file we need in classification.  Returns
# 1 and modifies the file attributes on success, otherwise returns zero.
sub fileProperties
{
    my ($self, $file) = @_;

    # Check that it's a file we handle.
    my $type = $file->{FILE}{META}{DataType};
    my $category = $file->{FILE}{META}{FileCategory};
    my $dataset = $file->{FILE}{META}{dataset};
    my $owner = $file->{FILE}{META}{owner};
    my $runid = $file->{FILE}{META}{runid};
    my $jobid = $file->{FILE}{META}{jobid};
    do { &alert ("unrecognised file $file->{DROP}/$file->{FILE}{LFN}");
	 $self->markBad ($file->{DROP}); return 0; }
      if ((! $type || $type ne 'EVD')
	  || (! $category || ($category ne "Events"
			      && $category ne "DST"
			      && $category ne "Digis"))
	  || (! $dataset || ! $owner || ! $runid || ! $jobid));

    # Determine queue characteristics.
    $file->{QUEUE} = ($owner =~ /(.*)-C-(.*)/
	    	      # $2 = dataset, $1 = owner, $dataset = stream
	    	      ? "$type.$category.$2.$1.$dataset"
		      : "$type.$category.$dataset.$owner.MAIN");
    return 1;
}

# Check and possibly create a queue assignment for a file.
sub assignFile
{
    my ($self, $queues, $file) = @_;

    # Get the GUID.
    my $drop = $file->{DROP};
    my $guid = $file->{FILE}{GUID};
    my $lfn = $file->{FILE}{LFN};
    return 0 if ! $guid;

    # Check for existing assignments.
    my $dropdir = "$self->{WORKDIR}/$drop";
    my @assigned = map { s|.*/QUEUED.$guid.||; $_ } <$dropdir/QUEUED.$guid.*>;
    return 1 if (scalar @assigned == 1);
    do { &alert ("$drop/$guid assigned to more than one queue: "
		 . join(', ', @assigned)); return 0; }
        if (scalar @assigned > 1);

    # Unassigned, determine what we should do with it.
    return 0 if ! $self->fileProperties ($file) || ! $file->{QUEUE};

    my $q = $file->{QUEUE};
    my $mytime = (stat("$dropdir/go"))[9];
    $queues->{$q} ||= { START => time, &queueType ($q), MEMBERS => {} };
    $queues->{$q}{START} = $mytime if $queues->{$q}{START} > $mytime;

    return 0 if ! &touch ("$dropdir/QUEUED.$guid.$q");
    &logmsg("assigning $drop/$guid/$lfn to $q");
    $queues->{$q}{MEMBERS}{$guid} = $file;
    $queues->{$q}{DIRTY} = 1;
    return 1;
}

######################################################################
# Get the names of the currently maintained queues.
sub currentQueues
{
    my $self = shift;
    my @items;
    getdir ("$self->{DROPDIR}/queues", \@items);
    return @items;
}

# Return the working directory for a queue.  Create the directory if
# it doesn't exist yet.  The queue directory contains current file
# assignments.  It is also where we download the files, create the
# archive and make a drop when the time comes to it.
sub queueDirectory
{
    my ($self, $name) = @_;
    my $queuedir = "$self->{DROPDIR}/queues/$name";
    eval { &mkpath ($queuedir); };
    do { &alert ("cannot create queue directory $queuedir: $@"); return undef; } if $@;
    return $queuedir;
}

# Return hash parameters to characterise queue by its name
sub queueType
{
    # Get queue dataset and owner
    my ($name) = @_;
    my ($type, $category, $dataset, $owner, $stream) = ($name =~ m|([^.]+)|g);
    return (NAME => $name,
	    TYPE => $type, CATEGORY => $category,
	    DATASET => $dataset, OWNER => $owner,
	    STREAM => $stream);
}

# Return the current assignments to the queue.
sub readQueueStatus
{
    my ($self, $name) = @_;

    # Determine queue location
    my $dir = $self->queueDirectory ($name);

    # Restore contents
    my $state = do { no strict "vars"; eval &input ("$dir/state") };
    if ($@)
    {
	&alert ("internal error when restoring queue state for $name: $@");
	return undef;
    }

    $state->{DIRTY} = 0;

    # Validate queue properties
    my $bad = (! exists $state->{START}
	       || ! exists $state->{MEMBERS}
	       || ! exists $state->{NAME}
	       || ! exists $state->{TYPE}
	       || ! exists $state->{CATEGORY}
	       || ! exists $state->{DATASET}
	       || ! exists $state->{OWNER}
	       || ! exists $state->{STREAM});

    # Validate the data about each file
    foreach my $member (values %{$state->{MEMBERS}})
    {
	$bad = 1 if (! $member->{FILE} 
	             || ! $member->{DROP}
	             || ! $member->{QUEUE});
	last if $bad;
    }

    if ($bad)
    {
	&alert ("corrupt queue state $name");
	return undef;
    }

    return $state;
}

# Update the assignments to the queue on disk.
sub saveQueueStatus
{
    my ($self, $name, $data) = @_;
    return 1 if ! $data->{DIRTY};

    my $dir = $self->queueDirectory ($name);
    do { &alert ("cannot update queue state for $name"); return 0; }
	if ! &output ("$dir/state", Dumper ($data));

    $data->{DIRTY} = 0;
    return 1;
}

# Return properties for a named queue.  Uses the configuration
# parameters given on command line.  Default queue properties
# are 30min/1.5GB expiry.
sub queueLimits
{
    my ($self, $queue) = @_;
    my $props = { AGE => 30 * 60, SIZE => 1500 }; # 30 mins, 1.5GB
    foreach my $conf (@{$self->{QUEUECONFS}})
    {
	if ($queue =~ /$conf->[0]/)
	{
	    $props->{AGE} = $conf->[1];
	    $props->{SIZE} = $conf->[2];
	    last;
	}
    }

    return $props;
}

# Calcuate queue statistics
sub queueStats
{
    my ($self, $qdata) = @_;
    my $qstat = {};
    $qstat->{MEMBERS} = 0;
    $qstat->{SIZE} = 0;
    $qstat->{AGE} = time - $qdata->{START};
    foreach my $m (values %{$qdata->{MEMBERS}})
    {
	$qstat->{SIZE} += $m->{FILE}{FILESIZE} / (1024*1024);
	$qstat->{MEMBERS}++;
    }
    return $qstat;
}

# Flush a queue.  Transfer the queue to least-loaded worker thread.
sub flushQueue
{
    my ($self, $queue, $data, $now) = @_;
    return 0 if ! $self->saveQueueStatus ($queue, $data);

    # Pick currently least loaded worker thread.
    my $worker = $self->pickWorker();

    # Transfer the queue to that worker, renaming it with current timestamp
    my $queuedir = $self->queueDirectory ($queue);
    return 0 if ! &touch ("$queuedir/go");
    return 0 if ! &mv ($queuedir, "$self->{DROPDIR}/worker-$worker/inbox/Zipped$queue.$now");
    return 1;
}

# Check for interconnected qeueue expiry.
#
# Keeps matching 'Events', 'DST' and 'Digi' simultaneously flushed.
# This way the two always contain exactly the same set of runs.
sub flushSync
{
    my ($queues, $q, $flush) = @_;
    return if ! $flush->{$q};

    my @sync = qw(DST Events Digi);
    my $category = $queues->{$q}{CATEGORY};
    if (grep ($category eq $_, @sync))
    {
	foreach my $syncit (grep ($category ne $_, @sync))
	{
	    my $other = $q;
	    $other =~ s/\.$category\./.$syncit./;
	    next if ! exists $queues->{$other};
	    &logmsg ("synchronised expiry of $q and $other");
	    $flush->{$other} = 1;
	}
    }
}

######################################################################
# Check if we are interested in this drop.  Checks to see if either
# all files in the drop are EVD files, or all of them are not.  In
# the former case we are interested, in the latter not.  If we find
# mixed EVD and other files, complains and marks the drop bad.
sub isDropInteresting
{
    my ($self, $drop, $attrs) = @_;
    return 0 if ! -d "$self->{WORKDIR}/$drop";

    # Count EVD and non-EVD files.
    my $evds = scalar(grep ($_->{META}{DataType} eq 'EVD', @$attrs));
    my $nonevds = scalar(@$attrs) - $evds;

    # If not interesting, move downstream and indicate non-interest
    do { $self->relayDrop ($drop); return 0; } if ! $evds;

    # If interesting, indicate so
    return 1 if $evds && ! $nonevds;

    # Mixed, barf
    &alert ("drop $drop has both EVD files and non-EVD files");
    $self->markBad ($drop);
    return 0;
}

# Check if all files in the drop have already been
# handled, and if so, remove it.
sub isDropDone
{
    my ($self, $drop, $attrs) = @_;
    my $dropdir = "$self->{WORKDIR}/$drop";
    return 1 if ! -d $dropdir;

    # Count files processed and assigned to queues
    my @processed = <$dropdir/QUEUEDONE.*>;
    my @assigned = <$dropdir/QUEUED.*>;

    # Produce logging information on when this drop was first handled
    &logmsg ("state: start $drop @{[&mytimeofday()]}") if ! scalar (@assigned);

    # Return if more to do
    return 0 if ! (scalar @assigned == scalar @processed
		   && scalar @assigned == scalar(@$attrs));

    # Delete and log when we finished handling this drop
    &logmsg ("state: end $drop @{[&mytimeofday()]}");
    &rmtree ($dropdir);
    return 1;
}

######################################################################
# Assign all unassigned files of a drop into queues.
sub assignToQueues
{
    my ($self, $drop, $attrs, $queues) = @_;

    # Check if we should process this one
    return 1 if ! $self->isDropInteresting ($drop, $attrs);

    # Check if all files in this drop have already been handled
    return 1 if $self->isDropDone ($drop, $attrs);

    # Ensure that the drop has enough information for us
    if (my @missing = grep (! defined $_->{FILESIZE}, @$attrs))
    {
	&alert ("$drop: missing size for @{[map { $_->{PFN} } @missing]}");
	$self->markBad ($drop);
	return 0;
    }

    # Maybe assign more files.
    foreach my $file (@$attrs)
    {
	$self->assignFile ($queues, { DROP => $drop, FILE => $file })
	     or return 0;
    }

    return 1;
}

# Consider queue expiry times and flush those full/late enough.
sub flushExpiredQueues
{
    my ($self, $queues, $last) = @_;
    my %flush = ();
    my ($q, $qdata, $qstat, $qlim, $qmem);

    # Check which queues ought to be flushed.
    foreach $q (keys %$queues)
    {
	$qdata = $queues->{$q};
	$qmem = $qdata->{MEMBERS};

	# Flush if queue limits are exceeded, but consider size
	# only if we have run out drops to handle.
	$qstat = $qdata->{STATS} = $self->queueStats ($qdata);
	$qlim = $qdata->{LIMITS} = $self->queueLimits ($q);
	$flush{$q} = (($last && $qstat->{AGE} >= $qlim->{AGE})
		      || $qstat->{SIZE} >= $qlim->{SIZE});
    }

    # Synchronise linked queues
    foreach $q (keys %$queues)
    {
	&flushSync ($queues, $q, \%flush);
    }

    # Swoosshhh...
    my $now = time;
    foreach $q (keys %$queues)
    {
	$self->maybeStop ();
	$qdata = $queues->{$q};
	next if ! $flush{$q};

	$qlim = $qdata->{LIMITS};
	$qstat = $self->queueStats ($qdata);
	my $agewas = $qdata->{STATS}{AGE}; # when we made decision, flush takes a while
	&logmsg ("expiring queue $q at age $qstat->{AGE} ($agewas; $qlim->{AGE}),"
		 . " size @{[sprintf ('%.2f', $qstat->{SIZE})]} ($qlim->{SIZE}),"
		 . " $qstat->{MEMBERS} members");
	return 0 if ! $self->flushQueue ($q, $qdata, $now);
        delete $queues->{$q};
    }

    return 1;
}

# Purge drops for which all files have been zipped and shipped out.
sub purgeProcessedDrop
{
    my ($self, $drop, $attrs) = @_;
    $self->maybeStop ();
    $self->isDropDone ($drop, $attrs);
    return 1;
}

######################################################################
# Start a worker
sub startWorker
{
    my ($self, $i) = @_;
    my $workerdir = "$self->{DROPDIR}/worker-$i";
    &mkpath ($workerdir) if ! -d $workerdir;

    my $pid = undef;
    while (1)
    {
	last if defined ($pid = fork ());
        &logmsg ("cannot fork: $!; trying again in 10 seconds");
	sleep (10);
    }

    # Return child pid in parent;
    return $pid if $pid;

    # Child.
    my @args = ("$::home/DropFunnelWorker",
		"-main", $self->{DROPDIR}, "-in", $workerdir,
		(map { ("-out", $_) } @{$self->{NEXTDIR}}),
		"-stagehost", $ENV{STAGE_HOST}, "-stagepool", $ENV{STAGE_POOL},
		($self->{DRYRUN} ? "-dryrun" : ()),
		($self->{CLEAN} ? "-remove" : ()),
		($self->{OUTPUT} ? ("-store", $self->{OUTPUT}) : ()),
		"-rfcp", $self->{NRFCP},
		"-wait", "7");

    exec { $args[0] } @args;
    die "Cannot start worker: $!\n";
}

# Actually process a drop.  This is an unusual agent in that we leave
# files in their working directories while a queue accumulates.  We
# only leave markers in the drop directory to indicate which decisions
# and actions have been taken so the state is retained across runs.
# Once we decide to ship an archive, we update the state of all its
# members.  If we then detect a drop is fully handled, we remove it.
# The only thing that is relayed onwards is the archive we create and
# drops we don't recognise.
sub processDrop
{
    my ($self, $drop, $left) = @_;

    # Sanity checking
    return if (! $self->inspectDrop ($drop));
    delete $self->{BAD}{$drop};
    &timeStart($self->{STARTTIME});

    # Get queue configuration
    my $queues = $self->{QUEUES} = {};
    foreach my $q ($self->currentQueues())
    {
	my $status = $self->readQueueStatus ($q);
	return if ! $status;

	$queues->{$q} = $status;
    }

    # Expire already full queues, but only by size
    return if ! $self->flushExpiredQueues ($queues, 0);

    # Find the attribute cache to discover file information
    my $dropdir = "$self->{WORKDIR}/$drop";
    my $attrs = eval { &readAttributeCache ("$dropdir/attrs") };
    do { &alert ("$drop: $@"); $self->markBad ($drop); return } if $@;

    # Assign new files to queues
    return if ! $self->assignToQueues ($drop, $attrs, $queues);

    # Save queues.
    foreach my $q (keys %$queues) {
	$self->saveQueueStatus ($q, $queues->{$q});
    }

    # Check for and flush queues that have expired now
    $self->flushExpiredQueues ($queues, $left == 0);
}

# This is called by the main agent routine before sleeping.
# Flush queues here.
sub idle
{
    my ($self, @pending) = @_;
    my $errors = 0;

    # Maybe prefetch some files
    if ($self->{PREFETCH})
    {
        my $now = &mytimeofday();
        foreach my $q (keys %{$self->{QUEUES}})
        {
	    $self->maybeStop ();
	    last if &mytimeofday() - $now > $self->{WAITTIME} * 3;
	    &fetchQueueFiles ($self, $self->queueDirectory ($q), $self->{QUEUES}{$q});
        }
    }

    # Purge fully processed drops
    foreach my $drop (@pending)
    {
	$self->maybeStop ();

	my $dropdir = "$self->{WORKDIR}/$drop";
	my $attrs = eval { &readAttributeCache ("$dropdir/attrs") };
        do { &alert ("$drop: $@"); $self->markBad ($drop); last } if $@;

        $self->purgeProcessedDrop ($drop, $attrs);
    }

    # Check children are still running and then wait
    $self->maybeStop ();
    $self->checkWorkers ();
    sleep ($self->{WAITTIME});
}
