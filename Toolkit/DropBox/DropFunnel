#!/usr/bin/perl

## This is the T0 agent to merge files in the Global Distribution
## Buffer (GDB) Castor pool as they arrive from reconstruction.
##
## Due to various reasons, jobs running on the reconstruction farm
## produce each their own files.  Logically the output of the whole
## farm could be merged into a number of queues based on the type
## of the data; there is no non-technical reason to split the output
## into many small chunks.  This agent does the merging.
##
## Files are assembled into larger chunks based on the data type.
## Each such queue has user-configurable size and time limit.
## When either limit expires, the files collected so far are
## merged into a bigger file and sent downstream.
##
## Files are merged into uncompressed zip archives; individual files
## in the archive retain their identity, the rest of the system
## continues to see them as individual files.  Only they have a
## strange URL such as "zip-member:rfio:/.../foo.zip#member-name".
## COBRA has means to read such "sub-files" directly, redirecting
## the file access into a sub-byte-range inside the archive.
##
## Currently the agent is running only in logging mode, it does do
## all the work except it never touches the original files, only
## does the work and logs what it would have done.  This allows us
## to analyse how well it would work in practise.

BEGIN { use strict; $^W = 1; }
my ($dropdir, @nextdir, $inbox, $workdir, $outdir, $stopflag, $pidfile);
my @startTime;
my $waittime = 7;		# Seconds to sleep between inbox checks
my %bad = ();			# Drops we've warned are bad
my %junk = ();			# Drops we've warned are junk in inbox

my @queueconfs;			# Queue configuration
my $dryrun = 0;			# Flag to indicate zip creation or logging only
my $clean = 0;			# Flag to indicate if we should remove originals
my $output = undef;		# Path for output zips
my $stagehost = "stagecmsdc04";	# Castor stage host
my $stagepool = "gdb";		# Castor stage pool

my $prefetch = 0;		# Flag for prefetching files when idle
my $nrfcp = 5;			# Number of parallel rfcp jobs
my $nworkers = 2;		# Number of worker threads
my @workers;			# Worker pids.

my $me = $0; $me =~ s|.*/||;
my $home = $0; $home =~ s|/[^/]+$||; $home ||= ".";

use POSIX; # qw(strftime sys_wait_h);
use Data::Dumper;
use File::Path;
eval qx(cat "$home/UtilsReaders.pm"); die $@ if $@;
eval qx(cat "$home/UtilsAgent.pm"); die $@ if $@;

######################################################################
# Routines specific to this agent.

# Determine the cksum of a LFN.
sub fileCksum
{
    my ($drop, $checksums, $lfn) = @_;
    my @cksums = grep ($_->[2] eq $lfn, @$checksums);
    if (scalar @cksums != 1)
    {
	&alert (scalar(@cksums) . " checksums match $lfn");
	&markBad ($drop);
	return undef;
    }
    return $cksums[0];
}

# Compute the attributes of a file we need in classification.  Returns
# 1 and modifies the file attributes on success, otherwise returns zero.
sub fileProperties
{
    my ($file) = @_;

    # Check that it's a file we handle.
    delete $file->{CATALOG}{TEXT};
    my $type = $file->{CATALOG}{META}{DataType};
    my $category = $file->{CATALOG}{META}{FileCategory};
    my $dataset = $file->{CATALOG}{META}{dataset};
    my $owner = $file->{CATALOG}{META}{owner};
    my $runid = $file->{CATALOG}{META}{runid};
    my $jobid = $file->{CATALOG}{META}{jobid};
    do { &alert ("unrecognised file $drop/$file->{CATALOG}{LFN}[0]");
	 &markBad ($drop); return 0; }
      if ((! $type || $type ne 'EVD')
	  || (! $category || ($category ne "Events"
			      && $category ne "DST"
			      && $category ne "Digis"))
	  || (! $dataset || ! $owner || ! $runid || ! $jobid));

    # Determine queue characteristics.
    $file->{QUEUE} = ($owner =~ /(.*)-C-(.*)/
	    	      # $2 = dataset, $1 = owner, $dataset = stream
	    	      ? "$type.$category.$2.$1.$dataset"
		      : "$type.$category.$dataset.$owner.MAIN");
    return 1;
}

# Check and possibly create a queue assignment for a file.
sub assignFile
{
    my ($queues, $file) = @_;

    # Get the GUID.
    my $drop = $file->{DROP};
    my $guid = $file->{CATALOG}{GUID};
    my $lfn = $file->{CATALOG}{LFN}[0];
    return 0 if ! $guid;

    # Check for existing assignments.
    my @assigned = map { s|.*/QUEUED.$guid.||; $_ } <$workdir/$drop/QUEUED.$guid.*>;
    return 1 if (scalar @assigned == 1);
    do { &alert ("$drop/$guid assigned to more than one queue: "
		 . join(', ', @assigned)); return 0; }
        if (scalar @assigned > 1);

    # Unassigned, determine what we should do with it.
    return 0 if ! &fileProperties ($file) || ! $file->{QUEUE};

    my $q = $file->{QUEUE};
    my $mytime = (stat("$workdir/$drop/go"))[9];
    $queues->{$q} ||= { START => time, &queueType ($q), MEMBERS => {} };
    $queues->{$q}{START} = $mytime if $queues->{$q}{START} > $mytime;

    return 0 if ! &touch ("$workdir/$drop/QUEUED.$guid.$q");
    &logmsg("assigning $drop/$guid/$lfn to $q");
    $queues->{$q}{MEMBERS}{$guid} = $file;
    $queues->{$q}{DIRTY} = 1;
    return 1;
}

######################################################################
# Get the names of the currently maintained queues.
sub currentQueues
{
    my @items;
    getdir ("$dropdir/queues", \@items);
    return @items;
}

# Return the working directory for a queue.  Create the directory if
# it doesn't exist yet.  The queue directory contains current file
# assignments.  It is also where we download the files, create the
# archive and make a drop when the time comes to it.
sub queueDirectory
{
    my ($name) = @_;
    my $queuedir = "$dropdir/queues/$name";
    eval { &mkpath ($queuedir); };
    do { &alert ("cannot create queue directory $queuedir: $@"); return undef; } if $@;
    return $queuedir;
}

# Return hash parameters to characterise queue by its name
sub queueType
{
    # Get queue dataset and owner
    my ($name) = @_;
    my ($type, $category, $dataset, $owner, $stream) = ($name =~ m|([^.]+)|g);
    return (NAME => $name,
	    TYPE => $type, CATEGORY => $category,
	    DATASET => $dataset, OWNER => $owner,
	    STREAM => $stream);
}

# Return the current assignments to the queue.
sub readQueueStatus
{
    my ($name) = @_;

    # Determine queue location
    my $dir = &queueDirectory ($name);

    # Restore contents
    my $state = eval &input ("$dir/state");
    if ($@)
    {
	&alert ("internal error when restoring queue state for $name: $@");
	return undef;
    }

    $state->{DIRTY} = 0;

    # Validate queue properties
    my $bad = (! exists $state->{START}
	       || ! exists $state->{MEMBERS}
	       || ! exists $state->{NAME}
	       || ! exists $state->{TYPE}
	       || ! exists $state->{CATEGORY}
	       || ! exists $state->{DATASET}
	       || ! exists $state->{OWNER}
	       || ! exists $state->{STREAM});

    # Validate the data about each file
    foreach $member (values %{$state->{MEMBERS}})
    {
	$bad = 1 if (! $member->{GUID}
		     || ! $member->{CHECKSUM}
	             || ref $member->{CHECKSUM} ne 'ARRAY'
	             || scalar @{$member->{CHECKSUM}} != 3
	             || ! $member->{CATALOG}
	             || ! $member->{DROP}
	             || ! $member->{QUEUE});
	last if $bad;
    }

    if ($bad)
    {
	&alert ("corrupt queue state $name");
	return undef;
    }

    return $state;
}

# Update the assignments to the queue on disk.
sub saveQueueStatus
{
    my ($name, $data) = @_;
    return 1 if ! $data->{DIRTY};

    my $dir = &queueDirectory ($name);
    do { &alert ("cannot update queue state for $name"); return 0; }
	if ! &output ("$dir/state", Dumper ($data));

    $data->{DIRTY} = 0;
    return 1;
}

# Return properties for a named queue.  Uses the configuration
# parameters given on command line.  Default queue properties
# are 30min/1.5GB expiry.
sub queueLimits
{
    my ($queue) = @_;
    my $props = { AGE => 30 * 60, SIZE => 1500 }; # 30 mins, 1.5GB
    foreach my $conf (@queueconfs)
    {
	if ($queue =~ /$conf->[0]/)
	{
	    $props->{AGE} = $conf->[1];
	    $props->{SIZE} = $conf->[2];
	    last;
	}
    }

    return $props;
}

# Calcuate queue statistics
sub queueStats
{
    my ($qdata) = @_;
    my $qstat = {};
    $qstat->{MEMBERS} = 0;
    $qstat->{SIZE} = 0;
    $qstat->{AGE} = time - $qdata->{START};
    foreach my $m (values %{$qdata->{MEMBERS}})
    {
	$qstat->{SIZE} += $m->{CHECKSUM}[1] / (1024*1024);
	$qstat->{MEMBERS}++;
    }
    return $qstat;
}

# Utility to log and cleanup from failed flush attempt
sub flushFailed
{
    my ($stats, $time, $msg, $dirs, $remote) = @_;

    # Try clean up RFIO file if there is one
    if ($remote)
    {
        my $attempts = 1;
        while ($attempts <= 10)
        {
	    last if &rfrm ($remote);
	    &alert ("failed to remove $remote (attempt $attempts), trying again in 10 seconds");
	    sleep (10);
	    $attempts++;
	}
    }

    # Get rid of temporary directories
    &rmtree ($dirs);

    # Log messages
    &alert ($msg);
    &logmsg ("$stats @{[&formatElapsedTime($time)]} failed");

    # Indicate failure
    return 0;
}

# Ensure all files for the queue have been fetched.
sub fetchQueueFiles
{
    my ($queue, $data) = @_;
    my $timing = [];
    &timeStart ($timing);

    my $basedir = &queueDirectory ($queue);
    my $predir = "$basedir/prefetch";
    my $filesdir = "$basedir/files";
    my $stats = "prefetch: $queue";
    my $fetched = 0;

    # Create upload directory if necessary
    eval { &mkpath ([$predir, $filesdir]); };
    return &flushFailed ($stats, $timing, "could not create working directories: $@", $filesdir) if $@;

    # Download and validate files.
    my %copy = ();
    foreach my $member (values %{$data->{MEMBERS}})
    {
	my $pfn = $member->{CATALOG}{PFN}[0];
	my $lfn = $member->{CATALOG}{LFN}[0];

	next if -f "$filesdir/$lfn";
	if ($dryrun) {
	    &touch ("$predir/$lfn");
	} else {
	    $copy{$pfn} = "$predir/$lfn";
	}
    }

    my %copied = &rfcpmany ($nrfcp, %copy);
    my @failed = grep ($copied{$_}, keys %copied);
    return &flushFailed ($stats, $timing, "failed to copy @{[scalar @failed]} files", $predir)
        if @failed;

    foreach my $member (values %{$data->{MEMBERS}})
    {
	my $pfn = $member->{CATALOG}{PFN}[0];
	my $lfn = $member->{CATALOG}{LFN}[0];

	next if ! -f "$predir/$lfn" && -f "$filesdir/$lfn";

	return &flushFailed ($stats, $timing, "file size mismatch for $lfn", $predir)
	    if ((stat("$predir/$lfn"))[7] != $member->{CHECKSUM}[1]);

	unlink ("$filesdir/$lfn");
	return &flushFailed ($stats, $timing, "failed to move $lfn into files",
			     [ $predir, $filesdir ])
	    if ! &mv ("$predir/$lfn", "$filesdir/$lfn");
    }

    &logmsg ("$stats @{[&formatElapsedTime($timing)]} success") if $fetched;
    return 1;
}

# Flush a queue.  Transfer the queue to least-loaded worker thread.
sub flushQueue
{
    my ($queue, $data, $now) = @_;
    return 0 if ! &saveQueueStatus ($queue, $data);

    # Pick currently least loaded worker thread.
    my $worker = (sort { $a->[1] <=> $b->[1] }
    		  map { [ $_, scalar @{[<$dropdir/worker-$_/{inbox,work}/*>]} ] }
		  0 .. $#workers) [0]->[0];

    # Transfer the queue to that worker, renaming it with current timestamp
    my $queuedir = &queueDirectory ($queue);
    return 0 if ! &touch ("$queuedir/go");
    return 0 if ! &mv ($queuedir, "$dropdir/worker-$worker/inbox/Zipped$queue.$now");
    return 1;
}

# Check for interconnected qeueue expiry.
#
# Keeps matching 'Events', 'DST' and 'Digi' simultaneously flushed.
# This way the two always contain exactly the same set of runs.
sub flushSync
{
    my ($queues, $q, $flush) = @_;
    return if ! $flush->{$q};

    my @sync = qw(DST Events Digi);
    my $category = $queues->{$q}{CATEGORY};
    if (grep ($category eq $_, @sync))
    {
	foreach my $syncit (grep ($category ne $_, @sync))
	{
	    my $other = $q;
	    $other =~ s/\.$category\./.$syncit./;
	    next if ! exists $queues->{$other};
	    &logmsg ("synchronised expiry of $q and $other");
	    $flush->{$other} = 1;
	}
    }
}

######################################################################
# Check if we are interested in this drop.  Checks to see if either
# all files in the drop are EVD files, or all of them are not.  In
# the former case we are interested, in the latter not.  If we find
# mixed EVD and other files, complains and marks the drop bad.
sub isDropInteresting
{
    my ($drop, $catalog) = @_;
    return 0 if ! -d "$workdir/$drop";

    # Count EVD and non-EVD files.
    my @files = values %$catalog;
    my $evds = scalar(grep ($_->{META}{DataType} eq 'EVD', @files));
    my $nonevds = scalar(@files) - $evds;

    # If not interesting, move downstream and indicate non-interest
    do { &relayDrop ($drop); return 0; } if ! $evds;

    # If interesting, indicate so
    return 1 if $evds && ! $nonevds;

    # Mixed, barf
    &alert ("drop $drop has both EVD files and non-EVD files");
    &markBad ($drop);
    return 0;
}

# Check if all files in the drop have already been
# handled, and if so, remove it.
sub isDropDone
{
    my ($drop, $catalog) = @_;
    return 1 if ! -d "$workdir/$drop";

    # Count files processed and assigned to queues
    my @processed = <$workdir/$drop/QUEUEDONE.*>;
    my @assigned = <$workdir/$drop/QUEUED.*>;

    # Produce logging information on when this drop was first handled
    &logmsg ("state: start $drop @{[&mytimeofday()]}") if ! scalar (@assigned);

    # Return if more to do
    return 0 if ! (scalar @assigned == scalar @processed
		   && scalar @assigned == scalar(keys %$catalog));

    # Delete and log when we finished handling this drop
    &logmsg ("state: end $drop @{[&mytimeofday()]}");
    &rmtree ("$workdir/$drop");
    return 1;
}

######################################################################
# Assign all unassigned files of a drop into queues.
sub assignToQueues
{
    my ($drop, $catalog, $checksums, $queues) = @_;

    # Check if we should process this one
    return 1 if ! &isDropInteresting ($drop, $catalog);

    # Check if all files in this drop have already been handled
    return 1 if &isDropDone ($drop, $catalog);

    # Maybe assign more files.
    foreach my $f (values %$catalog) {
	my $file = {
	    DROP => $drop,
	    GUID => $f->{GUID},
	    CATALOG => $f,
	    CHECKSUM => &fileCksum ($drop, $checksums, @{$f->{LFN}})
	};

	return 0 if ! $file->{CHECKSUM};
	return 0 if ! &assignFile ($queues, $file);
    }

    return 1;
}

# Consider queue expiry times and flush those full/late enough.
sub flushExpiredQueues
{
    my ($queues, $last) = @_;
    my %flush = ();
    my ($q, $qdata, $qstat, $qlim, $qmem);

    # Check which queues ought to be flushed.
    foreach $q (keys %$queues)
    {
	$qdata = $queues->{$q};
	$qmem = $qdata->{MEMBERS};

	# Flush if queue limits are exceeded, but consider size
	# only if we have run out drops to handle.
	$qstat = $qdata->{STATS} = &queueStats ($qdata);
	$qlim = $qdata->{LIMITS} = &queueLimits ($q);
	$flush{$q} = (($last && $qstat->{AGE} >= $qlim->{AGE})
		      || $qstat->{SIZE} >= $qlim->{SIZE});
    }

    # Synchronise linked queues
    foreach $q (keys %$queues)
    {
	&flushSync ($queues, $q, \%flush);
    }

    # Swoosshhh...
    my $now = time;
    foreach $q (keys %$queues)
    {
	&maybeStop ();
	$qdata = $queues->{$q};
	next if ! $flush{$q};

	$qlim = $qdata->{LIMITS};
	$qstat = &queueStats ($qdata);
	$agewas = $qdata->{STATS}{AGE}; # when we made decision, flush takes a while
	&logmsg ("expiring queue $q at age $qstat->{AGE} ($agewas; $qlim->{AGE}),"
		 . " size @{[sprintf ('%.2f', $qstat->{SIZE})]} ($qlim->{SIZE}),"
		 . " $qstat->{MEMBERS} members");
	return 0 if ! &flushQueue ($q, $qdata, $now);
        delete $queues->{$q};
    }

    return 1;
}

# Purge drops for which all files have been zipped and shipped out.
sub purgeProcessedDrop
{
    my ($drop, $catalog) = @_;
    &maybeStop ();
    &isDropDone ($drop, $catalog);
    return 1;
}

######################################################################
# Start worker threads
sub init
{
    @workers = (0) x $nworkers;
    &checkWorkers();
}

# Ensure workers are running, if not, restart them
sub checkWorkers
{
    for (my $i = 0; $i <= $#workers; ++$i)
    {
	if (! $workers[$i] || waitpid($workers[$i], WNOHANG) > 0) {
	    my ($old, $new) = ($workers[$i], &startWorker ($i));
	    $workers[$i] = $new;

	    if (! $old) {
		&logmsg ("worker $i ($new) started");
	    } else {
	        &logmsg ("worker $i ($old) stopped, restarted as $new");
	    }
	}
    }
}

# Start a worker
sub startWorker
{
    my ($i) = @_;
    my $workerdir = "$dropdir/worker-$i";
    &mkpath ($workerdir) if ! -d $workerdir;

    my $pid = undef;
    while (1)
    {
	last if defined ($pid = fork ());
        &logmsg ("cannot fork: $!; trying again in 10 seconds");
	sleep (10);
    }

    # Return child pid in parent;
    return $pid if $pid;

    # Child.
    my @args = ("$home/T0-Funnel-Worker.pl",
		"-main", $dropdir, "-in", $workerdir,
		(map { ("-out", $_) } @nextdir),
		"-stagehost", $stagehost, "-stagepool", $stagepool,
		($dryrun ? "-dryrun" : ()),
		($remove ? "-remove" : ()),
		($output ? ("-store", $output) : ()),
		"-rfcp", $nrfcp,
		"-wait", "7");

    exec { $args[0] } @args;
    die "Cannot start worker: $!\n";
}

# Custom stop routine: stop workers too
sub stop
{
    # Make workers quit
    &note ("stopping worker threads");
    &touch (map { "$dropdir/worker-$_/stop" } 0 .. $#workers);
    while (scalar @workers)
    {
	my $pid = waitpid (-1, 0);
	@workers = grep ($pid ne $_, @workers);
	&logmsg ("child process $pid exited, @{[scalar @workers]} workers remain") if $pid > 0;
    }
}

# Actually process a drop.  This is an unusual agent in that we leave
# files in their working directories while a queue accumulates.  We
# only leave markers in the drop directory to indicate which decisions
# and actions have been taken so the state is retained across runs.
# Once we decide to ship an archive, we update the state of all its
# members.  If we then detect a drop is fully handled, we remove it.
# The only thing that is relayed onwards is the archive we create and
# drops we don't recognise.
sub processDrop
{
    my ($drop, $left) = @_;

    # Sanity checking
    return if (! &inspectDrop ($drop));
    delete $bad{$drop};
    &timeStart();

    # Get queue configuration
    my $queues = {};
    foreach my $q (&currentQueues)
    {
	my $status = &readQueueStatus ($q);
	return if ! $status;

	$queues->{$q} = $status;
    }

    # Expire already full queues, but only by size
    return if ! &flushExpiredQueues ($queues, 0);

    # Find the catalog and checksum files
    my $xmlcat = (<$workdir/$drop/XMLCatFragment.*.{xml,txt}>)[0];
    my $cksum = (<$workdir/$drop/CheckSum.*.txt>)[0];
    if (! defined $cksum)
    {
	&alert ("no checksum file found in $drop");
	&markBad ($drop);
	return;
    }

    if (! defined $xmlcat)
    {
	&alert ("no xml catalog file found in $drop");
	&markBad ($drop);
	return;
    }

    # Read catalog and checksum data
    my $catalog = eval { &readXMLCatalog ($drop, $xmlcat) };
    do { &alert($@); &markBad ($drop); return } if $@;

    my @checksums = eval { &readChecksumData ($drop, $cksum) };
    do { &alert($@); &markBad ($drop); return } if $@;

    # Assign new files to queues
    return if ! &assignToQueues ($drop, $catalog, \@checksums, $queues);

    # Save queues.
    foreach my $q (keys %$queues) {
	&saveQueueStatus ($q, $queues->{$q});
    }

    # Check for and flush queues that have expired now
    &flushExpiredQueues ($queues, $left == 0);
}

# This is called by the main agent routine before sleeping.
# Flush queues here.
sub idle
{
    my ($time, @pending) = @_;
    my $errors = 0;

    # Maybe prefetch some files
    if ($prefetch)
    {
        my $now = &mytimeofday();
        foreach my $q (keys %$queues)
        {
	    &maybeStop ();
	    last if &mytimeofday() - $now > $waittime * 3;
	    &fetchQueueFiles ($q, $queues->{$q});
        }
    }

    # Purge fully processed drops
    foreach my $drop (@pending)
    {
	&maybeStop ();

	my $xmlcat = (<$workdir/$drop/XMLCatFragment.*.{xml,txt}>)[0];
        next if ! defined $xmlcat;

        my $catalog = eval { &readXMLCatalog ($drop, $xmlcat) };
	do { &alert($@); &markBad ($drop); next } if $@;

        &purgeProcessedDrop ($drop, $catalog);
    }

    # Check children are still running and then wait
    &maybeStop ();
    &checkWorkers ();
    sleep ($time);
}

######################################################################
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-in' && scalar @ARGV > 1)
    { shift (@ARGV); $dropdir = shift(@ARGV); }
    elsif ($ARGV[0] eq '-out' && scalar @ARGV > 1)
    { shift (@ARGV); push (@nextdir, shift(@ARGV)); }
    elsif ($ARGV[0] eq '-dryrun')
    { shift (@ARGV); $dryrun = 1; }
    elsif ($ARGV[0] eq '-remove')
    { shift (@ARGV); $clean = 1; }
    elsif ($ARGV[0] eq '-prefetch')
    { shift (@ARGV); $prefetch = 1; }
    elsif ($ARGV[0] eq '-store' && scalar @ARGV > 1)
    { shift (@ARGV); $output = shift(@ARGV); }
    elsif ($ARGV[0] eq '-stagehost' && scalar @ARGV > 1)
    { shift (@ARGV); $stagehost = shift(@ARGV); }
    elsif ($ARGV[0] eq '-stagepool' && scalar @ARGV > 1)
    { shift (@ARGV); $stagepool = shift(@ARGV); }
    elsif ($ARGV[0] eq '-wait' && scalar @ARGV > 1)
    { shift (@ARGV); $waittime = shift(@ARGV); }
    elsif ($ARGV[0] eq '-workers' && scalar @ARGV > 1)
    { shift (@ARGV); $nworkers = shift(@ARGV); }
    elsif ($ARGV[0] eq '-rfcp' && scalar @ARGV > 1)
    { shift (@ARGV); $nrfcp = shift(@ARGV); }
    elsif ($ARGV[0] eq '-queue' && scalar @ARGV > 2)
    { shift (@ARGV); push (@queueconfs, [ $ARGV[0], $ARGV[1], $ARGV[2] ]);
      shift (@ARGV); shift (@ARGV); shift (@ARGV); }
    else
    { last; }
}
	
if (scalar @ARGV || !$dropdir || !$stagehost || !$stagepool || ($dryrun && $clean))
{
    print STDERR
	"usage: $me -in IN-DROP-BOX\n",
	"    [-queue NAME TIME-LIMIT SIZE-LIMIT]...\n",
	"    { [-dryrun] | [-remove] [-store RFIO-OUTPUT-PATH] }\n",
	"    [-stagehost STAGE-HOST] [-stagepool POOL]\n",
	"    [-out NEXT-DROP-BOX] [-wait SECS-TO-WAIT]\n",
	"    [-rfcp N-PARALLEL-DOWNLOADS]\n",
	"    [-workers NUM-WORKERS] [-prefetch]\n";
    exit (1);
}

$ENV{STAGE_HOST} = $stagehost;
$ENV{STAGE_POOL} = $stagepool;
&process();
