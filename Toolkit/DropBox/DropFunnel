#!/usr/bin/env perl

## This drop-box agent merges files.  It is meant to be run on sites
## injecting data before the files are exposed to the transfer system.
##
## Due to various reasons, jobs running on the reconstruction farm
## produce each their own files.  Logically the output of the whole
## farm could be merged into a number of queues based on the type
## of the data; there is no non-technical reason to split the output
## into many small chunks.  This agent does the merging.  It doesn't
## matter whether the files arrive from a farm, or from other source,
## for instance the RefDB.
##
## Files are assembled into larger chunks based on the data type.
## Each such queue has user-configurable size and time limit.
## When either limit expires, the files collected so far are
## merged into a bigger file and sent downstream.
##
## Files are merged into uncompressed zip archives; individual files
## in the archive retain their identity, the rest of the system
## continues to see them as individual files.  Only they have a
## strange URL such as "zip-member:rfio:/.../foo.zip#member-name".
## COBRA has means to read such "sub-files" directly, redirecting
## the file access into a sub-byte-range inside the archive.

BEGIN {
  use strict; use warnings;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../../Toolkit/Common";
  unshift(@INC, $home);
}

######################################################################
my %args = (NJOBS => 5);
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-in' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DROPDIR}= shift(@ARGV); }
    elsif ($ARGV[0] eq '-out' && scalar @ARGV > 1)
    { shift (@ARGV); push (@{$args{NEXTDIR}}, shift(@ARGV)); }
    elsif ($ARGV[0] eq '-dryrun')
    { shift (@ARGV); $args{DRYRUN} = 1; }
    elsif ($ARGV[0] eq '-remove')
    { shift (@ARGV); $args{CLEAN} = 1; }
    elsif ($ARGV[0] eq '-store' && scalar @ARGV > 1)
    { shift (@ARGV); $args{OUTPUT} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-wait' && scalar @ARGV > 1)
    { shift (@ARGV); $args{WAITTIME} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-jobs' && scalar @ARGV > 1)
    { shift (@ARGV); $args{NJOBS} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-queue' && scalar @ARGV > 3)
    { shift (@ARGV); push (@{$args{QUEUECONFS}}, [ $ARGV[0], $ARGV[1], $ARGV[2] ]);
      shift (@ARGV); shift (@ARGV); shift (@ARGV); }
    else
    { last; }
}
	
if (scalar @ARGV || !$args{DROPDIR} || ($args{DRYRUN} && $args{CLEAN}))
{
    print STDERR
	"usage: $me -in IN-DROP-BOX\n",
	"    [-queue NAME TIME-LIMIT SIZE-LIMIT]...\n",
	"    { [-dryrun] | [-remove] [-store RFIO-OUTPUT-PATH] }\n",
	"    [-out NEXT-DROP-BOX] [-wait SECS-TO-WAIT] [-jobs NUM-JOBS]\n";
    exit (1);

}

(new DropFunnel (%args))->process();

######################################################################
# Routines specific to this agent.
package DropFunnel; use strict; use warnings; use base 'UtilsAgent';
use File::Path;
use UtilsCommand;
use UtilsLogging;
use UtilsTiming;
use UtilsReaders;
use UtilsRFIO;
use UtilsFunnel;
use UtilsCache;

sub new
{
    my $proto = shift;
    my $class = ref($proto) || $proto;
    my $self = $class->SUPER::new(@_);
    my %params = (QUEUECONFS => [],	# Queue configuration
	    	  DRYRUN => 1,		# Flag to indicate zip creation or logging only
		  CLEAN  => 0,		# Flag to indicate if we should remove originals
		  OUTPUT => undef,	# Path for output zips
		  WAITLIST => {},	# Drops and files pending processing
		  FLUSHED => [],	# Flushed queues
		  QUEUES => {});	# Queue status
    my %args = (@_);
    map { $self->{$_} = $args{$_} || $params{$_} } keys %params;
    bless $self, $class;

    &rmtree ("$self->{WORKDIR}/queues");
    return $self;
}

# Compute the attributes of a file we need in classification.  Returns
# 1 and modifies the file attributes on success, otherwise returns zero.
sub fileProperties
{
    my ($self, $file) = @_;

    # Check that it's a file we handle.
    my $type = $file->{FILE}{META}{DataType};
    my $category = $file->{FILE}{META}{FileCategory};
    my $dataset = $file->{FILE}{META}{dataset};
    my $owner = $file->{FILE}{META}{owner};
    my $runid = $file->{FILE}{META}{runid};
    my $jobid = $file->{FILE}{META}{jobid};
    do { &alert ("unrecognised file $file->{DROP}/$file->{FILE}{LFN}");
	 $self->markBad ($file->{DROP}); return 0; }
      if ((! $type || $type ne 'EVD')
	  || (! $category || ! grep ($category eq $_, qw(Events DST Digis Assoc MCInfo Hits)))
	  || (! $dataset || ! $owner || ! $runid || ! $jobid));

    # Determine queue characteristics.
    $file->{QUEUE} = ($owner =~ /(.*)-C-(.*)/
	    	      # $2 = dataset, $1 = owner, $dataset = stream
	    	      ? "$type.$category.$2.$1.$dataset"
		      : "$type.$category.$dataset.$owner.MAIN");
    return 1;
}

# Check and possibly create a queue assignment for a file.
sub assignFile
{
    my ($self, $file) = @_;

    # Get the GUID.
    my $drop = $file->{DROP};
    my $guid = $file->{FILE}{GUID};
    my $lfn = $file->{FILE}{LFN};
    return 0 if ! $guid;

    # Check for existing assignments.
    return 1 if $self->{WAITLIST}{$drop}{$guid} >= 0;

    # Unassigned, determine what we should do with it.
    return 0 if ! $self->fileProperties ($file) || ! $file->{QUEUE};

    my $qname = $file->{QUEUE};
    my $mytime = (stat("$self->{WORKDIR}/$drop/go"))[9];
    my $now = time();

    &logmsg ("state: start $drop @{[&mytimeofday()]}")
	if ! exists $self->{WAITLIST}{$drop};
    $self->{WAITLIST}{$drop}{$guid} = 0;

    &logmsg("assigning $drop/$guid/$lfn to $qname");
    my $q = $self->{QUEUES}{$qname} ||= {
	START => $now, &queueType ($qname), MEMBERS => [],
	PENDING => 0, NAME => $qname, LFN => "Zipped$qname.$now",
	WORKDIR => "$self->{DROPDIR}/queues/Zipped$qname.$now" };
    $q->{START} = $mytime if $q->{START} > $mytime;
    push(@{$q->{MEMBERS}}, $file);
    return 1;
}

######################################################################
# Return hash parameters to characterise queue by its name
sub queueType
{
    # Get queue dataset and owner
    my ($name) = @_;
    my ($type, $category, $dataset, $owner, $stream) = ($name =~ m|([^.]+)|g);
    return (NAME => $name,
	    TYPE => $type, CATEGORY => $category,
	    DATASET => $dataset, OWNER => $owner,
	    STREAM => $stream);
}

# Return properties for a named queue.  Uses the configuration
# parameters given on command line.  Default queue properties
# are 30min/1.5GB expiry.
sub queueLimits
{
    my ($self, $qname) = @_;
    my $props = { AGE => 30 * 60, SIZE => 1500 }; # 30 mins, 1.5GB
    foreach my $conf (@{$self->{QUEUECONFS}})
    {
	if ($qname =~ /$conf->[0]/)
	{
	    $props->{AGE} = $conf->[1];
	    $props->{SIZE} = $conf->[2];
	    last;
	}
    }

    return $props;
}

# Calcuate queue statistics
sub queueStats
{
    my ($self, $q) = @_;
    my $qstat = {};
    $qstat->{MEMBERS} = 0;
    $qstat->{SIZE} = 0;
    $qstat->{AGE} = time - $q->{START};
    foreach my $m (@{$q->{MEMBERS}})
    {
	$qstat->{SIZE} += $m->{FILE}{FILESIZE} / (1024*1024);
	$qstat->{MEMBERS}++;
    }
    return $qstat;
}

######################################################################
# Check if we are interested in this drop.  Checks to see if either
# all files in the drop are EVD files, or all of them are not.  In
# the former case we are interested, in the latter not.  If we find
# mixed EVD and other files, complains and marks the drop bad.
sub isDropInteresting
{
    my ($self, $drop, $files) = @_;
    return 0 if ! -d "$self->{WORKDIR}/$drop";

    # Count EVD and non-EVD files.
    my $evds = scalar(grep ($_->{META}{DataType} eq 'EVD', @$files));
    my $nonevds = scalar(@$files) - $evds;

    # If not interesting, move downstream and indicate non-interest
    do { $self->relayDrop ($drop); return 0; } if ! $evds;

    # If interesting, indicate so
    return 1 if $evds && ! $nonevds;

    # Mixed, barf
    &alert ("drop $drop has both EVD files and non-EVD files");
    $self->markBad ($drop);
    return 0;
}

######################################################################
# Assign all unassigned files of a drop into queues.
sub assignToQueues
{
    my ($self, $drop, $files) = @_;

    # Check if we should process this one
    return 1 if ! $self->isDropInteresting ($drop, $files);

    # Ensure that the drop has enough information for us
    if (my @missing = grep (! defined $_->{FILESIZE}, @$files))
    {
	&alert ("$drop: missing size for @{[map { $_->{PFN} } @missing]}");
	$self->markBad ($drop);
	return 0;
    }

    # Maybe assign more files.
    foreach my $file (@$files)
    {
	$self->assignFile ({ DROP => $drop, FILE => $file })
	     or return 0;
    }

    return 1;
}

# Consider queue expiry times and flush those full/late enough.
sub flushExpiredQueues
{
    my ($self, $last) = @_;
    my %flush = ();
    my ($q, $qstat, $qlim);

    # Check which queues ought to be flushed.
    foreach $q (values %{$self->{QUEUES}})
    {
	# Flush if queue limits are exceeded, but consider size
	# only if we have run out drops to handle.
	$qstat = $q->{STATS} = $self->queueStats ($q);
	$qlim = $q->{LIMITS} = $self->queueLimits ($q->{NAME});
	$flush{$q->{NAME}} = (($last && $qstat->{AGE} >= $qlim->{AGE})
		              || $qstat->{SIZE} >= $qlim->{SIZE});
    }

    # Synchronise linked queues.  We keep matching "Events", "DST"
    # and "Digi" simultaneously flushed.  This way the two always
    # contain exactly the same set of runs.
    foreach $q (values %{$self->{QUEUES}})
    {
        next if ! $flush{$q->{NAME}};
        my @sync = qw(DST Events Digi);
        my $category = $q->{CATEGORY};
        if (grep ($category eq $_, @sync))
        {
	    foreach my $syncit (grep ($category ne $_, @sync))
	    {
	        my $other = $q;
	        $other =~ s/\.$category\./.$syncit./;
	        next if ! exists $self->{QUEUES}{$other};
	        &logmsg ("synchronised expiry of $q and $other");
	        $flush{$other} = 1;
	    }
        }
    }

    # Swoosshhh...
    my $now = time;
    foreach $q (values %{$self->{QUEUES}})
    {
	next if ! $flush{$q->{NAME}};
	$qlim = $q->{LIMITS};
	$qstat = $q->{STATS};
	&logmsg ("expiring queue $q->{NAME} at age $qstat->{AGE} ($qlim->{AGE}),"
		 . " size @{[sprintf ('%.2f', $qstat->{SIZE})]} ($qlim->{SIZE}),"
		 . " $qstat->{MEMBERS} members");

	push (@{$self->{FLUSHED}}, $q);
	delete $self->{QUEUES}{$q->{NAME}};
    }

    return 1;
}

######################################################################
# Actually process a drop.  This agent is unusual in that we keep the
# master state in memory and leave the files in their drop directories
# while queues accumulate.  We leave no markers in the file system on
# which queue assignments have been made.  Once we decide to ship an
# an archive, we update the state of all its members, and if we detect
# a drop has been fully handled, we remove it.  The only thing relayed
# onward is the archive we create and the drops we do not recognise.
sub processDrop
{
    my ($self, $drop, $left) = @_;

    # Sanity checking
    return if (! $self->inspectDrop ($drop));
    delete $self->{BAD}{$drop};
    &timeStart($self->{STARTTIME});

    # Expire already full queues, but only by size
    return if ! $self->flushExpiredQueues (0);

    # Read catalogue data and build attribute cache from it
    my $dropdir = "$self->{WORKDIR}/$drop";
    my $xmlcat = (<$dropdir/XMLCatFragment.*.{txt,xml}>)[0];
    do { &alert("$drop: no catalogue"); $self->markBad ($drop); return }
        if ! $xmlcat;
    my $catalogue = eval { &readXMLCatalogue ($xmlcat) };
    do { &alert ("$drop: $@"); $self->markBad ($drop); return } if $@;

    # Merge checksum data into cache
    my $cksumfile = (<$dropdir/Checksum.*.txt>)[0];
    do { &alert ("no checksum file in $drop"); $self->markBad ($drop); return }
        if ! $cksumfile;

    my @cksums = eval { &readChecksumData ($cksumfile) };
    do { &alert ($@); $self->markBad ($drop); return } if $@;

    my $bad = 0;
    foreach my $file (@$catalogue)
    {
	my $lfn = $file->{LFN}[0];
	my $cksum = (grep ($_->[2] eq $lfn, @cksums))[0];

	if (! $cksum)
	{
	   &alert ("$drop: no checksum for $lfn");
	   $bad = 1;
	   next;
        }

	&warn ("$drop: zero-size file $lfn") if ! $cksum->[1];

	$file->{CHECKSUM} = $cksum->[0];
	$file->{FILESIZE} = $cksum->[1];
    }

    do { $self->markBad ($drop); return } if $bad;

    # Assign new files to queues
    return if ! $self->assignToQueues ($drop, $catalogue);
}

# This is called by the main agent routine before sleeping.
# Keep processing jobs for flushed queues here.
sub idle
{
    my ($self, @pending) = @_;

    # Check for and flush queues that have expired now
    $self->flushExpiredQueues (1);

    # Keep pumping tasks until we've waited long enough.
    my $target = time() + $self->{WAITTIME};
    while (time() < $target)
    {
	# Process through the state machine for each flushed queue.
        for (my $i = 0; $i < scalar @{$self->{FLUSHED}}; ++$i)
        {
	    my $q = $self->{FLUSHED}[$i];

            # 1) Download files.
	    $self->queueFetchFiles ($q);

	    # 2) Checksum and validate input files.
	    $self->queueValidateFiles ($q);

	    # 3) Generate XML template fragment for members.
	    # 4) Output XML fragment for archive.
	    # 5) Output checksum for archive.
	    # 6) Output replica map for input files.
	    # 7) Generate the zip of input files, XML template and checksums.
	    $self->queueMergeFiles ($q);
	
	    # 8) Checksum the zip archive.
	    $self->queueChecksum ($q);

	    # 9) Store back in mass store.
	    $self->queueStore ($q);

	    # 10) Make XML template concrete for our own site.
	    # 11) Mark all files done.
	    $self->queueFinish ($q);

	    # 12) Remove original input files if requested.
	    $self->queueRemoveOrig ($q);

	    # Clean up, remove working directories and mark files in drops.
	    my $erase = 0;
	    if ($q->{DONE_ALL})
	    {
		foreach my $m (@{$q->{MEMBERS}})
		{
		    $self->{WAITLIST}{$m->{DROP}}{$m->{FILE}{GUID}} = 1;
		}

		$erase = 1;
	    }
	    elsif ($q->{FAILURE} && ! $q->{PENDING})
	    {
		&alert ($q->{FAILURE});
		if ($q->{CLEANUP})
		{
		    for (my $j = 0; $j < 10; ++$j)
        	    {
	    		last if &rfrm ($q->{CLEANUP});
	    		&alert ("attempting to remove $q->{CLEANUP} again");
	    		sleep (10);
		    }
		}

		foreach my $m (@{$q->{MEMBERS}})
		{
		    $self->{WAITLIST}{$m->{DROP}}{$m->{FILE}{GUID}} = -1;
		}

		$erase = 1;
	    }

	    if ($erase)
	    {
		eval { &rmtree ($q->{WORKDIR}) };
		splice (@{$self->{FLUSHED}}, $i, 1);
		--$i;
	    }
        }

	# Keep jobs running
        $self->maybeStop ();
        $self->pumpJobs ();
        select (undef, undef, undef, .1);
    }

    # Remove all completed drops.  For each drop chek if all files have
    # been assigned to a queue and that queue has been flushed.  If so,
    # remove the drop.  Drops with unflushed files, or in failed flush,
    # are left and will be reprocessed again later on.
    foreach my $drop (@pending)
    {
	my $waitlist = $self->{WAITLIST}{$drop};
	next if grep ($waitlist->{$_} != 1, keys %$waitlist);

	&logmsg ("state: end $drop @{[&mytimeofday()]}");
	&rmtree ("$self->{WORKDIR}/$drop");
    }

    # Purge memory of all drops that no longer exist.
    foreach my $drop (keys %{$self->{WAITLIST}})
    {
	next if grep ($_ eq $drop, @pending);
	delete $self->{WAITLIST}{$drop};
    }
}

# Fetch all files in the queue.  If we've already done our job,
# return immediately.  Otherwise keep track of how many files
# are still remaining to be downloaded, and when they are all
# finished, flag downloads completed.
sub queueFetchFiles
{
    my ($self, $q, $job) = @_;
    return if $q->{FAILURE} || $q->{DONE_DOWNLOADS} || $q->{PENDING};

    # Create working directories if necessary
    my $filesdir = "$q->{WORKDIR}/files";
    eval { &mkpath ($filesdir); };
    do { &logmsg ("$@"); return 0 } if $@;

    # Start downloading files that have not been fetched yet
    foreach my $member (@{$q->{MEMBERS}})
    {
	$q->{PENDING}++;

	my $pfn = $member->{FILE}{PFN};
	my $lfn = $member->{FILE}{LFN};
	my @cmd = ($self->{DRYRUN}
		   ? ("touch", "$filesdir/$lfn")
		   : ("rfcp", "$pfn", "$filesdir/$lfn"));
	$self->addJob (sub { my ($job) = @_; $q->{PENDING}--;
			     $q->{DONE_DOWNLOADS} = 1 if ! $q->{PENDING};
	    		     $q->{FAILURE} = "exit $job->{STATUS} from @cmd"
			         if $job->{STATUS} },
	    	       {}, @cmd);
    }
}

# Verify that all the download files have the expected size; checksum
# is ignored.  Marks queue failed if file size mismatch is detected.
sub queueValidateFiles
{
    my ($self, $q) = @_;
    return if $q->{FAILURE} || $q->{DONE_VALIDATE} || ! $q->{DONE_DOWNLOADS} || $q->{PENDING};

    foreach my $member (@{$q->{MEMBERS}})
    {
	my $local = "$q->{WORKDIR}/files/$member->{FILE}{LFN}";
	return $q->{FAILURE} = "$local: no such file" if ! -f $local;
	return $q->{FAILURE} = "$local: file size mismatch"
	    if (! $self->{DRYRUN} && (-s _ != $member->{FILE}{FILESIZE}));
    }

    $q->{DONE_VALIDATE} = 1;
}

# Produce a merged zip from the input files.
sub queueMergeFiles
{
    my ($self, $q) = @_;
    return if $q->{FAILURE} || $q->{DONE_MERGE} || ! $q->{DONE_VALIDATE} || $q->{PENDING};

    my $time = ($q->{LFN} =~ /(\d+)$/)[0];
    my $filesdir = "$q->{WORKDIR}/files";

    # Generate XML fragment for the archive itself
    my $uuid = qx(uuidgen | tr '[a-f]' '[A-F]'); chomp ($uuid);
    return $q->{FAILURE} = "failed to generate uuid" if ! $uuid;

    my $mainstream = ($q->{STREAM} eq 'MAIN');
    my $owner = ($mainstream ? $q->{OWNER} : "$q->{OWNER}-C-$q->{DATASET}");
    my $dataset = ($mainstream ? $q->{DATASET} : $q->{STREAM});
    my $xmldata = <<EOF;
<File ID="$uuid">
  <physical>
    <pfn filetype="EVDZip" name="\@ZIPPFN\@"/>
  </physical>
  <logical>
    <lfn name="$q->{LFN}"/>
  </logical>
  <metadata att_name="Content" att_value="Zipped$q->{TYPE}"/>
  <metadata att_name="DBoid" att_value=""/>
  <metadata att_name="DataType" att_value="Zipped$q->{TYPE}"/>
  <metadata att_name="FileCategory" att_value="Zipped$q->{CATEGORY}"/>
  <metadata att_name="Flags" att_value=""/>
  <metadata att_name="dataset" att_value="$dataset"/>
  <metadata att_name="jobid" att_value="$time"/>
  <metadata att_name="owner" att_value="$owner"/>
  <metadata att_name="runid" att_value=""/>
</File>
EOF

    # Generate template XML fragment for archive contents
    my $replicas = "";
    foreach my $member (@{$q->{MEMBERS}})
    {
	my $lfn = $member->{FILE}{LFN};
	my $pfn = "zip-member:\@ZIPPFN\@#$lfn";
	$replicas .= "$member->{FILE}{GUID} $pfn\n";

	$xmldata .= "<File ID=\"$member->{FILE}{GUID}\">\n";
	$xmldata .= "  <physical>\n";
	$xmldata .= "    <pfn filetype=\"ROOT_All\" name=\"$pfn\"/>\n";
	$xmldata .= "  </physical>\n";
	$xmldata .= "  <logical>\n";
	$xmldata .= "    <lfn name=\"$lfn\"/>\n";
	$xmldata .= "  </logical>\n";
	while (my ($attr, $value) = each %{$member->{FILE}{META}})
	{
	    $xmldata .= "  <metadata att_name=\"$attr\" att_value=\"$value\"/>\n";
	}
	$xmldata .= "</File>\n";
    }

    # Output XML fragment
    return $q->{FAILURE} = "failed to write member xml catalog"
        if (! &outputCatalog ("$filesdir/XMLCatFragment.$q->{LFN}.txt", $xmldata));

    # Generate checksum file for archive contents
    return $q->{FAILURE} = "failed to write archive contents checksum"
        if (! &output ("$filesdir/CheckSum.Contents.$q->{LFN}.txt",
		       join ("",
                             map { "$_\n" }
                             map { join(" ", @{$_->{FILE}{CHECKSUM}}) }
                             @{$q->{MEMBERS}})));

    # Generate replica map template for T1 agents
    return $q->{FAILURE} = "failed to write replica map"
        if (! &output ("$filesdir/ReplicaMap.txt", $replicas));

    # Pack it up
    $q->{PENDING}++;
    $self->addJob (sub { my ($job) = @_; $q->{PENDING}--; $q->{DONE_MERGE} = 1;
			 $q->{FAILURE} = "failed to generate the zip archive:"
			     . " exit $job->{STATUS} from @{$job->{CMD}}"
			     if $job->{STATUS} }, {},
		   "zip", "-q", "-0", "-j", "$q->{WORKDIR}/$q->{LFN}.zip", <$filesdir/*>);
}

# Checksum the merged zip.
sub queueChecksum
{
    my ($self, $q) = @_;
    return if $q->{FAILURE} || $q->{DONE_CHECKSUM} || ! $q->{DONE_MERGE} || $q->{PENDING};

    # Generate checksum for the archive for transfer
    $q->{PENDING}++;
    $self->addJob (sub { my ($job) = @_; $q->PENDING--; $q->{DONE_CHECKSUM} = 1;
			 $q->{FAILURE} = "failed to write archive checksum:"
			     . " exit $job->{STATUS} from @{$job->{CMD}}"
			     if $job->{STATUS} }, {},
		   "sh", "-c", "cd $q->{WORKDIR} && cksum $q->{LFN}.zip > CheckSum.$q->{LFN}.txt");

    # return $q->{FAILURE} = "failed to write archive checksum"
    #     if (! &output ("$q->{WORKDIR}/CheckSum.$q->{LFN}.txt",
    #                    "-1 " . (-s "$q->{WORKDIR}/$q->{LFN}.zip") . " $q->{LFN}.zip\n"));
}

# Store the merged zip back into storage buffer.
sub queueStore
{
    my ($self, $q) = @_;
    return if $q->{FAILURE} || $q->{DONE_STORE} || ! $q->{DONE_CHECKSUM} || $q->{PENDING};

    # Check output destination doesn't already exist.
    my $storeddir = $self->{OUTPUT};
    my $stored = $storeddir && "$storeddir/$q->{LFN}.zip";
    return $q->{FAILURE} = "destination zip already exists: $stored"
        if (! $self->{DRYRUN} && $self->{OUTPUT} && &rfstatmode ($stored));

    # Store back into mass storage
    if (! $self->{DRYRUN} && $self->{OUTPUT})
    {
	return $q->{FAILURE} = "failed to create target rfio directory $storeddir"
            if ! &rfmkpath ($storeddir);

	$q->{PENDING}++;
        $q->{CLEANUP} = $stored;
	$self->addJob (sub { my ($job) = @_; $q->{PENDING}--; $q->{DONE_STORE} = 1;
		       $q->{FAILURE} = "failed to store archive to $stored:"
			   . " exit $job->{STATUS} from @{$job->{CMD}}"
			   if $job->{STATUS} }, {},
		       "rfcp", "$q->{WORKDIR}/$q->{LFN}.zip", $stored);
    }
    else
    {
	$q->{DONE_STORE} = 1;
    }
}

# Move information about the merged zip to the next agent
# in processing line
sub queueFinish
{
    my ($self, $q) = @_;
    return if $q->{FAILURE} || $q->{DONE_FINISH} || ! $q->{DONE_STORE} || $q->{PENDING};

    # Make XML fragment concrete for the drop
    my $xml = &input ("$q->{WORKDIR}/files/XMLCatFragment.$q->{LFN}.txt");
    my $replacement = ($self->{OUTPUT} ? "$self->{OUTPUT}/" : "") . "$q->{LFN}.zip";
    $xml =~ s/\@ZIPPFN\@/$replacement/g;
    return $q->{FAILURE} = "failed to write archive xml catalog"
        if (! $xml || ! &output ("$q->{WORKDIR}/XMLCatFragment.$q->{LFN}.txt", $xml));
}

# Remove original input files from storage buffer if so requested.
sub queueRemoveOrig
{
    my ($self, $q) = @_;
    return if $q->{FAILURE} || $q->{DONE_REMOVE} || ! $q->{DONE_FINISH} || $q->{PENDING};

    # Remove original members
    if (! $self->{DRYRUN} && $self->{OUTPUT} && $self->{CLEAN})
    {
	foreach my $pfn (map { $_->{FILE}{PFN} } @{$q->{MEMBERS}})
	{
	    for (my $j = 0; $j < 10; ++$j)
       	    {
    		last if &rfrm ($pfn);
    		&alert ("attempting to remove $pfn again");
    		sleep (10);
	    }
        }
    }

}

1;
