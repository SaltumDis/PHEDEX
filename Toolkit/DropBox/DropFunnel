#!/usr/bin/env perl

##H This drop-box agent merges files.  It is meant to be run on sites
##H injecting data before the files are exposed to the transfer system.
##H
##H Due to various reasons, jobs running on the reconstruction farm
##H produce each their own files.  Logically the output of the whole
##H farm could be merged into a number of queues based on the type
##H of the data; there is no non-technical reason to split the output
##H into many small chunks.  This agent does the merging.  It doesn't
##H matter whether the files arrive from a farm, or from other source,
##H for instance the RefDB.
##H
##H Files are assembled into larger chunks based on the data type.
##H Each such queue has user-configurable size and time limit.
##H When either limit expires, the files collected so far are
##H merged into a bigger file and sent downstream.
##H
##H Files are merged into uncompressed zip archives; individual files
##H in the archive retain their identity, the rest of the system
##H continues to see them as individual files.  Only they have a
##H strange URL such as "zip-member:rfio:/.../foo.zip#member-name".
##H COBRA has means to read such "sub-files" directly, redirecting
##H the file access into a sub-byte-range inside the archive.
##H
##H Usage:
##H   DropFunnel
##H      -state DIRECTORY [-next DIRECTORY] [-wait SECS] [-once]
##H      [-queue NAME TIME-LIMIT SIZE-LIMIT] [-jobs NJOBS]
##H      { [-dryrun] | [-remove] [-stored DIRECTORY] }
##H
##H -state     agent state directory, including inbox
##H -next      next agent to pass the drops to; can be given several times
##H -wait      time to wait in seconds between work scans
##H -once      run only until all drops are merged, then exit
##H -queue     set time and size limit for a queue matching a regexp
##H -jobs      run the specified number of subjobs in parallel (default: 5)
##H -dryrun    don't actually download and merge files, just run queuing logic
##H -remove    remove original files after successful store of the zip
##H -store     store the resulting zips into the given (RFIO) path

BEGIN {
  use strict; use warnings; $^W=1;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../../Toolkit/Common";
  unshift(@INC, $home);
}

######################################################################
use UtilsHelp;
my %args = (NJOBS => 5);
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-state' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DROPDIR}= shift(@ARGV); }
    elsif ($ARGV[0] eq '-next' && scalar @ARGV > 1)
    { shift (@ARGV); push (@{$args{NEXTDIR}}, shift(@ARGV)); }
    elsif ($ARGV[0] eq '-once')
    { shift (@ARGV); $args{ONCE} = 1; }
    elsif ($ARGV[0] eq '-dryrun')
    { shift (@ARGV); $args{DRYRUN} = 1; }
    elsif ($ARGV[0] eq '-remove')
    { shift (@ARGV); $args{CLEAN} = 1; }
    elsif ($ARGV[0] eq '-synchronise')
    { shift (@ARGV); $args{SYNCHRONISE} = 1; }
    elsif ($ARGV[0] eq '-store' && scalar @ARGV > 1)
    { shift (@ARGV); $args{OUTPUT} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-wait' && scalar @ARGV > 1)
    { shift (@ARGV); $args{WAITTIME} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-jobs' && scalar @ARGV > 1)
    { shift (@ARGV); $args{NJOBS} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-queue' && scalar @ARGV > 3)
    { shift (@ARGV); push (@{$args{QUEUECONFS}}, [ $ARGV[0], $ARGV[1], $ARGV[2] ]);
      shift (@ARGV); shift (@ARGV); shift (@ARGV); }
    elsif ($ARGV[0] eq '-h')
    { &usage(); }
    else
    { last; }
}
	
if (@ARGV || !$args{DROPDIR} || ($args{DRYRUN} && $args{CLEAN}))
{
    die "Insufficient parameters, use -h for help.\n";
}

(new DropFunnel (%args))->process();

######################################################################
# Routines specific to this agent.
package DropFunnel; use strict; use warnings; use base 'UtilsAgent';
use File::Path;
use UtilsCommand;
use UtilsLogging;
use UtilsTiming;
use UtilsReaders;
use UtilsWriters;
use UtilsRFIO;
use UtilsCache;

sub new
{
    my $proto = shift;
    my $class = ref($proto) || $proto;
    my $self = $class->SUPER::new(@_);
    my %params = (QUEUECONFS => [],	# Queue configuration
	    	  ONCE => 0,		# Flag to indicate we should quit when all done
	    	  DRYRUN => 1,		# Flag to indicate zip creation or logging only
		  CLEAN  => 0,		# Flag to indicate if we should remove originals
		  SYNCHRONISE => 0,	# Flag to indicate we should sync queues
		  SERIAL => 0,		# Serial number to guarantee uniqueness
		  OUTPUT => undef,	# Path for output zips
		  WAITLIST => {},	# Drops and files pending processing
		  FLUSHED => [],	# Flushed queues
		  QUEUES => {});	# Queue status
    my %args = (@_);
    map { $self->{$_} = $args{$_} || $params{$_} } keys %params;
    bless $self, $class;

    &rmtree ("$self->{WORKDIR}/queues");
    return $self;
}

# Compute the attributes of a file we need in classification.  Returns
# 1 and modifies the file attributes on success, otherwise returns zero.
sub fileProperties
{
    my ($self, $file) = @_;

    # Check that it's a file we handle.
    my $type = $file->{FILE}{META}{DataType};
    my $category = $file->{FILE}{META}{FileCategory};
    my $dataset = $file->{FILE}{META}{dataset};
    my $owner = $file->{FILE}{META}{owner};
    my $runid = $file->{FILE}{META}{runid};
    my $jobid = $file->{FILE}{META}{jobid};
    do { &alert ("unrecognised file $file->{DROP}/$file->{FILE}{LFN}[0]");
	 $self->markBad ($file->{DROP}); return 0; }
      if ((! $type || $type ne 'EVD')
	  || (! $category || ! grep ($category eq $_, qw(Events DST Digis Assoc MCInfo Hits)))
	  || (! $dataset || ! $owner || ! $runid || ! $jobid));

    # Determine queue characteristics.
    $file->{QUEUE} = ($owner =~ /(.*)-C-(.*)/
	    	      # $2 = dataset, $1 = owner, $dataset = stream
	    	      ? "$type.$category.$2.$1.$dataset"
		      : "$type.$category.$dataset.$owner.MAIN");
    return 1;
}

# Check and possibly create a queue assignment for a file.
sub assignFile
{
    my ($self, $file) = @_;

    # Get the GUID.
    my $drop = $file->{DROP};
    my $guid = $file->{FILE}{GUID};
    my $lfn = $file->{FILE}{LFN}[0];
    return 0 if ! $guid;

    # Check for existing assignments.
    return 1 if (exists $self->{WAITLIST}{$drop}
		 && exists $self->{WAITLIST}{$drop}{$guid}
		 && $self->{WAITLIST}{$drop}{$guid} >= 0);

    # Unassigned, determine what we should do with it.
    return 0 if ! $self->fileProperties ($file) || ! $file->{QUEUE};

    my $qname = $file->{QUEUE};
    my $mytime = (stat("$self->{WORKDIR}/$drop/go"))[9];
    my $now = time();

    # If the queue exists, make sure there's enough space in it.
    $self->maybeFlushQueue ($self->{QUEUES}{$qname}, 0,
			    $file->{FILE}{FILESIZE} / (1024*1024))
	if $self->{QUEUES}{$qname};

    # Assign to the queue.  Create a new queue if necessary.
    &logmsg ("state: start $drop @{[&mytimeofday()]}")
        if ! exists $self->{WAITLIST}{$drop};
    &logmsg("assigning $drop/$guid/$lfn to $qname");
    $self->{WAITLIST}{$drop}{$guid} = 0;
    my $q = $self->{QUEUES}{$qname};
    if (! $q)
    {
	my $n = ++$self->{SERIAL};
        $q = $self->{QUEUES}{$qname} ||= {
	    START => $now, &queueType ($qname), MEMBERS => [],
	    PENDING => 0, LABEL => "$qname.$now.$n", LFN => "Zipped$qname.$now.$n",
	    WORKDIR => "$self->{DROPDIR}/queues/Zipped$qname.$now.$n",
	    STATS => { MEMBERS => 0, SIZE => 0, AGE => 0 },
	    LIMITS => $self->queueLimits ($qname)
	};
    }
    $q->{START} = $mytime if $q->{START} > $mytime;
    $q->{STATS}{SIZE} += $file->{FILE}{FILESIZE} / (1024*1024);
    $q->{STATS}{MEMBERS}++;
    push(@{$q->{MEMBERS}}, $file);
    return 1;
}

######################################################################
# Return hash parameters to characterise queue by its name
sub queueType
{
    # Get queue dataset and owner
    my ($name) = @_;
    my ($type, $category, $dataset, $owner, $stream) = ($name =~ m|([^.]+)|g);
    return (NAME => $name,
	    TYPE => $type, CATEGORY => $category,
	    DATASET => $dataset, OWNER => $owner,
	    STREAM => $stream);
}

# Return properties for a named queue.  Uses the configuration
# parameters given on command line.  Default queue properties
# are 30min/1.99GB expiry.
sub queueLimits
{
    my ($self, $qname) = @_;
    my $props = { AGE => 30 * 60, SIZE => 1990 }; # 30 mins, 1.99GB
    foreach my $conf (@{$self->{QUEUECONFS}})
    {
	if ($qname =~ /$conf->[0]/)
	{
	    $props->{AGE} = $conf->[1];
	    $props->{SIZE} = $conf->[2];
	    last;
	}
    }

    return $props;
}

######################################################################
# Check if we are interested in this drop.  Checks to see if either
# all files in the drop are EVD files, or all of them are not.  In
# the former case we are interested, in the latter not.  If we find
# mixed EVD and other files, complains and marks the drop bad.
sub isDropInteresting
{
    my ($self, $drop, $files) = @_;
    return 0 if ! -d "$self->{WORKDIR}/$drop";

    # Count EVD and non-EVD files.
    my $evds = scalar(grep ($_->{META}{DataType} eq 'EVD', @$files));
    my $nonevds = scalar(@$files) - $evds;

    # If not interesting, move downstream and indicate non-interest
    do { $self->relayDrop ($drop); return 0; } if ! $evds;

    # If interesting, indicate so
    return 1 if $evds && ! $nonevds;

    # Mixed, barf
    &alert ("drop $drop has both EVD files and non-EVD files");
    $self->markBad ($drop);
    return 0;
}

######################################################################
# Assign all unassigned files of a drop into queues.
sub assignToQueues
{
    my ($self, $drop, $files) = @_;

    # Check if we should process this one
    return 1 if ! $self->isDropInteresting ($drop, $files);

    # Ensure that the drop has enough information for us
    if (my @missing = grep (! defined $_->{FILESIZE}, @$files))
    {
	&alert ("$drop: missing size for @{[map { $_->{PFN}[0]{PFN} } @missing]}");
	$self->markBad ($drop);
	return 0;
    }

    # Maybe assign more files.
    foreach my $file (@$files)
    {
	next if -f "$self->{WORKDIR}/$drop/DONE.$file->{GUID}";
	$self->assignFile ({ DROP => $drop, FILE => $file })
	     or return 0;
    }

    return 1;
}

# Flush a queue if it's expired in time or size, or cannot take
# the size of the file we would like to put into it.
sub maybeFlushQueue
{
    my ($self, $q, $last, $space) = @_;
    my %flush = ();

    # Flush if queue limits are exceeded, but consider size only if
    # we have no more drops to handle.  However make sure there is
    # at least $space room size-wise; flush if there is less.
    my $qlim = $q->{LIMITS};
    my $qstat = $q->{STATS};
    return if ! (($last && $qstat->{AGE} >= $qlim->{AGE})
		 || ($qstat->{SIZE} + $space) >= $qlim->{SIZE});

    $flush{$q->{NAME}} = 1;

    # Synchronise linked queues.  We keep matching "Events", "DST"
    # and "Digi" simultaneously flushed.  This way the two always
    # contain exactly the same set of runs.
    if ($self->{SYNCHRONISE})
    {
        my @sync = qw(DST Events Digi);
        my $category = $q->{CATEGORY};
        if (grep ($category eq $_, @sync))
        {
	    foreach my $syncit (grep ($category ne $_, @sync))
	    {
	        my $other = $q->{NAME};
	        $other =~ s/\.$category\./.$syncit./;
	        next if ! exists $self->{QUEUES}{$other};
	        &logmsg ("synchronised expiry of $q->{NAME} and $other");
	        $flush{$other} = 1;
	    }
        }
    }

    # Swoosshhh...
    my $now = time;
    foreach my $qname (keys %flush)
    {
	my $q = $self->{QUEUES}{$qname};
	my $qlim = $q->{LIMITS};
	my $qstat = $q->{STATS};
	&logmsg ("expiring queue $q->{LABEL} at age $qstat->{AGE} ($qlim->{AGE}),"
		 . " size @{[sprintf ('%.2f', $qstat->{SIZE})]} ($qlim->{SIZE}),"
		 . " $qstat->{MEMBERS} members");

	push (@{$self->{FLUSHED}}, $q);
	delete $self->{QUEUES}{$qname};
    }
}

# Consider queue expiry times and flush those full/late enough.
sub flushExpiredQueues
{
    my ($self, $last) = @_;
    my %flush = ();

    # Check which queues ought to be flushed.
    foreach my $q (values %{$self->{QUEUES}})
    {
	# Update queue age first, then see if we should flush.
        $q->{STATS}{AGE} = time - $q->{START};
	$self->maybeFlushQueue ($q, $last, 0);
    }

    return 1;
}

######################################################################
# Actually process a drop.  This agent is unusual in that we keep the
# master state in memory and leave the files in their drop directories
# while queues accumulate.  We leave no markers in the file system on
# which queue assignments have been made.  Once we decide to ship an
# an archive, we update the state of all its members, and if we detect
# a drop has been fully handled, we remove it.  The only thing relayed
# onward is the archive we create and the drops we do not recognise.
sub processDrop
{
    my ($self, $drop, $left) = @_;

    # Sanity checking
    return if (! $self->inspectDrop ($drop));
    delete $self->{BAD}{$drop};
    &timeStart($self->{STARTTIME});

    # If we've already seen this drop, consider only if waitlist
    # indicates there is something new to be done about it.
    return if (exists $self->{WAITLIST}{$drop}
	       && ! grep ($_ < 0, values %{$self->{WAITLIST}{$drop}}));

    # Expire already full queues, but only by size
    return if ! $self->flushExpiredQueues (0);

    # Read catalogue data and build attribute cache from it
    my $dropdir = "$self->{WORKDIR}/$drop";
    my $xmlcat = (<$dropdir/XMLCatFragment.*.{txt,xml}>)[0];
    do { &alert("$drop: no catalogue"); $self->markBad ($drop); return }
        if ! $xmlcat;
    my $catalogue = eval { &readXMLCatalogue ($xmlcat) };
    do { &alert ("$drop: $@"); $self->markBad ($drop); return } if $@;

    # Merge checksum data into cache
    my $cksumfile = (<$dropdir/Checksum.*.txt>)[0];
    do { &alert ("no checksum file in $drop"); $self->markBad ($drop); return }
        if ! $cksumfile;

    my @cksums = eval { &readChecksumData ($cksumfile) };
    do { &alert ($@); $self->markBad ($drop); return } if $@;

    my $bad = 0;
    foreach my $file (@$catalogue)
    {
	my $lfn = $file->{LFN}[0];
	my $cksum = (grep ($_->[2] eq $lfn, @cksums))[0];

	if (! $cksum)
	{
	   &alert ("$drop: no checksum for $lfn");
	   $bad = 1;
	   next;
        }

	&warn ("$drop: zero-size file $lfn") if ! $cksum->[1];

	$file->{CHECKSUM} = $cksum->[0];
	$file->{FILESIZE} = $cksum->[1];
    }

    do { $self->markBad ($drop); return } if $bad;

    # Assign new files to queues
    return if ! $self->assignToQueues ($drop, $catalogue);

    # Pump jobs about a few times every so often
    return if $left % 1000;
    # $self->flushPump ();
    &logmsg ("@{[scalar @{$self->{JOBS}}]} jobs,"
	     . " @{[scalar @{$self->{FLUSHED}}]} flushed,"
	     . " @{[scalar keys %{$self->{QUEUES}}]} queues,"
	     . " @{[scalar keys %{$self->{WAITLIST}}]} waiting,"
	     . " $left left");
}

sub flushPump
{
    my ($self) = @_;
    return if ! @{$self->{FLUSHED}} && ! @{$self->{JOBS}};

    # Process through the state machine for each flushed queue.
    for (my $i = 0; $i < scalar @{$self->{FLUSHED}} && $i < $self->{NJOBS}; ++$i)
    {
	my $q = $self->{FLUSHED}[$i];

        # 1) Download files.
	$self->queueFetchFiles ($q);

	# 2) Checksum and validate input files.
	$self->queueValidateFiles ($q);

	# 3) Generate XML template fragment for members.
	# 4) Output XML fragment for archive.
	# 5) Output checksum for archive.
	# 6) Output replica map for input files.
	# 7) Generate the zip of input files, XML template and checksums.
	$self->queueMergeFiles ($q);
	
	# 8) Checksum the zip archive.
	$self->queueChecksum ($q);

	# 9) Store back in mass store.
	$self->queueStore ($q);

	# 10) Make XML template concrete for our own site.
	# 11) Mark all files done.
	$self->queueFinish ($q);

	# 12) Remove original input files if requested.
	$self->queueRemoveOrig ($q);

	# Clean up, remove working directories and mark files in drops.
	my $erase = 0;
	if ($q->{DONE_ALL})
	{
	    &logmsg ("done queue $q->{LABEL}");
	    foreach my $m (@{$q->{MEMBERS}})
	    {
		&touch ("$self->{WORKDIR}/$m->{DROP}/DONE.$m->{FILE}{GUID}");
		$self->{WAITLIST}{$m->{DROP}}{$m->{FILE}{GUID}} = 1;
		$self->checkDropDone ($m->{DROP});
	    }

	    $erase = 1;
	}
	elsif ($q->{FAILURE} && ! $q->{PENDING})
	{
	    &alert ($q->{FAILURE});
	    if ($q->{CLEANUP})
	    {
		for (my $j = 0; $j < 10; ++$j)
        	{
	    	    last if &rfrm ($q->{CLEANUP});
	    	    &alert ("attempting to remove $q->{CLEANUP} again");
	    	    sleep (10);
		}
	    }

	    foreach my $m (@{$q->{MEMBERS}})
	    {
		$self->{WAITLIST}{$m->{DROP}}{$m->{FILE}{GUID}} = -1;
	    }

	    $erase = 1;
	}

	if ($erase)
	{
	    eval { &rmtree ($q->{WORKDIR}) };
	    splice (@{$self->{FLUSHED}}, $i, 1);
	    --$i;
	}

        # Keep jobs running
        $self->pumpJobs ();
    }
}

sub checkDropDone
{
    # Remove a completed drop.  Check if all files for this drop have
    # been assigned to a queue and that queue has been flushed.  If so,
    # remove the drop.  Drops with unflushed files, or in failed flush,
    # are left and will be reprocessed again later on.
    my ($self, $drop) = @_;
    my $waitlist = $self->{WAITLIST}{$drop};
    return if ! $waitlist || grep ($_ != 1, values %$waitlist);
    &logmsg ("state: end $drop @{[&mytimeofday()]}");
    &rmtree ("$self->{WORKDIR}/$drop");
    delete $self->{WAITLIST}{$drop};
}

# This is called by the main agent routine before sleeping.
# Keep processing jobs for flushed queues here.
sub idle
{
    my ($self, @pending) = @_;

    # Check for and flush queues that have expired now
    $self->flushExpiredQueues (1);

    # Keep pumping tasks until we've waited long enough.
    my $target = &mytimeofday() + $self->{WAITTIME};
    while (&mytimeofday() < $target && @{$self->{FLUSHED}})
    {
	$self->flushPump ();
	my $npending = scalar @{$self->{FLUSHED}};
	my $nrunning = scalar (grep ($_->{PID} > 0, @{$self->{JOBS}}));
	next if ($npending && $nrunning < $self->{NJOBS});
        select (undef, undef, undef, .02);
	$self->maybeStop ();
    }

    if (! @{$self->{FLUSHED}})
    {
        # Check if we can release any of the drops.
        foreach my $drop (@pending)
        {
	    $self->checkDropDone ($drop);
        }

        # Purge memory of all drops that no longer exist.
        my %known = map { ($_ => 1) } @pending;
        foreach my $drop (keys %{$self->{WAITLIST}})
        {
	    delete $self->{WAITLIST}{$drop} if ! $known{$drop};
        }
    }

    &logmsg ("@{[scalar @{$self->{JOBS}}]} jobs,"
	     . " @{[scalar @{$self->{FLUSHED}}]} flushed,"
	     . " @{[scalar keys %{$self->{QUEUES}}]} queues,"
	     . " @{[scalar keys %{$self->{WAITLIST}}]} waiting,"
	     . " @{[scalar @pending]} left") if @pending;

    # Stop now if nothing to do and we do only one pass
    $self->doStop() if $self->{ONCE} && ! keys %{$self->{WAITLIST}};

    # Nap the remaining of the time (if any)
    my $now = &mytimeofday ();
    $self->nap ($target - $now) if $now < $target;
}

# Fetch all files in the queue.  If we've already done our job,
# return immediately.  Otherwise keep track of how many files
# are still remaining to be downloaded, and when they are all
# finished, flag downloads completed.
sub queueFetchFiles
{
    my ($self, $q, $job) = @_;
    return if $q->{FAILURE} || $q->{DONE_DOWNLOADS} || $q->{PENDING};

    # Create working directories if necessary
    my $filesdir = "$q->{WORKDIR}/files";
    eval { &mkpath ($filesdir); };
    do { &logmsg ("$@"); return 0 } if $@;

    # Start downloading files that have not been fetched yet
    foreach my $member (@{$q->{MEMBERS}})
    {
	my $pfn = $member->{FILE}{PFN}[0]{PFN};
	my $lfn = $member->{FILE}{LFN}[0];
	if ($self->{DRYRUN})
	{
	    &touch ("$filesdir/$lfn");
	    $q->{DONE_DOWNLOADS} = 1;
	    next;
	}

	$q->{PENDING}++;
	$self->addJob (sub { my ($job) = @_; $q->{PENDING}--;
			     $q->{DONE_DOWNLOADS} = 1 if ! $q->{PENDING};
	    		     $q->{FAILURE} = "exit $job->{STATUS} from @{$job->{CMD}}"
			         if $job->{STATUS} },
	    	       {}, "rfcp", "$pfn", "$filesdir/$lfn");
    }
}

# Verify that all the download files have the expected size; checksum
# is ignored.  Marks queue failed if file size mismatch is detected.
sub queueValidateFiles
{
    my ($self, $q) = @_;
    return if $q->{FAILURE} || $q->{DONE_VALIDATE} || ! $q->{DONE_DOWNLOADS} || $q->{PENDING};

    foreach my $member (@{$q->{MEMBERS}})
    {
	my $local = "$q->{WORKDIR}/files/$member->{FILE}{LFN}[0]";
	return $q->{FAILURE} = "$local: no such file" if ! -f $local;
	return $q->{FAILURE} = "$local: file size mismatch"
	    if (! $self->{DRYRUN} && (-s _ != $member->{FILE}{FILESIZE}));
    }

    $q->{DONE_VALIDATE} = 1;
}

# Produce a merged zip from the input files.
sub queueMergeFiles
{
    my ($self, $q) = @_;
    return if $q->{FAILURE} || $q->{DONE_MERGE} || ! $q->{DONE_VALIDATE} || $q->{PENDING};

    my $time = ($q->{LFN} =~ /(\d+)$/)[0];
    my $filesdir = "$q->{WORKDIR}/files";

    # Generate XML fragment for the archive itself
    my $uuid = qx(uuidgen | tr '[a-f]' '[A-F]'); chomp ($uuid);
    return $q->{FAILURE} = "failed to generate uuid" if ! $uuid;

    my $mainstream = ($q->{STREAM} eq 'MAIN');
    my $owner = ($mainstream ? $q->{OWNER} : "$q->{OWNER}-C-$q->{DATASET}");
    my $dataset = ($mainstream ? $q->{DATASET} : $q->{STREAM});
    my $xmldata = <<EOF;
<File ID="$uuid">
  <physical>
    <pfn filetype="EVDZip" name="\@ZIPPFN\@"/>
  </physical>
  <logical>
    <lfn name="$q->{LFN}"/>
  </logical>
  <metadata att_name="Content" att_value="Zipped$q->{TYPE}"/>
  <metadata att_name="DBoid" att_value=""/>
  <metadata att_name="DataType" att_value="Zipped$q->{TYPE}"/>
  <metadata att_name="FileCategory" att_value="Zipped$q->{CATEGORY}"/>
  <metadata att_name="Flags" att_value=""/>
  <metadata att_name="dataset" att_value="$dataset"/>
  <metadata att_name="jobid" att_value="$time"/>
  <metadata att_name="owner" att_value="$owner"/>
  <metadata att_name="runid" att_value=""/>
</File>
EOF

    # Generate template XML fragment for archive contents
    my $replicas = "";
    foreach my $member (@{$q->{MEMBERS}})
    {
	my $lfn = $member->{FILE}{LFN}[0];
	my $pfn = "zip-member:\@ZIPPFN\@#$lfn";
	$replicas .= "$member->{FILE}{GUID} $pfn\n";

	$xmldata .= "<File ID=\"$member->{FILE}{GUID}\">\n";
	$xmldata .= "  <physical>\n";
	$xmldata .= "    <pfn filetype=\"$member->{FILE}{PFN}[0]{TYPE}\" name=\"$pfn\"/>\n";
	$xmldata .= "  </physical>\n";
	$xmldata .= "  <logical>\n";
	$xmldata .= "    <lfn name=\"$lfn\"/>\n";
	$xmldata .= "  </logical>\n";
	while (my ($attr, $value) = each %{$member->{FILE}{META}})
	{
	    $xmldata .= "  <metadata att_name=\"$attr\" att_value=\"$value\"/>\n";
	}
	$xmldata .= "</File>\n";
    }

    # Output XML fragment
    return $q->{FAILURE} = "failed to write member xml catalog"
        if (! &outputCatalog ("$filesdir/XMLCatFragment.$q->{LFN}.txt", $xmldata));

    # Generate checksum file for archive contents
    return $q->{FAILURE} = "failed to write archive contents checksum"
        if (! &output ("$filesdir/CheckSum.Contents.$q->{LFN}.txt",
		       join ("",
                             map { "$_->{CHECKSUM} $_->{FILESIZE} $_->{LFN}[0]$_\n" }
                             map { $_->{FILE} } @{$q->{MEMBERS}})));

    # Generate replica map template for T1 agents
    return $q->{FAILURE} = "failed to write replica map"
        if (! &output ("$filesdir/ReplicaMap.txt", $replicas));

    # Pack it up
    $q->{PENDING}++;
    $self->addJob (sub { my ($job) = @_; $q->{PENDING}--; $q->{DONE_MERGE} = 1;
			 $q->{FAILURE} = "failed to generate the zip archive:"
			     . " exit $job->{STATUS} from @{$job->{CMD}}"
			     if $job->{STATUS} }, {},
		   "zip", "-q", "-0", "-r", "-j", "$q->{WORKDIR}/$q->{LFN}.zip", $filesdir);
}

# Checksum the merged zip.
sub queueChecksum
{
    my ($self, $q) = @_;
    return if $q->{FAILURE} || $q->{DONE_CHECKSUM} || ! $q->{DONE_MERGE} || $q->{PENDING};

    # Generate checksum for the archive for transfer
    $q->{PENDING}++;
    $self->addJob (sub { my ($job) = @_; $q->{PENDING}--; $q->{DONE_CHECKSUM} = 1;
			 $q->{FAILURE} = "failed to write archive checksum:"
			     . " exit $job->{STATUS} from @{$job->{CMD}}"
			     if $job->{STATUS} }, {},
		   "sh", "-c", "cd $q->{WORKDIR} && cksum $q->{LFN}.zip > CheckSum.$q->{LFN}.txt");

    # return $q->{FAILURE} = "failed to write archive checksum"
    #     if (! &output ("$q->{WORKDIR}/CheckSum.$q->{LFN}.txt",
    #                    "-1 " . (-s "$q->{WORKDIR}/$q->{LFN}.zip") . " $q->{LFN}.zip\n"));
}

# Store the merged zip back into storage buffer.
sub queueStore
{
    my ($self, $q) = @_;
    return if $q->{FAILURE} || $q->{DONE_STORE} || ! $q->{DONE_CHECKSUM} || $q->{PENDING};

    my $storeddir = $self->{OUTPUT};
    my $stored = $storeddir && "$storeddir/$q->{LFN}.zip";

    # Store back into mass storage
    if (! $self->{DRYRUN} && $self->{OUTPUT})
    {
        # Check output destination doesn't already exist.
        return $q->{FAILURE} = "destination zip already exists: $stored"
            if &rfstatmode ($stored);

	# Create destination directories if necessary.
	return $q->{FAILURE} = "failed to create target rfio directory $storeddir"
            if ! &rfmkpath ($storeddir);

	# Initiate the copy
	$q->{PENDING}++;
        $q->{CLEANUP} = $stored;
	$self->addJob (sub { my ($job) = @_; $q->{PENDING}--; $q->{DONE_STORE} = 1;
		       $q->{FAILURE} = "failed to store archive to $stored:"
			   . " exit $job->{STATUS} from @{$job->{CMD}}"
			   if $job->{STATUS} }, {},
		       "rfcp", "$q->{WORKDIR}/$q->{LFN}.zip", $stored);
    }
    else
    {
	$q->{DONE_STORE} = 1;
    }
}

# Move information about the merged zip to the next agent
# in processing line
sub queueFinish
{
    my ($self, $q) = @_;
    return if $q->{FAILURE} || $q->{DONE_FINISH} || ! $q->{DONE_STORE} || $q->{PENDING};

    # Make XML fragment concrete for the drop
    my $xml = &input ("$q->{WORKDIR}/files/XMLCatFragment.$q->{LFN}.txt");
    my $replacement = ($self->{OUTPUT} ? "$self->{OUTPUT}/" : "") . "$q->{LFN}.zip";
    $xml =~ s/\@ZIPPFN\@/$replacement/g;
    return $q->{FAILURE} = "failed to write archive xml catalog"
        if (! $xml || ! &output ("$q->{WORKDIR}/XMLCatFragment.$q->{LFN}.txt", $xml));

    # Make a drop of this down the chain
    return $q->{FAILURE} = "failed to mark job done"
	if ! &touch ("$q->{WORKDIR}/done");

    &rmtree ([ "$q->{WORKDIR}/$q->{LFN}.zip", "$q->{WORKDIR}/files" ]);

    return $q->{FAILURE} = "failed to move queue to outbox"
	if ! &mv ("$q->{WORKDIR}", "$self->{OUTDIR}/$q->{LFN}");

    $q->{DONE_FINISH} = 1;
}

# Remove original input files from storage buffer if so requested.
sub queueRemoveOrig
{
    my ($self, $q) = @_;
    return if $q->{FAILURE} || $q->{DONE_REMOVE} || ! $q->{DONE_FINISH} || $q->{PENDING};

    # Remove original members
    if (! $self->{DRYRUN} && $self->{OUTPUT} && $self->{CLEAN})
    {
	foreach my $pfn (map { $_->{FILE}{PFN}[0]{PFN} } @{$q->{MEMBERS}})
	{
	    for (my $j = 0; $j < 10; ++$j)
       	    {
    		last if &rfrm ($pfn);
    		&alert ("attempting to remove $pfn again");
    		sleep (10);
	    }
        }
    }

    $q->{DONE_REMOVE} = 1;
    $q->{DONE_ALL} = 1;
}

1;
