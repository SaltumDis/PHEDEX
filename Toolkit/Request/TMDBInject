#!/usr/bin/env perl

##H Inject files into TMDB, overall much like DropTMDBPublisher.  The
##H main differences are that this utility processes only one set of
##H data at a time, adds only previously unknown files, and commits
##H each file at a time.
##H
##H The command must be given an XML catalogue file, a checksum file,
##H and either the list of nodes to add a replica for each file, or
##H a list of "site names" and a mapping of site names to node names.
##H Files and replicas previously unknown are added to the database;
##H previously known ones are simply skipped.  No file destinations
##H or subscriptions are added.
##H
##H If the program crashes or is terminated, it is always safe to
##H run again with the same arguments.
##H
##H Usage:
##H   TMDBInject
##H      -catalogue FILE -cksums FILE
##H      { -nodes NODE[,NODE...] | -sitemap FILE -sites SITE[,SITE...] }
##H      -db FILE[:SECTION]
##H
##H -catalogue xml catalogue file
##H -cksums    checksum file, one entry per each LFN in XML catalogue
##H -nodes     comma-separated list of nodes to add replicas for
##H -sitemap   a file with "site-name = node-name" mappings
##H -site      comma-separated list of sites to add replicas for; requires -sitemap
##H -db        database connection configuration parameter file

BEGIN {
  use strict; use warnings;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../../Toolkit/Common";
  unshift(@INC, $home);
}

######################################################################
use UtilsHelp;
my %args;
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-db' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBCONFIG} = shift(@ARGV); }

    elsif ($ARGV[0] eq '-nodes' && scalar @ARGV > 1)
    { shift (@ARGV); push(@{$args{NODES}}, split(',', shift(@ARGV))); }
    elsif ($ARGV[0] eq '-sites' && scalar @ARGV > 1)
    { shift (@ARGV); push(@{$args{SITES}}, split(/[,\s]+/, shift(@ARGV))); }
    elsif ($ARGV[0] eq '-sitemap' && scalar @ARGV > 1)
    { shift (@ARGV); $args{SITEMAP} = shift (@ARGV); }
    elsif ($ARGV[0] eq '-catalogue' && scalar @ARGV > 1)
    { shift (@ARGV); $args{CATALOGUE} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-cksums' && scalar @ARGV > 1)
    { shift (@ARGV); $args{CKSUMS} = shift(@ARGV); }

    elsif ($ARGV[0] eq '-verbose')
    { shift (@ARGV); $args{VERBOSE} = 1; }
    elsif ($ARGV[0] eq '-h')
    { &usage(); }
    else
    { last; }
}
	
if (@ARGV || !$args{DBCONFIG} || !$args{CATALOGUE} || !$args{CKSUMS}
    || !($args{NODES} || ($args{SITES} && $args{SITEMAP})))
{
    die "Insufficient parameters, use -h for help.\n";
}

# If we got a site specification, map the nodes to site `
if ($args{SITES})
{
    # Read site mappings
    my %sitemap = ();
    open(S, "< $args{SITEMAP}") || die "$args{SITEMAP}: cannot read: $!\n";
    while (<S>)
    {
	chomp; s/#.*//; s/^\s+//; s/\s+$//; next if /^$/;
	die "$args{SITEMAP}: $.: unrecognised line\n"
	     if !  /^\s*(\S+)\s*=\s*(\S+)?\s*$/;
	$sitemap{$1} = $2;
    }
    close (S);

    # Map sites to nodes
    foreach my $site (@{$args{SITES}})
    {
	if (! exists $sitemap{$site}) {
	    die "no mapping for site $site\n";
	} elsif (! $sitemap{$site}) {
	    warn "ignoring site $site, no mapping to node\n";
	} else {
	    print "mapping site $site to node $sitemap{$site}\n" if $args{VERBOSE};
	    push(@{$args{NODES}}, $sitemap{$site});
	}
    }

    die "no node mappings created from site list @{$args{SITES}}\n"
	if ! @{$args{NODES}};
}

# Ensure catalogue and checksum files exist and are readable
-r $args{CATALOGUE} || die "$args{CATALOGUE}: cannot read: $!\n";
-r $args{CKSUMS} || die "$args{CKSUMS}: cannot read: $!\n";

######################################################################
use UtilsCommand;
use UtilsReaders;
use UtilsTiming;
use UtilsDB;

# Read in the inputs
print "Reading catalogue $args{CATALOGUE}\n" if $args{VERBOSE};
my $catalogue = eval { &readXMLCatalogue ($args{CATALOGUE}) };

print "Reading checksums $args{CKSUMS}\n" if $args{VERBOSE};
my @cksums = eval { &readChecksumData ($args{CKSUMS}) };

print "Checking data consistency\n" if $args{VERBOSE};
my $bad = 0;
foreach my $file (@$catalogue)
{
    my $lfn = $file->{LFN}[0];
    my $cksum = (grep ($_->[2] eq $lfn, @cksums))[0];

    if (! $cksum)
    {
	print STDERR "$lfn: no checksum\n";
	$bad = 1;
	next;
    }

    print STDERR "$lfn: zero-size file\n" if ! $cksum->[1];
    $file->{CHECKSUM} = $cksum->[0];
    $file->{FILESIZE} = $cksum->[1];
}
exit 1 if $bad;

# Now update database
print "Connecting to database\n" if $args{VERBOSE};
my $dbh = &connectToDatabase (\%args, 0);
my $now = &mytimeofday ();

print "Processing @{[scalar @$catalogue]} files " if $args{VERBOSE};
my $isfstmt = &dbprep ($dbh, qq{
    select guid from t_file
    where guid = :guid});
my $isrstmt = &dbprep ($dbh, qq{
    select guid from t_replica_state
    where guid = :guid and node = :node});
my $isbstmt = &dbprep ($dbh, qq{
    select name from t_block
    where name = :block});

my $fstmt = &dbprep ($dbh, qq{
    insert into t_file
    (timestamp, guid, node, inblock, insubblock,
     lfn, filetype, filesize, checksum)
    values (:now, :guid, :node, :inblock, :insubblock,
     :lfn, :filetype, :filesize, :checksum)});
my $rstmt = &dbprep ($dbh, qq{
    insert into t_replica_state (timestamp, guid, node, state, state_timestamp)
    values (:now, :guid, :node, 0, :now)});
my $mstmt = &dbprep ($dbh, qq{
    insert into t_file_attributes (guid, attribute, value)
    values (:guid, :attr, :value)});
my $bistmt = &dbprep ($dbh, qq{
    insert into t_block (name, owner, dataset, files, bytes)
    values (:name, :owner, :dataset, 0, 0)});
my $bistmt2 = ($args{DBSECTION} eq 'RAC') && &dbprep ($dbh, qq{
    insert into t_block (timestamp, name, owner, dataset, files, bytes, isopen)
    values (:now, :name, :owner, :dataset, 0, 0, 1)});

foreach my $f (@$catalogue)
{
    # Print some dots, skip non-existent files
    if ($f->{FILESIZE} == -1)
    {
	do { local $| = 1; print ":" } if $args{VERBOSE};
	next;
    }
    do { local $| = 1; print "." } if $args{VERBOSE};

    # Check the file block is known, otherwise create an open one
    my $block = "$f->{META}{owner}/$f->{META}{dataset}";
    &dbbindexec ($isbstmt, ":block" => $block);
    my ($found) = $isbstmt->fetchrow();
    $isbstmt->finish();

    &dbbindexec (($bistmt2 ? ($bistmt2, ":now" => $now) : ($bistmt)),
		 ":name" => $block,
		 ":owner" => $f->{META}{owner},
		 ":dataset" => $f->{META}{dataset})
	if ! $found;
    $dbh->commit();

    # Check if the file is known, otherwise insert new entry
    &dbbindexec ($isfstmt, ":guid" => $f->{GUID});
    ($found) = $isfstmt->fetchrow();
    $isfstmt->finish();

    &dbbindexec ($fstmt,
	         ":now" => $now,
		 ":guid" => $f->{GUID},
	         ":node" => $args{NODES}[0],
		 ":inblock" => "$f->{META}{owner}/$f->{META}{dataset}",
		 ":insubblock" => "$f->{META}{jobid}",
		 ":lfn" => $f->{LFN}[0],
		 ":filetype" => $f->{PFN}[0]{TYPE},
		 ":filesize" => $f->{FILESIZE},
	 	 ":checksum" => $f->{CHECKSUM})
	 if ! $found;

    # Insert file attribute data, again only if file not yet known
    my %meta = (map { "POOL_".$_ => $f->{META}{$_} } keys %{$f->{META}});
    foreach my $m (sort keys %meta)
    {
        &dbbindexec ($mstmt,
		     ":guid" => $f->{GUID},
		     ":attr" => $m,
		     ":value" => $meta{$m})
	     if ! $found;
    }
    $dbh->commit();

    # Insert replica for all nodes where we don't have one yet
    foreach my $n (@{$args{NODES}})
    {
	&dbbindexec ($isrstmt, ":guid" => $f->{GUID}, ":node" => $n);
	($found) = $isrstmt->fetchrow();
	$isrstmt->finish();

        &dbbindexec ($rstmt, 
    	             ":now" => $now,
		     ":guid" => $f->{GUID},
		     ":node" => $n)
	     if ! $found;
    }

    $dbh->commit();
}
print "\n" if $args{VERBOSE};

$dbh->disconnect ();
undef $dbh;
exit 0;
