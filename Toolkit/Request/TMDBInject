#!/usr/bin/env perl

##H Inject files into TMDB, overall much like DropTMDBPublisher.  The
##H main differences are that this utility processes only one set of
##H data at a time, adds only previously unknown files, and commits
##H each file at a time.
##H
##H The command must be given an XML catalogue file, a checksum file,
##H and either the list of nodes to add a replica for each file, or
##H a list of "site names" and a mapping of site names to node names.
##H Files and replicas previously unknown are added to the database;
##H previously known ones are simply skipped.  No file destinations
##H or subscriptions are added.
##H
##H If the program crashes or is terminated, it is always safe to
##H run again with the same arguments.
##H
##H Usage:
##H   TMDBInject
##H      -catalogue FILE -cksums FILE
##H      { -nodes NODE[,NODE...] | -sitemap FILE -sites SITE[,SITE...] }
##H      -db FILE[:SECTION] [-strict]
##H
##H -catalogue xml catalogue file
##H -cksums    checksum file, one entry per each LFN in XML catalogue
##H -nodes     comma-separated list of nodes to add replicas for
##H -sitemap   a file with "site-name = node-name" mappings
##H -site      comma-separated list of sites to add replicas for; requires -sitemap
##H -db        database connection configuration parameter file
##H -strict    don't allow file or its replicas to already exist

BEGIN {
  use strict; use warnings; $^W=1;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../../Toolkit/Common";
  unshift(@INC, $home);
}

######################################################################
my %args;
use Getopt::Long;
use UtilsHelp;
&GetOptions ("db=s"        => \$args{DBCONFIG},
	     "nodes=s"     => sub { push(@{$args{NODES}}, split(/,/, $_[1])) },
	     "sites=s"     => sub { push(@{$args{SITES}}, split(/,/, $_[1])) },
             "sitemap=s"   => \$args{SITEMAP},
             "catalogue=s" => \$args{CATALOGUE},
             "cksums=s"    => \$args{CKSUMS},
             "strict"      => \$args{STRICT},
             "verbose"     => \$args{VERBOSE},
	     "help|h"      => sub { &usage() });

if (@ARGV || !$args{DBCONFIG} || !$args{CATALOGUE} || !$args{CKSUMS}
    || !($args{NODES} || ($args{SITES} && $args{SITEMAP})))
{
    die "Insufficient parameters, use -h for help.\n";
}

# If we got a site specification, map the nodes to site `
if ($args{SITES})
{
    # Read site mappings
    my %sitemap = ();
    open(S, "< $args{SITEMAP}") || die "$args{SITEMAP}: cannot read: $!\n";
    while (<S>)
    {
	chomp; s/#.*//; s/^\s+//; s/\s+$//; next if /^$/;
	die "$args{SITEMAP}: $.: unrecognised line\n"
	     if !  /^\s*(\S+)\s*=\s*(\S+)?\s*$/;
	$sitemap{$1} = $2;
    }
    close (S);

    # Map sites to nodes
    foreach my $site (@{$args{SITES}})
    {
	if (! exists $sitemap{$site}) {
	    die "no mapping for site $site\n";
	} elsif (! $sitemap{$site}) {
	    warn "ignoring site $site, no mapping to node\n";
	} else {
	    print "mapping site $site to node $sitemap{$site}\n" if $args{VERBOSE};
	    push(@{$args{NODES}}, $sitemap{$site});
	}
    }

    die "no node mappings created from site list @{$args{SITES}}\n"
	if ! @{$args{NODES}};
}

# Ensure catalogue and checksum files exist and are readable
-r $args{CATALOGUE} || die "$args{CATALOGUE}: cannot read: $!\n";
-r $args{CKSUMS} || die "$args{CKSUMS}: cannot read: $!\n";

######################################################################
use UtilsCommand;
use UtilsReaders;
use UtilsTiming;
use UtilsDB;

# Read in the inputs
print "Reading catalogue $args{CATALOGUE}\n" if $args{VERBOSE};
my $catalogue = eval { &readXMLCatalogue ($args{CATALOGUE}) };

print "Reading checksums $args{CKSUMS}\n" if $args{VERBOSE};
my %cksums = eval { map { $_->[2] => $_ } &readChecksumData ($args{CKSUMS}) };

print "Checking data consistency\n" if $args{VERBOSE};
my $bad = 0;
foreach my $file (@$catalogue)
{
    my $lfn = $file->{LFN}[0];
    my $cksum = $cksums{$lfn};

    if (! $cksum)
    {
	print STDERR "$lfn: no checksum\n";
	$bad = 1;
	next;
    }

    print STDERR "$lfn: zero-size file\n" if ! $cksum->[1];
    $file->{CHECKSUM} = $cksum->[0];
    $file->{FILESIZE} = $cksum->[1];
}
exit 1 if $bad;

# Connect to database for update
print "Connecting to database\n" if $args{VERBOSE};
my $dbh = &connectToDatabase (\%args, 0);
my $now = &mytimeofday ();
my %seen = ();

# Preprocess all the blocks we are going to touch.  Find out which
# blocks already exist, and for those that exist, which files exist.
print "Processing @{[scalar @$catalogue]} files " if $args{VERBOSE};
my %blockdata = ();
foreach my $f (@$catalogue)
{
    my $block = "$f->{META}{owner}/$f->{META}{dataset}";
    next if exists $blockdata{$block};
    my $b = $blockdata{$block} = {
	EXISTS => 0, ISOPEN => 0, GUIDS => {}, REPLICAS => {} };

    do { local $| = 1; print "[B" } if $args{VERBOSE};
    my $qblock = &dbexec ($dbh, qq{
	select name, isopen from t_block where name = :block},
	":block" => $block);
    ($b->{EXISTS}, $b->{ISOPEN}) = $qblock->fetchrow();

    do { local $| = 1; print "F" } if $args{VERBOSE};
    my $qfiles = &dbexec ($dbh, qq{
	select guid from t_file where inblock = :block},
	":block" => $block);
    while (my ($guid) = $qfiles->fetchrow()) {
	$b->{GUIDS}{$guid} = 1;
    }

    do { local $| = 1; print "R" } if $args{VERBOSE};
    my $qreplicas = &dbexec ($dbh, qq{
	select rs.node, rs.guid
	from t_replica_state rs
	join t_file f on f.guid = rs.guid
	where f.inblock = :block},
	":block" => $block);
    while (my ($node, $guid) = $qreplicas->fetchrow())
    {
	$b->{REPLICAS}{$node}{$guid} = 1;
    }

    do { local $| = 1; print "]" } if $args{VERBOSE};
}

# Get existing files and replicas
my %sqlargs = ();
my %blockupd = ();
my $fstmt = &dbprep ($dbh, qq{
    insert into t_file
    (timestamp, guid, node, inblock, insubblock,
     lfn, filetype, filesize, checksum)
    values (?, ?, ?, ?, ?, ?, ?, ?, ?)});
my $rstmt = &dbprep ($dbh, qq{
    insert into t_replica_state (timestamp, guid, node, state, state_timestamp)
    values (?, ?, ?, 0, ?)});
my $mstmt = &dbprep ($dbh, qq{
    insert into t_file_attributes (guid, attribute, value)
    values (?, ?, ?)});
my $blstmt = &dbprep ($dbh, qq{
    select * from t_block where name = :name for update});
my $bistmt = &dbprep ($dbh, qq{
    insert into t_block (timestamp, name, owner, dataset, files, bytes, isopen)
    values (?, ?, ?, ?, 0, 0, 1)});
my $bustmt = &dbprep ($dbh, qq{
    update t_block
    set files = files + :files, bytes = bytes + :bytes
    where name = :block});

foreach my $f (@$catalogue)
{
    # Print some dots, skip non-existent files
    if ($f->{FILESIZE} == -1)
    {
	do { local $| = 1; print ":" } if $args{VERBOSE};
	next;
    }

    # Add block if it doesn't exist yet, otherwise lock existing one.
    my $block = "$f->{META}{owner}/$f->{META}{dataset}";
    if (! $blockdata{$block}{EXISTS})
    {
	push (@{$sqlargs{$bistmt}{1}}, $now);
	push (@{$sqlargs{$bistmt}{2}}, $block);
	push (@{$sqlargs{$bistmt}{3}}, $f->{META}{owner});
	push (@{$sqlargs{$bistmt}{4}}, $f->{META}{dataset});
        $blockdata{$block}{EXISTS} = 1;
        $blockdata{$block}{ISOPEN} = 1;
    }
    else
    {
        # Block exists, lock it
        &dbbindexec ($blstmt, ":name" => $block);
        $blstmt->finish();
    }

    # If the file isn't yet in the block, add it.  Require the
    # block to be open for this.  Note that this just pushes the
    # file to the list of things to add; we commit everything in
    # one big array operation at the end.
    if (! exists $blockdata{$block}{GUIDS}{$f->{GUID}})
    {
	die "block $block not open, cannot add files\n"
	    if ! $blockdata{$block}{ISOPEN};

        do { local $| = 1; print "." } if $args{VERBOSE};
	$blockupd{$block} ||= { FILES => 0, BYTES => 0 };
	$blockupd{$block}{FILES}++;
	$blockupd{$block}{BYTES} += $f->{FILESIZE};

	push (@{$sqlargs{$fstmt}{1}}, $now);
	push (@{$sqlargs{$fstmt}{2}}, $f->{GUID});
	push (@{$sqlargs{$fstmt}{3}}, $args{NODES}[0]);
	push (@{$sqlargs{$fstmt}{4}}, $block);
	push (@{$sqlargs{$fstmt}{5}}, "$f->{META}{jobid}");
	push (@{$sqlargs{$fstmt}{6}}, $f->{LFN}[0]);
	push (@{$sqlargs{$fstmt}{7}}, $f->{PFN}[0]{TYPE});
	push (@{$sqlargs{$fstmt}{8}}, $f->{FILESIZE});
	push (@{$sqlargs{$fstmt}{9}}, $f->{CHECKSUM});

        my %meta = (map { "POOL_".$_ => $f->{META}{$_} } keys %{$f->{META}});
        foreach my $m (sort keys %meta)
        {
	    push (@{$sqlargs{$mstmt}{1}}, $f->{GUID});
	    push (@{$sqlargs{$mstmt}{2}}, $m);
	    push (@{$sqlargs{$mstmt}{3}}, $meta{$m});
        }
    }
    else
    {
	die "file $f->{GUID} already exists\n" if $args{STRICT};
        do { local $| = 1; print "/" } if $args{VERBOSE};
    }

    # Insert replicas; again ignore duplicate errors.
    foreach my $n (@{$args{NODES}})
    {
	if (exists $blockdata{$block}{REPLICAS}{$n}{$f->{GUID}})
	{
	    die "file replica for $f->{GUID} at $n already exists\n"
	        if $args{STRICT};
	    next;
	}
	push (@{$sqlargs{$rstmt}{1}}, $now);
	push (@{$sqlargs{$rstmt}{2}}, $f->{GUID});
	push (@{$sqlargs{$rstmt}{3}}, $n);
	push (@{$sqlargs{$rstmt}{4}}, $now);
    }
}

foreach my $stmt ('B', $bistmt, 'F', $fstmt, 'A', $mstmt, 'R', $rstmt)
{
    if (! ref $stmt)
    {
        do { local $| = 1; print $stmt } if $args{VERBOSE};
	next;
    }

    next if ! keys %{$sqlargs{$stmt}};
    do { local $| = 1; print ">" } if $args{VERBOSE};
    foreach my $k (keys %{$sqlargs{$stmt}}) {
        $stmt->bind_param_array ($k, $sqlargs{$stmt}{$k});
    }
    $stmt->execute_array ({ ArrayTupleResult => []});
}

foreach my $block (keys %blockupd)
{
    &dbbindexec ($bustmt,
	         ":block" => $block,
	         ":files" => $blockupd{$block}{FILES},
		 ":bytes" => $blockupd{$block}{BYTES});
}

$dbh->commit();
print "\n" if $args{VERBOSE};

$dbh->disconnect ();
undef $dbh;
exit 0;
