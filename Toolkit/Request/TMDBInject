#!/usr/bin/env perl

##H Inject files into TMDB.  By default this commits only previoulsy
##H unknown files; known files are skipped.  However in strict mode
##H all files are required to be new to TMDB.
##H
##H The command must be given a XML file that describes the files to
##H add, plus a list of PhEDEx nodes that will get a replica for each
##H file added.  The files are simply made known to TMDB without any
##H any addition of subscriptions or other destination definitions.
##H
##H If the program crashes or is terminated, it is always safe to
##H run again with the same arguments.
##H
##H Usage:
##H   TMDBInject -db FILE[:SECTION] [-strict] [-verbose]
##H     { -nodes NODE[,NODE...] | -storage-elements SE[,SE...] }
##H     -filedata XMLFILE
##H
##H -db                database connection configuration parameter file
##H -strict            don't allow file or its replicas to already exist
##H -verbose           print progress indicators for injection stages
##H -nodes             comma-separated list of nodes to add replicas for
##H -storage-elements  comma-separated list of storage-elements to add
##H                      replicas for; each element will be mapped to
##H                      nodes as recorded in the database
##H -filedata          description of files to add
##H
##H The argument to "-filedata" must be an XML file.  It must contain
##H a top-level "<dbs>" element, which should contain any number of
##H "<dataset>" elements, containing any number of "<block>" elements
##H containing "<file>" elements.
##H
##H The XML file may identify the each dataset and block many times.
##H The union of all files of each block are added to the database.
##H However in the end each file must belong to exactly one DBS,
##H dataset and block.
##H
##H The "<dbs>" element must have an attribute "name", which is the
##H canonical name of the dataset bookkeeping system which owns the
##H files.  Usually this should be the contact address of the DBS.
##H
##H The "<dataset>" element must have an attribute "name", the name
##H of the dataset in the DBS, and two boolean attributes, "is-open"
##H and "is-transient", both which must have value 'y' or 'n'.  The
##H options are checked before processing and new values are applied
##H at the end of the processing, allowing datasets and blocks to be
##H closed by injecting them with these attributes set, possibly not
##H including any files in the injection.
##H
##H A dataset must be open if any of its blocks are open.  Only open
##H datasets can have blocks added to them; similarly with blocks and
##H files.  Closed blocks and datasets cannot be made open with this
##H utility.  If the dataset is marked transient and is closed (and
##H thus all its blocks are closed), and all transfer requests on it
##H have been fulfilled, knowledge about the dataset is removed from
##H the TMDB.  (Typically datasets are known to be transient from the
##H transfer point of view at the time they are first created.)
##H 
##H Each "<block>" must have attribute "name", the canonical and
##H unique name of the block as known the "<dbs>", and "is-open"
##H boolean, either 'y' or 'n'.  If "is-open" is 'n', the block will
##H be marked closed at the end of the processing; this still allows
##H one to add files to new and previously open blocks, then close
##H the blocks.  If the block is already closed in the database, new
##H files cannot be added to it; setting "is-open" to 'y' won't help.
##H New blocks cannot be introduced to closed datasets.  If the
##H dataset is closed, all its blocks must be closed too.
##H
##H Each "<file>" must have attributes "lfn", the logical file name
##H which must be unique, "size", the size of the file in bytes, and
##H "checksum", the cksum checksum of the file data.
##H
##H All elements may contain other attributes; they will be ignored.
##H Only white-space character data is allowed; only information from
##H the attributes of the above elements are added.
##H
##H Example:
##H   <dbs name="http://cmsdoc.cern.ch/cms/aprom/DBS/CGIServer/query">
##H     <dataset name="/sample/dataset" is-open="y" is-transient="n">
##H       <block name="/sample/dataset#1" is-open="y">
##H         <file lfn="file1" size="10" checksum="cksum:1234"/>
##H         <file lfn="file2" size="22" checksum="cksum:456"/>
##H       </block>
##H       <block name="/sample/dataset#2" is-open="y">
##H         <file lfn="file3" size="1" checksum="cksum:2"/>
##H       </block>
##H     </dataset>
##H     <dataset name="/sample/dataset2" is-open="n" is-transient="n">
##H       <block name="/sample/dataset2#1" is-open="n"/>
##H       <block name="/sample/dataset2#2" is-open="n"/>
##H     </dataset>
##H   </dbs>

######################################################################
my ($verbose, $strict, %args);
use Getopt::Long;
use PHEDEX::Core::Help;
&GetOptions ("db=s"                => \$args{DBCONFIG},
             "strict"              => \$strict,
             "verbose"             => \$verbose,
             "filedata=s"          => \$args{FILEDATA},
	     "nodes=s"             => sub { push(@{$args{NODES}}, split(/,/, $_[1])) },
	     "storage-elements=s"  => sub { push(@{$args{SES}}, split(/,/, $_[1])) },
	     "help|h"              => sub { &usage() });

if (@ARGV || !$args{DBCONFIG} || !$args{FILEDATA}
    || (!$args{NODES} && !$args{SES}))
{
    die "Insufficient parameters, use -h for help.\n";
}

# Ensure file data is readable
-r $args{FILEDATA} || die "$args{FILEDATA}: cannot read: $!\n";

######################################################################
use XML::Parser;
use PHEDEX::Core::Timing;
use PHEDEX::Core::DB;

sub fetchall
{
    my ($dbh, $table) = @_;
    return &dbexec($dbh, qq{select * from t_$table})
        ->fetchall_arrayref({});
}

sub getone
{
    my ($dbh, $table, %id) = @_;
    my @names = keys %id;
    my $params = join(" and ", map { "$_ = :attr_$_" } @names);
    my ($obj) = @{&dbexec($dbh, qq{select * from t_$table where $params},
        map { (":attr_$_" => $id{$_} ) } @names)->fetchall_arrayref({})};
    return $obj;
}

sub lockone
{
    my ($dbh, $table, %id) = @_;
    my @names = keys %id;
    my $params = join(" and ", map { "$_ = :attr_$_" } @names);
    my ($obj) = @{&dbexec($dbh, qq{select * from t_$table where $params for update},
        map { (":attr_$_" => $id{$_} ) } @names)->fetchall_arrayref({})};
    return $obj;
}

# Connect to database for update
print "Connecting to database\n" if $verbose;
my $dbh = &connectToDatabase (\%args, 0);
$$dbh{FetchHashKeyName} = "NAME_uc";

# Read in the inputs
print "Reading file information from $args{FILEDATA}\n" if $verbose;
my $info = (new XML::Parser (Style => "Tree"))->parsefile ($args{FILEDATA});

# Fetch known DBSes, datasets and blocks.
my $now = &mytimeofday();
my $all_nodes = &fetchall($dbh, "adm_node");
my $all_dbs = [];
my $all_dataset = [];
my $all_block = [];

# Produce a node list.
my @nodes;

if ($args{SES})
{
    # Map storage elements to nodes.  If we have a choice of more than
    # one, discard tape nodes, but only if that leaves at least one
    # node.  If we have only tape nodes to match, keep them.
    # T0 is a special case. We only accept injection here, if we are told
    # explicitly by supplying a node name.
    foreach my $name (@{$args{SES}})
    {
        my @match = grep(defined $$_{SE_NAME}
			 && $$_{SE_NAME} eq $name, @$all_nodes);
	die "storage element $name not known to the database\n"
	    if ! @match;
	if (scalar @match > 1)
	{
	    my @notape = grep($$_{KIND} ne 'MSS'
			      && $$_{NAME} ne 'T0_CERN_Export', @match);
	    @match = @notape if @notape;
	}

	push(@nodes, @match);
	print "storage element $name mapped to @{[ map { $$_{NAME} } @match ]}\n"
	     if $verbose;
    }
}
else
{
    # Check all nodes are known
    foreach my $node (@{$args{NODES}})
    {
	my @match = grep($$_{NAME} eq $node, @$all_nodes);
        die "Node $node not known\n" if ! @match;
	push(@nodes, @match);
    }
}

# Process the file data content.
while (@$info)
{
    my ($tag, $val) = splice(@$info, 0, 2);
    
    # Skip leading white space, and find next <dbs> element.
    next if ($tag eq '0' && $val =~ /^\s+$/so);
    die "$args{FILEDATA}: unexpected character data\n" if $tag eq '0';
    die "$args{FILEDATA}: expected <dbs> entry, found <$tag>\n"
	if $tag ne 'dbs';

    my ($dbsattrs, @dbscontent) = @$val;
    die "$args{FILEDATA}: <dbs name=''> attribute missing or empty\n"
	if ! defined $$dbsattrs{'name'} || $$dbsattrs{'name'} eq '';

    # Create the dbs
    my ($dbs) = grep ($$_{NAME} eq $$dbsattrs{'name'}, @$all_dbs);
    if (! $dbs)
    {
        $dbs = &getone($dbh, "dps_dbs", "name" => $$dbsattrs{'name'});
    }
    if (! $dbs)
    {
	push(@$all_dbs, $dbs = { ID => undef, NAME => $$dbsattrs{'name'},
				 DLS => $$dbsattrs{'dls'}});
	&dbexec ($dbh, qq{
	    insert into t_dps_dbs (id, name, dls, time_create)
	    values (seq_dps_dbs.nextval, :name, :dls, :now)
	    returning id into :id},
	    ":name" => $$dbs{NAME}, ":dls" => $$dbs{DLS},
	    ":id" => \$$dbs{ID}, ":now" => $now);
    }

    # Now process all datasets inside this dbs
    print "Processing dbs $$dbs{NAME} ($$dbs{ID})\n" if $verbose;
    while (@dbscontent)
    {
	($tag, $val) = splice(@dbscontent, 0, 2);
    
	# Skip leading white space, and find next <dbs> element.
	next if ($tag eq '0' && $val =~ /^\s+$/so);
	die "$args{FILEDATA}: unexpected character data\n" if $tag eq '0';
	die "$args{FILEDATA}: expected <dataset> entry, found <$tag>\n"
	    if $tag ne 'dataset';

	my ($dsattrs, @dscontent) = @$val;
	die "$args{FILEDATA}: <dataset name=''> attribute missing or empty\n"
	    if ! defined $$dsattrs{'name'} || $$dsattrs{'name'} eq '';
	die "$args{FILEDATA}: <dataset is-open=''> attribute missing or empty\n"
	    if ! defined $$dsattrs{'is-open'} || $$dsattrs{'is-open'} eq '';
	die "$args{FILEDATA}: <dataset is-transient=''> attribute missing or empty\n"
	    if ! defined $$dsattrs{'is-transient'} || $$dsattrs{'is-transient'} eq '';

	# Create the dataset
	my ($ds) = grep ($$_{DBS} eq $$dbs{ID} && $$_{NAME} eq $$dsattrs{'name'}, @$all_dataset);
	if (! $ds)
	{
	    $ds = &getone($dbh, "dps_dataset",
		    	  "dbs" => $$dbs{ID},
		    	  "name" => $$dsattrs{'name'});
	}
	if (! $ds)
	{
	    push(@$all_dataset, $ds = { ID => undef,
					DBS => $$dbs{ID},
					NAME => $$dsattrs{'name'},
					IS_OPEN => 'y',
					IS_OPEN_REALLY => $$dsattrs{'is-open'},
					IS_TRANSIENT => $$dsattrs{'is-transient'} });
	    &dbexec ($dbh, qq{
	        insert into t_dps_dataset (id, dbs, name, is_open, is_transient, time_create)
	        values (seq_dps_dataset.nextval, :dbs, :name, 'y', :transient, :now)
	        returning id into :id},
		":id" => \$$ds{ID},
		":dbs" => $$dbs{ID},
		":name" => $$ds{NAME},
		":transient" => $$ds{IS_TRANSIENT},
		":now" => $now);
	}
	else
	{
	    $$ds{IS_OPEN_REALLY} = $$dsattrs{'is-open'};
	}

	# Now the blocks...
	print " Processing dataset $$ds{NAME} ($$ds{ID})\n" if $verbose;
	while (@dscontent)
	{
	    ($tag, $val) = splice(@dscontent, 0, 2);
    
	    # Skip leading white space, and find next <dbs> element.
	    next if ($tag eq '0' && $val =~ /^\s+$/so);
	    die "$args{FILEDATA}: unexpected character data\n" if $tag eq '0';
	    die "$args{FILEDATA}: expected <block> entry, found <$tag>\n"
		if $tag ne 'block';

	    my ($battrs, @bcontent) = @$val;
	    die "$args{FILEDATA}: <block name=''> attribute missing or empty\n"
		if ! defined $$battrs{'name'} || $$battrs{'name'} eq '';
	    die "$args{FILEDATA}: <block is-open=''> attribute missing or empty\n"
		if ! defined $$battrs{'is-open'} || $$battrs{'is-open'} eq '';

	    # Create the dataset
	    my ($b) = grep ($$_{DATASET} == $$ds{ID} && $$_{NAME} eq $$battrs{'name'}, @$all_block);
	    if (! $b)
	    {
	        $b = &lockone($dbh, "dps_block",
		    	      "dataset" => $$ds{ID},
		    	      "name" => $$battrs{'name'});
	    }
	    if (! $b)
	    {
		push(@$all_block, $b = { ID => undef,
					 DATASET => $$ds{ID},
					 NAME => $$battrs{'name'},
					 IS_OPEN => 'y',
					 IS_OPEN_REALLY => $$battrs{'is-open'} });
		&dbexec ($dbh, qq{
	            insert into t_dps_block (id, dataset, name, files, bytes, is_open, time_create)
	            values (seq_dps_block.nextval, :dataset, :name, 0, 0, 'y', :now)
	            returning id into :id},
			 ":id" => \$$b{ID},
			 ":dataset" => $$ds{ID},
			 ":name" => $$b{NAME},
			 ":now" => $now);
	    }
	    else
	    {
		$$b{IS_OPEN_REALLY} = $$battrs{'is-open'};
	    }

	    print "  Processing block $$b{NAME} ($$b{ID})\n    :" if $verbose;

	    # Get existing files in the block
	    my $dbfiles = &dbexec($dbh, qq{
		select id, logical_name from t_dps_file where inblock = :block},
		":block" => $$b{ID})->fetchall_arrayref({});
	    my $dbreplicas = &dbexec($dbh, qq{
		select f.id, f.logical_name, xr.node
		from t_xfer_file f
 		  join t_xfer_replica xr on xr.fileid = f.id
		where f.inblock = :block},
		":block" => $$b{ID})->fetchall_arrayref({});

	    # Finally(!) the files
	    my (@files, @replicas);
	    while (@bcontent)
	    {
		($tag, $val) = splice(@bcontent, 0, 2);
    
		# Skip leading white space, and find next <dbs> element.
		next if ($tag eq '0' && $val =~ /^\s+$/so);
		die "$args{FILEDATA}: unexpected character data\n" if $tag eq '0';
		die "$args{FILEDATA}: expected <file> entry, found <$tag>\n"
		    if $tag ne 'file';

		my ($fattrs, @fcontent) = @$val;
		die "$args{FILEDATA}: <file> may not have content\n"
		    if @fcontent;
		die "$args{FILEDATA}: <file lfn=''> attribute missing or empty\n"
		    if ! defined $$fattrs{'lfn'} || $$fattrs{'lfn'} eq '';
		die "$args{FILEDATA}: <file size=''> attribute missing or bad value\n"
		    if ! defined $$fattrs{'size'} || $$fattrs{'size'} !~ /^\d+$/;
		die "$args{FILEDATA}: <file checksum=''> attribute missing or bad value\n"
		    if ! defined $$fattrs{'checksum'} || $$fattrs{'checksum'} !~ /^cksum:\d+$/;
		# Check if it exists
		if (grep($$_{LOGICAL_NAME} eq $$fattrs{'lfn'}, @$dbfiles))
		{
		    die "File $$fattrs{'lfn'} exists\n" if $strict;
		    do { local $|=1; print "-" } if $verbose;
		}
		else
		{
		    die "Dataset $$ds{NAME} is closed, cannot add files\n"
			if $$ds{IS_OPEN} ne 'y';
		    die "Block $$b{NAME} is closed, cannot add files\n"
			if $$b{IS_OPEN} ne 'y';

		    do { local $|=1; print "+" } if $verbose;
		    push(@files, $fattrs);
		}

		foreach my $node (@nodes)
		{
		    next if grep($$_{LOGICAL_NAME} eq $$fattrs{'lfn'}
				 && $$_{NODE} eq $$node{ID}, @$dbreplicas);
		    do { local $|=1; print "/" } if $verbose;
		    push(@replicas, [ $fattrs, $node ]);
		}
	    }

	    print " ", scalar @files, " new files, ", scalar @replicas, " new replicas"
		if $verbose;
	    my $idps = &dbprep($dbh, qq{
		insert into t_dps_file
		(id, node, inblock, logical_name, checksum, filesize, time_create)
		values (seq_dps_file.nextval, ?, ?, ?, ?, ?, ?)});
	    my $ixfer = &dbprep($dbh, qq{
		insert into t_xfer_file
		(id, inblock, logical_name, checksum, filesize)
		(select id, inblock, logical_name, checksum, filesize
		 from t_dps_file where logical_name = ?)});
	    my $ixr = &dbprep($dbh, qq{
		insert into t_xfer_replica
		(id, fileid, node, state, time_create, time_state)
		(select seq_xfer_replica.nextval, id, ?, 0, ?, ?
		 from t_xfer_file where logical_name = ?)});

	    my (%dps, %xfer, %xr);
	    my ($bytes, $files) = (0, 0);
	    foreach my $file (@files)
	    {
		$bytes += $$file{'size'};
		$files++;

		my $n = 1;
		push(@{$dps{$n++}}, $nodes[0]{ID});
		push(@{$dps{$n++}}, $$b{ID});
		push(@{$dps{$n++}}, $$file{'lfn'});
		push(@{$dps{$n++}}, $$file{'checksum'});
		push(@{$dps{$n++}}, $$file{'size'});
		push(@{$dps{$n++}}, $now);

		$n = 1;
		push(@{$xfer{$n++}}, $$file{'lfn'});
	    }

	    foreach my $replica (@replicas)
	    {
		my ($file, $node) = @$replica;
		$n = 1;
		push(@{$xr{$n++}}, $$node{ID});
		push(@{$xr{$n++}}, $now);
		push(@{$xr{$n++}}, $now);
		push(@{$xr{$n++}}, $$file{'lfn'});		
	    }

	    if (@files)
	    {
		do { local $|=1; print " P" } if $verbose;
		&dbbindexec($idps, %dps);

		do { local $|=1; print "T" } if $verbose;
		&dbbindexec($ixfer, %xfer);
	    }

	    if (@replicas)
	    {
		do { local $|=1; print " R" } if $verbose;
		&dbbindexec($ixr, %xr);
	    }

	    # Now mark block closed if required
	    if ($$b{IS_OPEN_REALLY} eq 'n' && $$b{IS_OPEN_REALLY} ne $$b{IS_OPEN})
	    {
		do { local $|=1; print " C" } if $verbose;
		&dbexec($dbh, qq{
		    update t_dps_block
		    set is_open = :is_open, time_update = :now
 		    where id = :block},
		    ":block" => $$b{ID},
		    ":is_open" => $$b{IS_OPEN_REALLY},
		    ":now" => $now);
	    }

	    $$b{IS_OPEN} = $$b{IS_OPEN_REALLY};
	    print "\n" if $verbose;
	}

	# Now mark dataset closed if required
	if ($$ds{IS_OPEN_REALLY} eq 'n' && $$ds{IS_OPEN_REALLY} ne $$ds{IS_OPEN})
	{
	    print "  Closing dataset $$ds{NAME}\n" if $verbose;
	    &dbexec($dbh, qq{
	        update t_dps_dataset
	        set is_open = :is_open, time_update = :now
 	        where id = :dataset},
	        ":dataset" => $$ds{ID},
	        ":is_open" => $$ds{IS_OPEN_REALLY},
		":now" => $now);
	}

	$$ds{IS_OPEN} = $$ds{IS_OPEN_REALLY};
    }
}

$dbh->commit();
&disconnectFromDatabase(\%args, $dbh, 1);
undef $dbh;
exit 0;
