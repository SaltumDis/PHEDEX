#!/usr/bin/perl

#!/usr/bin/env perl

##H Inject files into TMDB.  By default this commits only previoulsy
##H unknown files; known files are skipped.  However in strict mode
##H all files are required to be new to TMDB.
##H
##H The command must be given a XML file that describes the files to
##H add, plus a list of PhEDEx nodes that will get a replica for each
##H file added.  The files are simply made known to TMDB without any
##H any addition of subscriptions or other destination definitions.
##H
##H If the program crashes or is terminated, it is always safe to
##H run again with the same arguments.
##H
##H Usage:
##H   TMDBInject -db FILE[:SECTION] [-strict] [-verbose]
##H     { -nodes NODE[,NODE...] | -storage-elements SE[,SE...] }
##H     -filedata XMLFILE
##H
##H -db                database connection configuration parameter file
##H -strict            don't allow file or its replicas to already exist
##H -verbose           print progress indicators for injection stages
##H -nodes             comma-separated list of nodes to add replicas for
##H -storage-elements  comma-separated list of storage-elements to add
##H                      replicas for; each element will be mapped to
##H                      nodes as recorded in the database
##H -filedata          description of files to add
##H
##H The argument to "-filedata" must be an XML file.  It must contain
##H a top-level "<dbs>" element, which should contain any number of
##H "<dataset>" elements, containing any number of "<block>" elements
##H containing "<file>" elements.
##H
##H The XML file may identify the each dataset and block many times.
##H The union of all files of each block are added to the database.
##H However in the end each file must belong to exactly one DBS,
##H dataset and block.
##H
##H The "<dbs>" element must have an attribute "name", which is the
##H canonical name of the dataset bookkeeping system which owns the
##H files.  Usually this should be the contact address of the DBS.
##H
##H The "<dataset>" element must have an attribute "name", the name
##H of the dataset in the DBS, and two boolean attributes, "is-open"
##H and "is-transient", both which must have value 'y' or 'n'.  The
##H options are checked before processing and new values are applied
##H at the end of the processing, allowing datasets and blocks to be
##H closed by injecting them with these attributes set, possibly not
##H including any files in the injection.
##H
##H A dataset must be open if any of its blocks are open.  Only open
##H datasets can have blocks added to them; similarly with blocks and
##H files.  Closed blocks and datasets cannot be made open with this
##H utility.  If the dataset is marked transient and is closed (and
##H thus all its blocks are closed), and all transfer requests on it
##H have been fulfilled, knowledge about the dataset is removed from
##H the TMDB.  (Typically datasets are known to be transient from the
##H transfer point of view at the time they are first created.)
##H 
##H Each "<block>" must have attribute "name", the canonical and
##H unique name of the block as known the "<dbs>", and "is-open"
##H boolean, either 'y' or 'n'.  If "is-open" is 'n', the block will
##H be marked closed at the end of the processing; this still allows
##H one to add files to new and previously open blocks, then close
##H the blocks.  If the block is already closed in the database, new
##H files cannot be added to it; setting "is-open" to 'y' won't help.
##H New blocks cannot be introduced to closed datasets.  If the
##H dataset is closed, all its blocks must be closed too.
##H
##H Each "<file>" must have attributes "lfn", the logical file name
##H which must be unique, "size", the size of the file in bytes, and
##H "checksum", the cksum checksum of the file data.
##H
##H All elements may contain other attributes; they will be ignored.
##H Only white-space character data is allowed; only information from
##H the attributes of the above elements are added.
##H
##H Example:
##H   <dbs name="http://cmsdoc.cern.ch/cms/aprom/DBS/CGIServer/query">
##H     <dataset name="/sample/dataset" is-open="y" is-transient="n">
##H       <block name="/sample/dataset#1" is-open="y">
##H         <file lfn="file1" size="10" checksum="cksum:1234"/>
##H         <file lfn="file2" size="22" checksum="cksum:456"/>
##H       </block>
##H       <block name="/sample/dataset#2" is-open="y">
##H         <file lfn="file3" size="1" checksum="cksum:2"/>
##H       </block>
##H     </dataset>
##H     <dataset name="/sample/dataset2" is-open="n" is-transient="n">
##H       <block name="/sample/dataset2#1" is-open="n"/>
##H       <block name="/sample/dataset2#2" is-open="n"/>
##H     </dataset>
##H   </dbs>

# Developer Note:
# All SQL bind variables referring to character data in this script
# have been wrapped with TO_CHAR() because of an unresolved problem
# involving Oracle forgoing the use of the table index (columns are
# all varchar2 type) and instead doing a type conversion and
# comparison for the insertion.  As this is done on large columns like
# t_dps_file.logical_name the performance hit was enourmous.  It has
# not been determined *why* this conversion was taking place; we
# checked the following:  
#  * XML which caused the problem had ASCII encoding 
#  * Data inserted as a result looked fine 
#  * No NLS_LANG environment variable set
#
# My understanding of the DBD::Oracle docs leads me to believe this
# should result in the database character encoding being used for all
# bind variables, but this was not the case.

use warnings;
use strict;

use PHEDEX::Core::DB;
use PHEDEX::Core::Inject;
use PHEDEX::Core::XML;
use PHEDEX::Core::Timing;

use Getopt::Long;
use Data::Dumper;

my ($verbose, $strict, %args);
use Getopt::Long;
use PHEDEX::Core::Help;
&GetOptions ("db=s"                => \$args{DBCONFIG},
             "strict"              => \$strict,
             "verbose"             => \$verbose,
             "filedata=s"          => \$args{FILEDATA},
	     "nodes=s"             => sub { push(@{$args{NODES}}, split(/,/, $_[1])) },
	     "storage-elements=s"  => sub { push(@{$args{SES}}, split(/,/, $_[1])) },
	     "version0"            => \$args{VERSION0},
	     "help|h"              => sub { &usage() });

if (@ARGV || !$args{DBCONFIG} || !$args{FILEDATA}
    || (!$args{NODES} && !$args{SES}))
{
    die "Insufficient parameters, use -h for help.\n";
}

# Ensure file data is readable
-r $args{FILEDATA} || die "$args{FILEDATA}: cannot read: $!\n";

# Parse file
print "Parsing $file\n";
my $data;
if ($args{VERSION0})
    # initial XML verison, before version was written in the file
    $data = &PHEDEX::Core::XML::parseData_0(FILE => $args{FILEDATA});
} else {
    # all future versions
    $data = &PHEDEX::Core::XML::parseData(FILE => $args{FILEDATA});
}

# Connect to database
print "Connecting to $args{DBCONFIG}\n";
my $self = { DBCONFIG => $args{DBCONFIG} };
bless $self;
my $dbh = &connectToDatabase ($self);

# Produce a node list.
my @nodes;
if ($args{SES})
{
    @nodes = &PHEDEX::Core::Inject::SEs2InjectionNodes($self, $args{SES});
}
else
{
    my @all_nodes = &PHEDEX::Core::SQL::getNodes($self);
    # Check all nodes are known
    foreach my $node (@{$args{NODES}})
    {
	my @match = grep($$_{NAME} eq $node, @$all_nodes);
        die "Node $node not known\n" if ! @match;
	push(@nodes, @match);
    }
}

# The source node is the first one in the list
# The rest are ignored...
# TODO:  Support non-source replica creation?
my $src_node = shift @nodes;

# Inject data to source node
&PHEDEX::Core::Inject::injectData ($self, $data, $src_node,
				   VERBOSE => $verbose,
				   STRICT => $strict);
print "Done.\n";

&PHEDEX::Core::Inject::execute_commit($self);

&disconnectFromDatabase($self);

exit;
