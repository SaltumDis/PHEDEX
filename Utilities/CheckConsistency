#!/usr/bin/env perl

# The tool will attempt to cache data from the catalogue and tmdb. If
# you want to refresh these caches delete the files *-cache in the dir
# in which you run this tool. If such a file exists the tool will read
# that rather than querying the relevant db.
#
# Note on domains option: allows you to choose which domains to examine
# construct as comma separated list: p [phedex], c [catalogue], fs [file
# system], f [files]

BEGIN {
  use strict; use warnings;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../Toolkit/Common";
  unshift(@INC, $home);
}

use File::Copy;

my $me = $0; $me =~ s|.*/||;
my %args = (DBITYPE => "Oracle", NJOBS => 10);
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-db' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBNAME} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-dbi' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBITYPE} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-dbuser' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBUSER} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-dbpass' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBPASS} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-node' && scalar @ARGV > 1)
    { shift (@ARGV); $args{MYNODE} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-catalogue' && scalar @ARGV > 1)
    { shift (@ARGV); $args{CATALOGUE} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-match' && scalar @ARGV > 1)
    { shift (@ARGV); $args{HOST_KEY} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-jobs' && scalar @ARGV > 1)
    { shift (@ARGV); $args{NJOBS} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-domains' && scalar @ARGV > 1)
    { shift (@ARGV); map { $args{DOMAINS}{$_} = 1 } split(/,/, shift(@ARGV)); }
    elsif ($ARGV[0] eq '-locallister' && scalar @ARGV > 1)
    { shift (@ARGV); $args{LOCALLS} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-surlroot' && scalar @ARGV > 1)
    { shift (@ARGV); $args{SURLROOT} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-localroots' && scalar @ARGV > 1)
    { shift (@ARGV); $args{LOCALROOTS} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-guessfromcat' && scalar @ARGV > 1)
    { shift (@ARGV); $args{GUESS} = shift(@ARGV) }
    else
    { last; }
}

# FIXME: would be good to check for known fstypes: castor or mount
if (scalar @ARGV || !$args{DBNAME} || !$args{DBUSER} || !$args{DBPASS}
    || !$args{DBITYPE} || !$args{MYNODE} || !$args{HOST_KEY}
    || !$args{DOMAINS}
    || ($args{DOMAINS}{c} && !$args{CATALOGUE}) )
{
    print STDERR "usage: $me -node NODE [-catalogue CATALOGUE] -match PATTERN\n",
		 " [-jobs NJOBS] -db NAME -dbuser USER -dbpass PASSWORD [-dbitype TYPE]\n",
                 " -domains DOMAINS\n",
                 "[-localroots ROOTDIRs -locallister SCRIPT -surlroot SURLROOT]\n";
    exit (1);
}


my $files = {};
my $recurse = 1;

if ($args{DOMAINS}{p}) {
    if ( -e "./phedex-cache" ) {
	&readPhedexCache(\%args,$files);
    } else {
	die if ! &queryPhEDEx(\%args, $files);
	&writePhedexCache(\%args,$files);
    }
}
if ($args{DOMAINS}{c} || $args{GUESS} ) {
    if ( -e "./catalogue-cache" ) {
	&readCatalogueCache(\%args, $files);
    } else {
	die if ! &queryFileCatalogue(\%args, $files);
	&writeCatalogueCache(\%args, $files);
    }
}

if ($args{GUESS}) {
    $recurse = 0;
    my @dirs = &getDirsFromCatalogue(\%args, $files);
    $args{LOCALROOTS} = join( ',', @dirs );
}
if ($args{DOMAINS}{fs}) {
    die if ! &queryFileSystem(\%args, $files);
}
if ($args{DOMAINS}{f}) {
    if ( -e "./file-cache" ) {
	&readFileCache(\%args,$files);
    } else {
	die if ! &queryFiles(\%args, $files);
	&writeFileCache(\%args, $files);
    }
}

# Build matrix of counts for all possible states. As guids are found in
# each domain the DOMAIN tag is ORd with the existing value. The domain
# tag is then used to build a table of guid counts in each state
my @counts = ();
my $localcount = 0;
my $catcount = 0;
my $phedexcount = 0;
print "\nSummary of consistency check\n\n";
open(OUT,">all-states");
foreach my $file (values %$files) {
    $phedexcount++ if ( $file->{DOMAINS} & 4 );
    $catcount++ if ( $file->{DOMAINS} & 2 );
    $localcount++ if ( $file->{DOMAINS} & 1 );
    $counts[$file->{DOMAINS}]++;
    my $s = &convertDomainToString($file->{DOMAINS});
    print OUT "$s: $file->{GUID} $file->{FCSURL} $file->{LOCALSURL}\n";
}
close(OUT);

print "\rPCL  #          \n";
for (my $idx=0;$idx<8;$idx++) {
    my $s = &convertDomainToString($idx);
    print "$s: $counts[$idx]\n";
}

print "\nTotal local     : $localcount\n"
       ."Total catalogue : $catcount\n"
       ."Total phedex    : $phedexcount\n";

exit 0;

######################################################################
sub getDirsFromCatalogue
{
    my ($args, $files) = @_;
    my %dirs = ();
    print "Extracting directories from catalogue\n";
    foreach my $file (%$files) {
	if ($file->{DOMAINS} & 2) {
	    my $surl = $file->{FCSURL};
	    my @bits = split( /\//, $surl );
	    $surl =~ s|$args->{SURLROOT}||;
	    $surl =~ s|$bits[$#bits]||;
	    $dirs{$surl} = 1;
	}
    }
    return keys %dirs;
}

sub convertDomainToString
{
    my $idx = shift;
    my $s = '';
    foreach my $d ( qw(4 2 1) ) {
	if ( $idx & $d ) { $s .= "x"; } else { $s .= " "; }
    }
    return $s;
}

sub readPhedexCache
{
    my ($args, $files) = @_;
    print "Reading PhEDEx cache\n";
    open(CACHE, "gunzip -c < ./phedex-cache |");
    while(<CACHE>) {
	chop;
	my ($guid) = split( / / );
	$files->{$guid}{GUID} = $guid;
	$files->{$guid}{DOMAINS} += 4;
    }
    die if ! close(CACHE);
}

sub writePhedexCache
{
    my ($args, $files) = @_;
    print "Writing PhEDEx cache\n";
    open(CACHE, "| gzip -c > ./phedex-cache") || die "Couldn't open phedex-cache for write";
    foreach my $file (values %$files) {
	print CACHE "$file->{GUID}\n" if ($file->{DOMAINS} & 4);
    }
    die if ! close(CACHE);
}

sub readCatalogueCache
{
    my ($args, $files) = @_;
    print "Reading Catalogue cache\n";
    open(CACHE, "gunzip -c < ./catalogue-cache |");
    while(<CACHE>) {
	chop;
	my ($guid,$fcsurl) = split( / / );
	$files->{$guid}{GUID} = $guid;
	$files->{$guid}{DOMAINS} += 2;
	$files->{$guid}{FCSURL} = $fcsurl;
    }
    die if ! close(CACHE);
}

sub writeCatalogueCache
{
    my ($args, $files) = @_;
    print "Writing Catalogue cache\n";
    open(CACHE, "| gzip -c > ./catalogue-cache");
    foreach my $file (values %$files) {
	print CACHE "$file->{GUID} $file->{FCSURL}\n" if ($file->{DOMAINS} & 2);;
    }
    die if ! close(CACHE);
}

sub readFileCache
{
    my ($args, $files) = @_;
    print "Reading File cache\n";
    open(CACHE, "gunzip -c < ./file-cache |");
    while(<CACHE>) {
        chop;
        my ($guid,$localsurl) = split( / / );
        $files->{$guid}{GUID} = $guid;
        $files->{$guid}{DOMAINS} += 1;
        $files->{$guid}{LOCALSURL} = $localsurl;
    }
    die if ! close(CACHE);
}

sub writeFileCache
{
    my ($args, $files) = @_;
    print "Writing File cache\n";
    open(CACHE, "| gzip -c > ./file-cache");
    foreach my $file (values %$files) {
        print CACHE "$file->{GUID} $file->{LOCALSURL}\n" if ($file->{DOMAINS} & 1);;
    }
    die if ! close(CACHE);
}

# Fetch all guids for a node in the TMDB.
sub queryPhEDEx
{
    my ($args, $files) = @_;
    use UtilsDB;
    local $| = 1;

    $dbh = &connectToDatabase ($args, 0);
    my $stmt = &dbexec($dbh, qq{
	select guid from t_replica_state where node = :node},
	":node" => $args->{MYNODE});
    my $nguids = 0;
    print "downloading guids: ";
    while (my ($guid) = $stmt->fetchrow()) {
	$files->{$guid}{GUID} = $guid;
	$files->{$guid}{DOMAINS} += 4;
	print "." if ++$nguids % 1000 == 0;
    }
    print " done\n";
    $dbh->disconnect();
    undef $stmt;
    undef $dbh;
    return 1;
}

# Map GUIDs to PFNs using catalogue, running a number of queries
# in parallel.  Adds "PFN" entry to each file in $files.
sub queryFileCatalogue
{
    my ($args, $files) = @_;
    local $| = 1;

    # Create jobs to resolve guids to pfns
    print "fetching pfns: ";
    my @hex = qw(0 1 2 3 4 5 6 7 8 9 A B C D E F);
    my @hex2 = map { my $x = $_; map { "$x$_" } @hex } @hex;
    my @hex3 = map { my $x = $_; map { "$x$_%" } @hex } @hex2;
    open (CAT, "$home/../../Utilities/PFClistGuidPFN"
	  . " -u '$args->{CATALOGUE}' -j '$args->{NJOBS}' -g -m @hex3 |")
       or die "cannot run PFClistGuidPFN: $!\n";
    my $nguids = 0;
    while (<CAT>)
    {
	my ($guid, $pfn) = /^([-0-9A-F]+)\s+(.*)/;
	if ($pfn =~ /$args->{HOST_KEY}/) {
	    $files->{$guid}{GUID} = $guid;
	    $files->{$guid}{FCSURL} = $pfn;
	    $files->{$guid}{DOMAINS} += 2;
	    print "." if ++$nguids % 1000 == 0;
	}
    }
    close (CAT) or die "PFClistGuidPFN: $!\n";
    print "done\n";
    return 1;
}

# Get local SURLs. Compare to FC. If all files are in the FC then
# and only then can we make the full comparison to the TMDB.
sub queryFileSystem
{
    print "Sorry, direct File System checks aren't supported yet\n";
    return 1;
}

# Query local filesystem for directories and names, and build SURLs
# for each. Map SURLs onto GUIDs where possible using the data in $files
# from the FC. For non matching SURLs create a placeholder GUID.
sub queryFiles
{
    my ($args, $files) = @_;
    my @directories = ();
    my @surls = ();
    my $nguids = 0;
    my $count = 1;

    my @dirs = split( /,/,$args->{LOCALROOTS} );
    push( @directories, @dirs ); 

    my%surltoguid = ();
    foreach $file ( values %$files ) {
	$surltoguid{$file->{FCSURL}} = $file->{GUID} if ( $file->{DOMAINS} & 2 );
    }

    print "getting directory listings: ";

    while( my $current = pop( @directories ) ) {
	open( CMD, "$args->{LOCALLS} $current $args->{SURLROOT} 2>&1 |" );
	while( <CMD> ) {
	    chop;
	    if ( /^d:/ ) {
		my ($tag,$dir) = split( / / );
		push( @directories, "$current/$dir" ) if ( $recurse == 0 );
	    } else {
		print "." if ++$nguids % 1000 == 0;
		my $guid = $surltoguid{$_};
		if ( ! $surltoguid{$_} ) {
		    # File isn't known from catalogue
		    $guid = "placeholder".$count++;
		    $files->{$guid}{GUID} = $guid;
		}  
		$files->{$guid}{LOCALSURL} = $_;
		$files->{$guid}{DOMAINS} += 1;
	    }
	}
	close( CMD );
    }
    print "done\n";

    return 1;
}
