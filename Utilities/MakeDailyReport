#!/usr/bin/env perl

##H Generate daily PhEDEx status- and health report.  Various issues of
##H concern to the administrators of the system are reported in a nice
##H convenient summary which can be archived and/or mailed out.
##H
##H The report includes the following information:
##H   - Database space usage, quota limits.
##H   - Average transfer performance and pending queues.
##H   - Statistics on sites preventing block deactivation.
##H   - Consistency check warnings on the tables.
##H
##H Usage:
##H   MakeDailyReport -db FILE[:SECTION] [-upto TIME]
##H
##H -db        database connection configuration parameter file
##H -upto      transfer report result up to TIME (unix time stamp)
##H
##H The output goes to the standard output in plain text format.

BEGIN {
  use strict; use warnings; $^W=1;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../Toolkit/Common";
  unshift(@INC, $home);
}

# Process command line arguments.
my %args;
use Getopt::Long;
use UtilsHelp;
use UtilsTiming;
use UtilsNet;
use UtilsDB;
use POSIX;
&GetOptions ("db=s"        => \$args{DBCONFIG},
             "upto=s"      => \$args{UPTO},
	     "help|h"      => sub { &usage() });

# Check arguments.
if (@ARGV || !$args{DBCONFIG})
{
    die "Insufficient parameters, use -h for help.\n";
}

my $dbh = &connectToDatabase (\%args, 0);

print "PhEDEx status report for $args{DBSECTION} ($args{DBH_DBUSER}\@$args{DBH_DBNAME})\n",
      "generated at @{[strftime('%Y-%m-%d %H:%M:%S', gmtime())]} GMT",
      " by <@{[scalar(getpwuid($<)) . '@' . &getfullhostname()]}>.\n\n";

######################################################################
# Database table used space statistics

print "#" x 70, "\n";
print "# Table used space\n\n";
print sprintf ("%-8s %-31s %-31s %10s %10s %10s\n",
	       "TYPE", "SEGMENT", "TABLESPACE",
	       "MEGABYTES", "BLOCKS", "EXTENTS");
print "-" x 8, " ", "-" x 31, " ", "-" x 31, " ",
      "-" x 10, " ", "-" x 10, " ", "-" x 10, "\n";

my $qtables = &dbexec($dbh, qq{
	select
            segment_type,
            segment_name,
            tablespace_name,
            sum(bytes),
            sum(blocks),
            count(extent_id)
        from user_extents
        group by segment_name, segment_type, tablespace_name
        order by sum(bytes) desc, segment_type desc, segment_name});
while (my ($type, $object, $tspace, $bytes, $blocks, $extents) = $qtables->fetchrow())
{
    print sprintf ("%-8s %-31s %-31s %10.2f %10d %10d\n",
	    	   $type, $object, $tspace,
		   $bytes/(1024**2), $blocks, $extents);
}
$qtables->finish();

print "\n\n";

######################################################################
# Database tablespace used, available statistics

print "#" x 70, "\n";
print "# Tablespace used space\n\n";
print sprintf ("%-31s %15s %15s %15s %15s %-6s\n", "TABLESPACE", "USED_MEGABYTES",
	       "USED_BLOCKS", "FREE_MEGABYTES", "FREE_BLOCKS", "STATUS");
print "-" x 31, " ", "-" x 15, " ", "-" x 15, " ", "-" x 15, " ", "-" x 15, " ", "-" x 6, "\n";

my $qtspace = &dbexec($dbh, qq{
	select
	    used.tablespace_name,
	    used.bytes, used.blocks,
	    free.bytes, free.blocks
	from (select tablespace_name, sum(bytes) bytes, sum(blocks) blocks
	      from user_extents group by tablespace_name) used
	join (select tablespace_name, sum(bytes) bytes, sum(blocks) blocks
	      from user_free_space group by tablespace_name) free
	  on used.tablespace_name = free.tablespace_name
	order by free.bytes asc, used.bytes desc});
while (my ($tspace, $bytes_used, $blocks_used,
	   $bytes_free, $blocks_free) = $qtspace->fetchrow())
{
    print sprintf ("%-31s %15.2f %15d %15.2f %15d %-6s\n",
	    	   $tspace, $bytes_used/(1024**2), $blocks_used,
		   $bytes_free/(1024**2), $blocks_free,
	   	   $bytes_free < 100*(1024**2) ? "FULL!" : "OK");
}
$qtspace->finish();

print "\n\n";

######################################################################
# Database tablespace used, available statistics

print "#" x 70, "\n";
print "# Recent transfer status\n",
      "#\n",
      "# XFER_MBPS_TOT      Aggregate transfer rate over the period\n",
      "# XFER_GB_TOT        Total amount in gigabytes transferred\n",
      "# XFER_F_TOT         Total number of files transferred\n",
      "# XFER_SUCC_TOT      Total percentage of successful transfers\n",
      "# XFER_HRS           Count of hours in which transfers have completed\n",
      "# XFER_DAYS          Count of days in which transfers have completed\n",
      "# XFER_MBPS_HRMIN    Minimum average hourly transfer rate in MB/s\n",
      "# XFER_MBPS_HRMAX    Maximum average hourly transfer rate in MB/s\n",
      "# XFER_MBPS_HRAVG    Average average hourly transfer rate in MB/s\n",
      "# XFER_SUCC_HRMIN    Minimum hourly percentage of transfer successes\n",
      "# XFER_SUCC_HRMAX    Maximum hourly percentage of transfer successes\n",
      "# WAIT_GB_CHNG       Aggregate difference in pending queue in gigabytes over period\n",
      "# WAIT_GB_FIN        Pending queue in gigabytes at the end of period\n",
      "# WAIT_F_FIN         Pending queue in number of files at the end of period\n",
      "# WAIT_GB_MIN        Minimum size of pending queue during the period\n",
      "# WAIT_GB_MAX        Maximum size of pending queue during the period\n",
      "# WAIT_GB_AVG        Average size of pending queue during the period\n";

foreach my $prevdays (1, 7, 14, 30, 90, 365)
{
    my ($timelow, $timemax, $timespan, %perf, %success);
    my $now = $args{UPTO} || &mytimeofday();
    my $lowlimit = (int($now/86400)-$prevdays)*86400;
    $now = $lowlimit + $prevdays*86400;

    my $qperf = &dbexec($dbh, qq{
	select
	    f.name,
	    t.name,
	    h.timebin,
	    h.timewidth,
	    h.done_files,
	    h.done_bytes,
	    h.wait_files,
	    h.wait_bytes,
	    h.try_files,
	    h.fail_files
	from t_link_histogram h
	  join t_node f on f.id = h.from_node
	  join t_node t on t.id = h.to_node
	where h.timebin >= :limit
	  and h.timebin < :upto
	  and f.name not like '%MSS'},
	":limit" => $lowlimit, ":upto" => $now);
    while (my ($from, $to, $bin, $width,
	       $xfiles, $xbytes, $pfiles, $pbytes,
       	       $tfiles, $ffiles) = $qperf->fetchrow())
    {
	if (! defined $timemax || $bin > $timemax)
	{
            $timemax = $bin;
	    $timespan = $width;
	}
	if (! defined $timelow || $bin < $timelow)
	{
            $timelow = $bin;
	}
	my $key = "$to < $from";
	$xfiles ||= 0; $xbytes ||= 0;
	$pfiles ||= 0; $pbytes ||= 0;
	$tfiles ||= 0; $ffiles ||= 0;
	my $xfer = { BIN => $bin, FILES => $xfiles, BYTES => $xbytes };
	my $pend = { BIN => $bin, FILES => $pfiles, BYTES => $pbytes };
	my $succ = { BIN => $bin, START => $tfiles, ERROR => $ffiles, SUCCESS => $xfiles };

        push (@{$perf{$to}{XFERRED}}, $xfer);
        push (@{$perf{$key}{XFERRED}}, $xfer);
        push (@{$perf{$to}{PENDING}}, $pend);
        push (@{$perf{$key}{PENDING}}, $pend);
        push (@{$success{$to}}, $succ);
        push (@{$success{$key}}, $succ);
    }

    # Make sure the time bounds are defined in case the period was empty
    if (! defined $timemax)
    {
	$timespan = 300;
	$timelow = $lowlimit;
	$timemax = $now - $timespan;
    }
    $timespan += $timemax - $timelow;

    # Print out the headings
    print "\n# $prevdays-day period from ",
          strftime ('%Y-%m-%d %H:%M:%S', gmtime(int($timelow))), " to ",
          strftime ('%Y-%m-%d %H:%M:%S', gmtime(int($timelow+$timespan-1))), "\n\n";
    print sprintf ("%-25s" . " %15s" x 18 . "\n",
	           "DESTINATION/FROM",
	           "XFER_MBPS_TOT", "XFER_GB_TOT", "XFER_F_TOT", "XFER_SUCC_TOT",
		   "XFER_HRS", "XFER_DAYS",
		   "XFER_MBPS_HRMIN", "XFER_MBPS_HRMAX", "XFER_MBPS_HRAVG",
		   "XFER_SUCC_HRMIN", "XFER_SUCC_HRMAX",
	           "WAIT_GB_CHNG", "WAIT_GB_FIN", "WAIT_F_FIN",
		   "WAIT_GB_MIN", "WAIT_GB_MAX", "WAIT_GB_AVG",
	           "EST_DAYS_LEFT");
    print "-" x 25, (" ", "-" x 15) x 18, "\n";

    foreach my $link (sort keys %perf)
    {
        my %stats = (XFER_MBPS_TOT => 0, XFER_GB_TOT => 0, XFER_F_TOT => 0, XFER_SUCC_TOT => 'N/A',
		     XFER_HRS => 0, XFER_DAYS => 0,
		     XFER_SUCCESS => { START => 0, ERROR => 0, SUCCESS => 0, RATIO => undef },
	             XFER_MBPS_HRMIN => 0, XFER_MBPS_HRMAX => 0, XFER_MBPS_HRAVG => 0,
	             XFER_SUCC_HRMIN => 0, XFER_SUCC_HRMAX => 0,
		     WAIT_GB_CHNG => 0, WAIT_GB_FIN => 0, WAIT_F_FIN => 0,
		     WAIT_GB_MIN => 0, WAIT_GB_MAX => 0, WAIT_GB_AVG => 0);

	# Bin quality hourly and calculate statistics
        my %success_hourly = ();
        foreach my $v (@{$success{$link}})
        {
	    my $hour = int($v->{BIN}/3600)*3600;
	    $success_hourly{$hour} ||= { START => 0, SUCCESS => 0, ERROR => 0, RATIO => undef };
	    $success_hourly{$hour}{START} += $v->{START};
	    $success_hourly{$hour}{ERROR} += $v->{ERROR};
	    $success_hourly{$hour}{SUCCESS} += $v->{SUCCESS};

	    $stats{XFER_SUCCESS}{START} += $v->{START};
	    $stats{XFER_SUCCESS}{ERROR} += $v->{ERROR};
	    $stats{XFER_SUCCESS}{SUCCESS} += $v->{SUCCESS};
        }

	foreach my $v ($stats{XFER_SUCCESS}, values %success_hourly)
	{
	    if ($v->{START}) {
		$v->{RATIO} = $v->{SUCCESS} / $v->{START};
	    } elsif ($v->{SUCCESS} || $v->{ERROR}) {
		$v->{RATIO} = $v->{SUCCESS} / ($v->{SUCCESS} + $v->{ERROR});
	    } else {
		$v->{RATIO} = undef;
	    }
	}

        my @success_sorted = sort { $a <=> $b }
	                     map { $_->{RATIO} }
	                     grep (defined $_->{RATIO}, values %success_hourly);
        $stats{XFER_SUCC_HRMIN} = &naformat($success_sorted[0], "%d%%", 100);
        $stats{XFER_SUCC_HRMAX} = scalar @success_sorted
				  ? &naformat($success_sorted[$#success_sorted], "%d%%", 100)
				  : 'N/A';
        $stats{XFER_SUCC_TOT} = &naformat($stats{XFER_SUCCESS}{RATIO}, "%d%%", 100);

	# Bin transfers hourly and calculate statistics.  The binning is
	# seeded from success statistics so we correctly report the hours
	# in which transfers took place.  After this seeding we report
	# hours in which nothing happened to avoid reporting hours with
	# non-zero pending queue as hours of transfer.
        my %xfer_hourly = map { ($_ => 0) } keys %success_hourly;
        foreach my $v (@{$perf{$link}{XFERRED}})
        {
	    next if ! $v->{FILES};
	    my $hour = int($v->{BIN}/3600)*3600;
	    $xfer_hourly{$hour} ||= 0;
	    $xfer_hourly{$hour} += $v->{BYTES};

	    $stats{XFER_GB_TOT} += $v->{BYTES} / (1024**3);
	    $stats{XFER_F_TOT} += $v->{FILES};
        }

        my @xfer_sorted = sort { $a <=> $b } values %xfer_hourly;
	my %xfer_hours = map { (int($_/3600) => 1) } keys %xfer_hourly;
	my %xfer_days = map { (int($_/86400) => 1) } keys %xfer_hourly;
        $stats{XFER_MBPS_HRMIN} = ($xfer_sorted[0] || 0) / (1024**2) / 3600;
        $stats{XFER_MBPS_HRMAX} = ($xfer_sorted[$#xfer_sorted] || 0) / (1024**2) / 3600;
        $stats{XFER_MBPS_HRAVG} = (&avg(@xfer_sorted) || 0) / (1024**2) / 3600;
        $stats{XFER_MBPS_TOT} = $stats{XFER_GB_TOT} * 1024 / $timespan;
	$stats{XFER_HRS} = scalar keys %xfer_hours;
	$stats{XFER_DAYS} = scalar keys %xfer_days;

	# Bin pending queue hourly and calculate statistics
        my %pend_binned = ();
        foreach my $v (@{$perf{$link}{PENDING}})
        {
	    $pend_binned{$v->{BIN}} ||= { BIN => $v->{BIN}, FILES => 0, BYTES => 0 };
	    $pend_binned{$v->{BIN}}{FILES} += $v->{FILES} || 0;
	    $pend_binned{$v->{BIN}}{BYTES} += $v->{BYTES} || 0;
        }

        my @pend_sorted = sort { $a <=> $b } map { $_->{BYTES} } values %pend_binned;
        my @pendtimes = sort { $a <=> $b } keys %pend_binned;
        my $pendmin = $pendtimes[0];
        my $pendmax = $timemax;

        $stats{WAIT_GB_MIN} = ($pend_sorted[0] || 0) / (1024**3);
        $stats{WAIT_GB_MAX} = ($pend_sorted[$#pend_sorted] || 0) / (1024**3);
        $stats{WAIT_GB_AVG} = (&avg(@pend_sorted) || 0) / (1024**3);
        $stats{WAIT_GB_FIN} = ($pend_binned{$pendmax}{BYTES} || 0) / (1024**3);
        $stats{WAIT_F_FIN}  = ($pend_binned{$pendmin}{FILES} || 0);
        $stats{WAIT_GB_CHNG} = (($pend_binned{$pendmax}{BYTES} || 0)
			        - ($pend_binned{$pendmin}{BYTES} || 0)) / (1024**3);

	# Print out results
	$link =~ s/.*<\s*/. /;
        print sprintf ("%-25s"
	               . " %15.3f %15.3f %15d %15s"
		       . " %15d %15d"
		       . " %15.3f %15.3f %15.3f"
		       . " %15s %15s"
		       . " %15.3f %15.3f %15d"
		       . " %15.3f %15.3f %15.3f"
		       . " %s\n",
	               $link,
		       $stats{XFER_MBPS_TOT}, $stats{XFER_GB_TOT}, $stats{XFER_F_TOT}, $stats{XFER_SUCC_TOT},
		       $stats{XFER_HRS}, $stats{XFER_DAYS},
		       $stats{XFER_MBPS_HRMIN}, $stats{XFER_MBPS_HRMAX}, $stats{XFER_MBPS_HRAVG},
		       $stats{XFER_SUCC_HRMIN}, $stats{XFER_SUCC_HRMAX},
		       $stats{WAIT_GB_CHNG}, $stats{WAIT_GB_FIN}, $stats{WAIT_F_FIN},
		       $stats{WAIT_GB_MIN}, $stats{WAIT_GB_MAX}, $stats{WAIT_GB_AVG},
	   	       ($stats{XFER_MBPS_TOT} && $stats{WAIT_GB_FIN}
		        ? sprintf ("%15.3f", $stats{WAIT_GB_FIN} / ($stats{XFER_MBPS_TOT}*86400/1024))
	   	        : !$stats{WAIT_GB_FIN} ? sprintf ("%15.3f", 0)
		        : sprintf ("%15s", "N/A")));
    }
}

print "\n\n";

######################################################################
# Sites preventing block activation

print "#" x 70, "\n";
print "# Sites preventing block deactivation\n\n";
print sprintf ("%-20s %15s %15s %15s\n", "DESTINATION",
	       "BLOCKS", "REPLICAS", "GIGABYTES");
print "-" x 20, (" ", "-" x 15) x 3, "\n";

my $qblocks = &dbexec($dbh, qq{
    select
        n.name,
	count(b.name),
	sum(b.files - br.node_files),
	sum(b.bytes - br.node_bytes)
    from t_dps_block b
      join t_dps_block_replica br on br.block = b.id
      join t_node n on n.id = br.node
    where b.is_open = 'n'
      and br.is_active = 'y'
      and br.dest_files > 0
      and br.node_files != br.dest_files
    group by n.name
    order by 2 desc, 4 desc});
while (my ($node, $blocks, $files, $bytes) = $qblocks->fetchrow())
{
    print sprintf ("%-20s %15d %15d %15.2f\n",
	           $node, $blocks, $files, $bytes/(1024**3));
}

print "\n\n";

######################################################################
# Consistency checks

print "#" x 70, "\n";
print "# Consistency checks\n\n";

my $errors = 0;
my $qtrdups = &dbexec($dbh, qq{
    select xs.to_node, xs.fileid, f.logical_name
    from t_xfer_state xs
      join t_xfer_file f
        on f.id = xs.fileid
      join t_xfer_replica xr
        on xr.fileid = xs.fileid
       and xr.node = xs.to_node
    order by xs.to_node, f.logical_name});
while (my ($to, $id, $lfn) = $qtrdups->fetchrow ())
{
    print "WARNING: destination replica exists for transfer of $id to $to ($lfn)\n";
    ++$errors;
}

print "(Nothing to report)\n" if ! $errors;

print "\n\n";

######################################################################
$dbh->disconnect();
exit 0;

sub avg
{
    my (@values) = @_;
    my $sum = 0; my $defined = 0;
    foreach my $val (@values)
    {
	next if ! defined ($val);
	$sum += $val;
	++$defined;
    }
    return $defined ? ($sum / $defined) : undef;
}

sub naformat
{
    my ($value, $format, $factor) = @_;
    return 'N/A' if ! defined $value;
    return sprintf($format, $value * $factor);
}
