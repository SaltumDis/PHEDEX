#!/usr/bin/env perl

##H Generate daily PhEDEx status- and health report.  Various issues of
##H concern to the administrators of the system are reported in a nice
##H convenient summary which can be archived and/or mailed out.
##H
##H The report includes the following information:
##H   - Database space usage, quota limits.
##H   - Average transfer performance and pending queues.
##H   - Statistics on sites preventing block deactivation.
##H   - Consistency check warnings on the tables.
##H
##H Usage:
##H   MakeDailyReport -db FILE[:SECTION] [-upto TIME]
##H
##H -db        database connection configuration parameter file
##H -upto      transfer report result up to TIME (unix time stamp)
##H
##H The output goes to the standard output in plain text format.

BEGIN {
  use strict; use warnings; $^W=1;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../Toolkit/Common";
  unshift(@INC, $home);
}

# Process command line arguments.
my %args;
use List::Util qw(reduce min max sum);
use Getopt::Long;
use UtilsHelp;
use UtilsTiming;
use UtilsNet;
use UtilsDB;
use POSIX;
&GetOptions ("db=s"        => \$args{DBCONFIG},
             "upto=s"      => \$args{UPTO},
	     "help|h"      => sub { &usage() });

# Check arguments.
if (@ARGV || !$args{DBCONFIG})
{
    die "Insufficient parameters, use -h for help.\n";
}

my $dbh = &connectToDatabase (\%args, 0);

print "PhEDEx status report for $args{DBSECTION} ($args{DBH_DBUSER}\@$args{DBH_DBNAME})\n",
      "generated at @{[strftime('%Y-%m-%d %H:%M:%S', gmtime())]} GMT",
      " by <@{[scalar(getpwuid($<)) . '@' . &getfullhostname()]}>.\n\n";

######################################################################
# Database table used space statistics

print "#" x 70, "\n";
print "# Table used space\n\n";
print sprintf ("%-8s %-31s %-31s %10s %10s %10s\n",
	       "TYPE", "SEGMENT", "TABLESPACE",
	       "MEGABYTES", "BLOCKS", "EXTENTS");
print "-" x 8, " ", "-" x 31, " ", "-" x 31, " ",
      "-" x 10, " ", "-" x 10, " ", "-" x 10, "\n";

my $qtables = &dbexec($dbh, qq{
	select
            segment_type,
            segment_name,
            tablespace_name,
            sum(bytes),
            sum(blocks),
            count(extent_id)
        from user_extents
        group by segment_name, segment_type, tablespace_name
        order by sum(bytes) desc, segment_type desc, segment_name});
while (my ($type, $object, $tspace, $bytes, $blocks, $extents) = $qtables->fetchrow())
{
    print sprintf ("%-8s %-31s %-31s %10.2f %10d %10d\n",
	    	   $type, $object, $tspace,
		   $bytes/(1024**2), $blocks, $extents);
}
$qtables->finish();

print "\n\n";

######################################################################
# Database tablespace used, available statistics

print "#" x 70, "\n";
print "# Tablespace used space\n\n";
print sprintf ("%-31s %15s %15s %15s %15s %-6s\n", "TABLESPACE", "USED_MEGABYTES",
	       "USED_BLOCKS", "FREE_MEGABYTES", "FREE_BLOCKS", "STATUS");
print "-" x 31, " ", "-" x 15, " ", "-" x 15, " ", "-" x 15, " ", "-" x 15, " ", "-" x 6, "\n";

my $qtspace = &dbexec($dbh, qq{
	select
	    used.tablespace_name,
	    used.bytes, used.blocks,
	    free.bytes, free.blocks
	from (select tablespace_name, sum(bytes) bytes, sum(blocks) blocks
	      from user_extents group by tablespace_name) used
	join (select tablespace_name, sum(bytes) bytes, sum(blocks) blocks
	      from user_free_space group by tablespace_name) free
	  on used.tablespace_name = free.tablespace_name
	order by free.bytes asc, used.bytes desc});
while (my ($tspace, $bytes_used, $blocks_used,
	   $bytes_free, $blocks_free) = $qtspace->fetchrow())
{
    print sprintf ("%-31s %15.2f %15d %15.2f %15d %-6s\n",
	    	   $tspace, $bytes_used/(1024**2), $blocks_used,
		   $bytes_free/(1024**2), $blocks_free,
	   	   $bytes_free < 100*(1024**2) ? "FULL!" : "OK");
}
$qtspace->finish();

print "\n\n";

######################################################################
# Database tablespace used, available statistics

print "#" x 70, "\n";
print "# Recent transfer status\n",
      "#\n",
      "# XFER_MBPS_TOT      Aggregate transfer rate over the period\n",
      "# XFER_GB_TOT        Total amount in gigabytes transferred\n",
      "# XFER_F_TOT         Total number of files transferred\n",
      "# XFER_SUCC_TOT      Total percentage of successful transfers\n",
      "# XFER_HRS           Count of hours in which transfers have completed\n",
      "# XFER_DAYS          Count of days in which transfers have completed\n",
      "# XFER_MBPS_HRMIN    Minimum average hourly transfer rate in MB/s\n",
      "# XFER_MBPS_HRMAX    Maximum average hourly transfer rate in MB/s\n",
      "# XFER_MBPS_HRAVG    Average average hourly transfer rate in MB/s\n",
      "# XFER_SUCC_HRMIN    Minimum hourly percentage of transfer successes\n",
      "# XFER_SUCC_HRMAX    Maximum hourly percentage of transfer successes\n",
      "# WAIT_GB_CHNG       Aggregate difference in pending queue in gigabytes over period\n",
      "# WAIT_GB_FIN        Pending queue in gigabytes at the end of period\n",
      "# WAIT_F_FIN         Pending queue in number of files at the end of period\n",
      "# WAIT_GB_MIN        Minimum size of pending queue during the period\n",
      "# WAIT_GB_MAX        Maximum size of pending queue during the period\n",
      "# WAIT_GB_AVG        Average size of pending queue during the period\n";

foreach my $prevdays (1, 7, 14, 30, 90, 365)
{
    my ($timelow, $timemax, $timespan, %perf, %success);
    my $now = $args{UPTO} || &mytimeofday();
    my $lowlimit = (int($now/86400)-$prevdays)*86400;
    $now = $lowlimit + $prevdays*86400;

    my $qperf = &dbexec($dbh, qq{
	select
	    f.name,
	    t.name,
	    trunc(h.timebin/3600)*3600,
	    3600,
	    nvl(sum(h.done_files),0),
	    nvl(sum(h.done_bytes),0),
	    nvl(sum(pend_files) keep (dense_rank last order by timebin asc),0),
	    nvl(sum(pend_bytes) keep (dense_rank last order by timebin asc),0),
	    nvl(sum(h.try_files),0),
	    nvl(sum(h.fail_files),0)
	from t_link_histogram h
	  join t_node f on f.id = h.from_node
	  join t_node t on t.id = h.to_node
	where h.timebin >= :limit
	  and h.timebin < :upto
	  and f.name not like '%MSS'
  	group by f.name, t.name, trunc(h.timebin/3600)*3600, 3600},
	":limit" => $lowlimit, ":upto" => $now);
    while (my ($from, $to, $bin, $width,
	       $xfiles, $xbytes, $pfiles, $pbytes,
       	       $tfiles, $ffiles) = $qperf->fetchrow())
    {
	if (! defined $timemax || $bin > $timemax)
	{
            $timemax = $bin;
	    $timespan = $width;
	}
	if (! defined $timelow || $bin < $timelow)
	{
            $timelow = $bin;
	}

	push(@{$perf{$to}{$from}}, {
	  BIN => $bin,
	  XFER_FILES => $xfiles,
	  XFER_BYTES => $xbytes,
	  PEND_FILES => $pfiles,
	  PEND_BYTES => $pbytes,
	  SUCC_START => $tfiles,
	  SUCC_ERROR => $ffiles,
	  SUCC_SUCCESS => $xfiles });
    }

    # Make sure the time bounds are defined in case the period was empty
    if (! defined $timemax)
    {
	$timespan = 300;
	$timelow = $lowlimit;
	$timemax = $now - $timespan;
    }
    $timespan += $timemax - $timelow;

    # Print out the headings
    print "\n# $prevdays-day period from ",
          strftime ('%Y-%m-%d %H:%M:%S', gmtime(int($timelow))), " to ",
          strftime ('%Y-%m-%d %H:%M:%S', gmtime(int($timelow+$timespan-1))), "\n\n";
    print sprintf ("%-25s" . " %15s" x 18 . "\n",
	           "DESTINATION/FROM",
	           "XFER_MBPS_TOT", "XFER_GB_TOT", "XFER_F_TOT", "XFER_SUCC_TOT",
		   "XFER_HRS", "XFER_DAYS",
		   "XFER_MBPS_HRMIN", "XFER_MBPS_HRMAX", "XFER_MBPS_HRAVG",
		   "XFER_SUCC_HRMIN", "XFER_SUCC_HRMAX",
	           "WAIT_GB_CHNG", "WAIT_GB_FIN", "WAIT_F_FIN",
		   "WAIT_GB_MIN", "WAIT_GB_MAX", "WAIT_GB_AVG",
	           "EST_DAYS_LEFT");
    print "-" x 25, (" ", "-" x 15) x 18, "\n";

    # Build array of link structures we want to report on.  This is first
    # a summary row for each destination, then individual links to that
    # destination.
    my @links;
    foreach my $to (sort keys %perf)
    {
	my @from = sort keys %{$perf{$to}};
	push (@links, [ $to, map { $perf{$to}{$_} } @from ]);
	push (@links, [ ". $_", $perf{$to}{$_} ]) for @from;
    }

    # Now build a report for each link.
    foreach my $link (@links)
    {
	my $label = shift (@$link);
        my %stats = (XFER_MBPS_TOT => 0, XFER_GB_TOT => 0, XFER_F_TOT => 0, XFER_SUCC_TOT => 'N/A',
		     XFER_HRS => 0, XFER_DAYS => 0,
		     XFER_SUCCESS => { START => 0, ERROR => 0, SUCCESS => 0, RATIO => undef },
	             XFER_MBPS_HRMIN => 0, XFER_MBPS_HRMAX => 0, XFER_MBPS_HRAVG => 0,
	             XFER_SUCC_HRMIN => 0, XFER_SUCC_HRMAX => 0,
		     WAIT_GB_CHNG => 0, WAIT_GB_FIN => 0, WAIT_F_FIN => 0,
		     WAIT_GB_MIN => 0, WAIT_GB_MAX => 0, WAIT_GB_AVG => 0);

	# Bin quality hourly and calculate statistics
        my %hourly = ();
        foreach my $array (@$link)
        {
            foreach my $v (@$array)
	    {
	        my $hour = $$v{BIN};
	        $hourly{$hour} ||= { START => 0, SUCCESS => 0, ERROR => 0, RATIO => undef };
	        $hourly{$hour}{START} += $$v{SUCC_START};
	        $hourly{$hour}{ERROR} += $$v{SUCC_ERROR};
	        $hourly{$hour}{SUCCESS} += $$v{SUCC_SUCCESS};

	        $stats{XFER_SUCCESS}{START} += $$v{SUCC_START};
	        $stats{XFER_SUCCESS}{ERROR} += $$v{SUCC_ERROR};
	        $stats{XFER_SUCCESS}{SUCCESS} += $$v{SUCC_SUCCESS};
	    }
        }

	foreach my $v ($stats{XFER_SUCCESS}, values %hourly)
	{
	    if ($$v{START}) {
		$$v{RATIO} = $$v{SUCCESS} / $$v{START};
	    } elsif ($$v{SUCCESS} || $$v{ERROR}) {
		$$v{RATIO} = $$v{SUCCESS} / ($$v{SUCCESS} + $$v{ERROR});
	    } else {
		$$v{RATIO} = undef;
	    }
	}


	my $succ_min = reduce { $$a{RATIO} < $$b{RATIO} ? $a : $b }
		       grep(defined $$_{RATIO}, values %hourly);
	my $succ_max = reduce { $$a{RATIO} > $$b{RATIO} ? $a : $b }
		       grep(defined $$_{RATIO}, values %hourly);
        $stats{XFER_SUCC_HRMIN} = &naformat($$succ_min{RATIO}, "%d%%", 100);
        $stats{XFER_SUCC_HRMAX} = &naformat($$succ_max{RATIO}, "%d%%", 100);
        $stats{XFER_SUCC_TOT} = &naformat($stats{XFER_SUCCESS}{RATIO}, "%d%%", 100);

	# Bin transfers hourly and calculate statistics.  The binning is
	# seeded from success statistics so we correctly report the hours
	# in which transfers took place.  After this seeding we report
	# hours in which nothing happened to avoid reporting hours with
	# non-zero pending queue as hours of transfer.
        $hourly{$_} = 0 for keys %hourly;
        foreach my $array (@$link)
        {
            foreach my $v (@$array)
	    {
		next if ! $$v{XFER_FILES};

	        my $hour = $$v{BIN};
	        $hourly{$hour} ||= 0;
		$hourly{$hour} += $$v{XFER_BYTES};

		$stats{XFER_GB_TOT} += $$v{XFER_BYTES} / (1024**3);
		$stats{XFER_F_TOT} += $$v{XFER_FILES};
	    }
	}

	my $xfer_min = min values %hourly;
	my $xfer_max = max values %hourly;
	my $xfer_avg = (%hourly
			? (sum (values %hourly) / scalar (values %hourly))
			: undef);
	my %xfer_hours = map { (int($_/3600) => 1) } keys %hourly;
	my %xfer_days = map { (int($_/86400) => 1) } keys %hourly;
        $stats{XFER_MBPS_HRMIN} = ($xfer_min || 0) / (1024**2) / 3600;
        $stats{XFER_MBPS_HRMAX} = ($xfer_max || 0) / (1024**2) / 3600;
        $stats{XFER_MBPS_HRAVG} = ($xfer_avg || 0) / (1024**2) / 3600;
        $stats{XFER_MBPS_TOT} = $stats{XFER_GB_TOT} * 1024 / $timespan;
	$stats{XFER_HRS} = scalar keys %xfer_hours;
	$stats{XFER_DAYS} = scalar keys %xfer_days;

	# Bin pending queue hourly and calculate statistics
        %hourly = ();
        foreach my $array (@$link)
        {
            foreach my $v (@$array)
	    {
	        $hourly{$$v{BIN}} ||= { BIN => $$v{BIN}, FILES => 0, BYTES => 0 };
		$hourly{$$v{BIN}}{FILES} += $$v{PEND_FILES};
		$hourly{$$v{BIN}}{BYTES} += $$v{PEND_BYTES};
	    }
	}

	my $pend_min = reduce { $$a{BYTES} < $$b{BYTES} ? $a : $b } values %hourly;
	my $pend_max = reduce { $$a{BYTES} > $$b{BYTES} ? $a : $b } values %hourly;
	my $pend_avg = &avg (map { $$_{BYTES} } values %hourly);
        my @pendtimes = sort { $a <=> $b } keys %hourly;
        my $pendmin = $pendtimes[0];
        my $pendmax = $timemax;

        $stats{WAIT_GB_MIN} = ($$pend_min{BYTES} || 0) / (1024**3);
        $stats{WAIT_GB_MAX} = ($$pend_max{BYTES} || 0) / (1024**3);
        $stats{WAIT_GB_AVG} = ($pend_avg || 0) / (1024**3);
        $stats{WAIT_GB_FIN} = ($hourly{$pendmax}{BYTES} || 0) / (1024**3);
        $stats{WAIT_F_FIN}  = ($hourly{$pendmin}{FILES} || 0);
        $stats{WAIT_GB_CHNG} = (($hourly{$pendmax}{BYTES} || 0)
			        - ($hourly{$pendmin}{BYTES} || 0)) / (1024**3);

	# Print out results
        print sprintf ("%-25s"
	               . " %15.3f %15.3f %15d %15s"
		       . " %15d %15d"
		       . " %15.3f %15.3f %15.3f"
		       . " %15s %15s"
		       . " %15.3f %15.3f %15d"
		       . " %15.3f %15.3f %15.3f"
		       . " %s\n",
	               $label,
		       $stats{XFER_MBPS_TOT}, $stats{XFER_GB_TOT}, $stats{XFER_F_TOT}, $stats{XFER_SUCC_TOT},
		       $stats{XFER_HRS}, $stats{XFER_DAYS},
		       $stats{XFER_MBPS_HRMIN}, $stats{XFER_MBPS_HRMAX}, $stats{XFER_MBPS_HRAVG},
		       $stats{XFER_SUCC_HRMIN}, $stats{XFER_SUCC_HRMAX},
		       $stats{WAIT_GB_CHNG}, $stats{WAIT_GB_FIN}, $stats{WAIT_F_FIN},
		       $stats{WAIT_GB_MIN}, $stats{WAIT_GB_MAX}, $stats{WAIT_GB_AVG},
	   	       ($stats{XFER_MBPS_TOT} && $stats{WAIT_GB_FIN}
		        ? sprintf ("%15.3f", $stats{WAIT_GB_FIN} / ($stats{XFER_MBPS_TOT}*86400/1024))
	   	        : !$stats{WAIT_GB_FIN} ? sprintf ("%15.3f", 0)
		        : sprintf ("%15s", "N/A")));
    }
}

print "\n\n";

######################################################################
# Sites preventing block activation

print "#" x 70, "\n";
print "# Sites preventing block deactivation\n\n";
print sprintf ("%-20s %15s %15s %15s\n", "DESTINATION",
	       "BLOCKS", "REPLICAS", "GIGABYTES");
print "-" x 20, (" ", "-" x 15) x 3, "\n";

my $qblocks = &dbexec($dbh, qq{
    select
        n.name,
	count(b.name),
	sum(b.files - br.node_files),
	sum(b.bytes - br.node_bytes)
    from t_dps_block b
      join t_dps_block_replica br on br.block = b.id
      join t_node n on n.id = br.node
    where b.is_open = 'n'
      and br.is_active = 'y'
      and br.dest_files > 0
      and br.node_files != br.dest_files
    group by n.name
    order by 2 desc, 4 desc});
while (my ($node, $blocks, $files, $bytes) = $qblocks->fetchrow())
{
    print sprintf ("%-20s %15d %15d %15.2f\n",
	           $node, $blocks, $files, $bytes/(1024**3));
}

print "\n\n";

######################################################################
# Consistency checks

print "#" x 70, "\n";
print "# Consistency checks\n\n";

my $errors = 0;
my $qtrdups = &dbexec($dbh, qq{
    select xs.to_node, xs.fileid, f.logical_name
    from t_xfer_state xs
      join t_xfer_file f
        on f.id = xs.fileid
      join t_xfer_replica xr
        on xr.fileid = xs.fileid
       and xr.node = xs.to_node
    order by xs.to_node, f.logical_name});
while (my ($to, $id, $lfn) = $qtrdups->fetchrow ())
{
    print "WARNING: destination replica exists for transfer of $id to $to ($lfn)\n";
    ++$errors;
}

print "(Nothing to report)\n" if ! $errors;

print "\n\n";

######################################################################
$dbh->disconnect();
exit 0;

sub avg
{
    my (@values) = @_;
    my $sum = 0; my $defined = 0;
    foreach my $val (@values)
    {
	next if ! defined ($val);
	$sum += $val;
	++$defined;
    }
    return $defined ? ($sum / $defined) : undef;
}

sub naformat
{
    my ($value, $format, $factor) = @_;
    return 'N/A' if ! defined $value;
    return sprintf($format, $value * $factor);
}
