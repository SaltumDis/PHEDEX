# This is where it all happens...
%Lifecycle::Lite = (
  Name		=> 'PhEDEx Lifecycle Agent', # don't worry about this

# These are true global values. Overriding these per dataflow does not make sense
  Quiet		=> 0,
  Verbose	=> 1,
  Debug		=> 1,
  Dummy		=> 0,   # Don't update TMDB, just run the framework. Used only for
			# specialised debugging (of the LifeCycle agent itself)
  Jitter	=> 0.1, # Spread delay-times for workflow events by a small factor
  CycleSpeedup	=>   1, # speed up time. 1 => real-time, 7 => do a week of work in a day
  StopOnIdle	=>   1, # Not yet implemented...
  Suspend       =>   0, # set to 1 to suspend new workflows from starting,
                        # but allow existing workflows to run to completion
  NJobs         =>   8, # degree of parallelism

# Also true globals, but these make sense to override. Providing values here
# is just a convenient way to avoid having to repeat them everywhere.
  CycleTime     => 600,
  NCycles       => -1, # < 0 => infinite, > 0 to limit

  KeepInputs    => 1, # keep the  input files of successful jobs?
  KeepOutputs   => 1, # keep the output files of successful jobs?
  KeepLogs      => 1, # keep the    log files of successful jobs?
  KeepFailedInputs      => 1, # keep the  input files of failed jobs?
  KeepFailedOutputs     => 1, # keep the output files of failed jobs?
  KeepFailedLogs        => 1, # keep the    log files of failed jobs?

# Next, some global values that _can_ be overridden sensibly, per dataflow or per dataset
  StuckFileFraction => 0, # percentage of files stuck in transfer  
  FileSizeMean	 => 2.0, # GB
  FileSizeStdDev => 0.2, # GB

# After the global values, set the Dafaflow default values and dataset workflow
  Templates => {
#   Default parameters for each workflow. These override global defaults, but
#   are in turn overridden by values in the specific workflow instances.
#   Typically, set CycleTime and NFiles, based on the expectations from the
#   computing model in question. For example, NFiles * FileSizeMean / CycleTime
#   (FileSizeMean is set above) gives you the average rate of data 'flowing'
#   through your system. Each of those values can be set per workflow

#   This template will inject data at the T0, subscribe it to the T1s, then,
#   when it gets there, delete it from the T0.
    'RAW' => {
      CycleTime		=>  900 , # Start another instance of this workflow every so often
#     CycleTime         => {algo => 'table',min => 1,max => 900,step => 1,table => [1,0,0,1]},  
#      Events		=> [ 'Inject', 'T1Subscribe', 'addData' ], # , 'T2Subscribe' ], #, 'srcdelete' ],
      Events		=> [ 'makeDataset', 'makeBlocks', 'makeFiles', 'Inject', 'T1Subscribe', 'addData', ],
      Intervals		=> {
	Inject      =>     0,
	T1Subscribe =>     3,
	T2Subscribe =>     5,
        addData     =>     3,
	srcdelete   =>   900,
      },
#     FileSizeStdDev	=>   0.1, # GB - override global default value for this dataflow
      Priority		=> 'low',
      IsCustodial	=>   'n',
      IsMove		=>   'n',
      Group		=> 'operators',
    },
    CheckProxy => {
#     Events       => [ 'CheckProxy' ], # This is the default
      Incarnations =>  1,
    },
    Auth => {
      Incarnations => 1,
      NCycles      => 1,
    },
  },

  Defaults => {
#   Use the Datasvc module to perform the actions, instead of calling the code directly.
    Namespace	=> 'PHEDEX::Testbed::Lifecycle',
    Module => {
      Auth        => 'Datasvc',
      Inject      => 'Datasvc',
      T1Subscribe => 'Datasvc',
      T2Subscribe => 'Datasvc',
      srcdelete   => 'Datasvc',
      makeDataset => 'DataProvider',
      makeBlocks  => 'DataProvider',
      makeFiles   => 'DataProvider',
      addData     => 'DataProvider',
    },
    DataProvider => { # parameters for the DataProvider module constructor
      addData  => {
        addEvents => [ 'Inject', 'addData', ], # After running addData, push these events back onto the workflow
      },
    },
    Datasvc	=> { # parameters for the Datasvc module constructor
      url      => 'https://phedex-web-dev.cern.ch/phedex/datasvc',
      instance => 'tony',
#      Set up your proxy by running 'voms-proxy-init --voms cms --valid 196:00'
       cert_file => $ENV{X509_USER_PROXY} || "/tmp/x509up_u$<",
       key_file	 => $ENV{X509_USER_PROXY} || "/tmp/x509up_u$<",
       ca_file	 => $ENV{X509_USER_PROXY} || "/tmp/x509up_u$<",
       ca_dir	 => $ENV{X509_CERT_DIR}   || '/afs/cern.ch/project/gd/LCG-share2/certificates',
    },
    Exec => {
#     External executables for some other actions
      'CheckProxy'	=> 'CheckProxy.pl',
    },
  },

# This is a hash of named workflows. Workflows are based on their 'Template' member,
# and may contain parameters that override the template, or simply add new data that
# is used by separate events in the workflow.
  Workflows => [
    {
      Name			=> 'Raw data',
      Template			=> 'RAW',
      Suspend			=> 0, # Enable/suspend this particular workflow

#     Injection parameters. Only one, so a simple scalar will do
      InjectionSite		=>    'T0_Test_Buffer',

#     addData parameters. How to add data to this dataset
      InjectionsPerBlock	=>         2, # Use open blocks <n> times, then close them
      BlocksPerDataset		=>	   2, # Add <n> blocks to the dataset

#     Subscription parameters. Complex object, and can be multiple.
      T1Subscribe	=> {
        Nodes    => 'T1_Test1_Buffer',
        Priority => 'high',
      },
#      T2Subscribe	=> {
#        Nodes       => 'T1_Test1_MSS',
#      },
#     Subscription parameters that are 'global' for this workflow
      IsCustodial	=>        'n',
      IsMove		=>        'n',

#     Initial parameters for the generator
      Dataset	=> '/tony/testA-%02x/RAW',
      Datasets	=>     1,
      Blocks	=>     2,
      Files	=>    10,

      DBS	=> 'http://cmsdoc.cern.ch/cms/aprom/DBS/CGIServer/query',
    },
#    { Name => 'CheckProxy', },
#    { Name => 'Auth', },
  ],

#  DatasetDefaults =>
#  {
##   These are global defaults. They are overridden by per-dataflow defaults and
##   by values in the individual workflows.
#    InUse		=>    1, # These are standard block-parameters
#    IsOpen		=>   'y',
#    IsMove		=>   'n',
#    IsTransient		=>   'n',
#    IsCustodial		=>   'y',
#    InjectionSite	=>    'T0_Test_Buffer',
#    NFiles		=> 1000,
#    Priority		=>    3,
#    InjectionsPerBlock	=>   10, # Use open blocks <n> times, then close them
#
#    NCycles	=>   -1, # < 0 => infinite. > 0 to limit
#    CycleTime	=>   7200,
#
##   These are intervals between events. Undefined => event fires immediately
#    inject	=> undef,
#    t1subscribe	=>     3, # subscribe the data for transfer almost immediately
#    srcdelete	=>  3600, # set deletion for some time after arrival
#  },

# This is where I name my datasets and their detailed parameters. This is a
# Perl array of hashes, each of which has a Name and a Dataflow that say
# what type of data it is. They also have a set of T1s or T2s specified
# to steer the workflow accordingly. For example, when a dataset is to be
# subscribed to a T1, it will go to all of the T1s listed in this definition.
# Different dataset instances can go to different sets of T1s.
# To specify the probability for each transfer to fail at NN percent, add 
# "_FailNN" string at the end of dataset name, see example below.
# (If you don't want any transfer to fail, don't add any string.) 
  Datasets =>
  [
    {
      Name	=> '/lifecycle/custodial/raw_1'.'_Fail20',     # . "_Fail10"
      Dataflow	=> 'RAW',
      T1s	=> ['T1_Test1_Buffer'],
    },
    {
      Name	=> '/lifecycle/custodial/raw_2',     # . "_Fail10"
      Dataflow	=> 'RAW',
      T1s	=> ['T1_Test1_Buffer'],
    },
  ],

# These are in case I am using a PhEDEx::Logger to send stuff to. I'm not...
  QueueEntries  => 1,
  RetryInterval => 2,
);

do "$ENV{PHEDEX_CONFIG}/LifecycleNodes.pl";

do "$ENV{PHEDEX_CONFIG}/LifecycleGroups.pl";

# Everything below here can be ignored.
%Logger::Receiver =
(
  ConfigRefresh	=> 10, # Interval for checking config file
  Host		=> 'localhost',
  Port		=> 22201,
# Logfile	=> /tmp/wildish/PhEDEx/logs/prototype.log,
  Quiet		=> 0,
  Verbose	=> 1,
  Debug		=> 0,
);

%Logger::Sender =
(
  QueueEntries	=> 1,
  RetryInterval => 2,
  Quiet		=> 1,
  Verbose	=> 0,
  Debug		=> 0,
);

1;
