#!/usr/bin/perl

## Add checksums for files that don't have the information.
##
## This agent works in tandem with FileCastorExport.  The former
## manages the file export castor stage pool based on file requests
## from downstream transfer agents.  Once the files are brought on
## disk, the export agent marks them as requiring checksum using a
## special node-specific state.  This agent looks for files in such
## a state, and if they don't have a checksum, calculates and adds
## it to the database.  Only once the checksum is available we mark
## the file available for transfer.
##
## This agent periodically checks TMDB for files in "needs checksum"
## state.  For each such file it creates a job packet for an internal
## slave that does the actual checksumming.  While the file is being
## checksummed, we mark it as "in checksum" state so several checksum
## agents can be ran in parallel on different computers.
##
## Note that inbox of this agent is used solely by the internal
## slaves.  We create job packets as drops for the slaves, which
## then pass the drops to our inbox when they are done.  The
## main agent then updates the database according to the status.
## The program itself is used both as a slave and a master, but
## there are two separate agents.

BEGIN {
  use strict; use warnings;
  our $me = $0; $me =~ s|.*/||;
  our $home = $0; $home =~ s|/[^/]+$||; $home ||= "."; $home .= "/../../Toolkit/Common";
  unshift(@INC, $home);
}

######################################################################
$ENV{STAGE_HOST} ||= "stagecmsprod";	# Castor stage host
$ENV{STAGE_POOL} ||= "cms_prod2";	# Castor stage pool
my %args = (DBITYPE => "Oracle");
while (scalar @ARGV)
{
    if ($ARGV[0] eq '-stagehost' && scalar @ARGV > 1)
    { shift (@ARGV); $ENV{STAGE_HOST} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-stagepool' && scalar @ARGV > 1)
    { shift (@ARGV); $ENV{STAGE_POOL} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-wait' && scalar @ARGV > 1)
    { shift (@ARGV); $args{WAITTIME} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-state' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DROPDIR} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-db' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBNAME} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-dbi' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBITYPE} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-dbuser' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBUSER} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-dbpass' && scalar @ARGV > 1)
    { shift (@ARGV); $args{DBPASS} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-node' && scalar @ARGV > 1)
    { shift (@ARGV); $args{MYNODE} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-prefix' && scalar @ARGV > 1)
    { shift (@ARGV); $args{RM_PATH_PREFIX} = shift(@ARGV); }
    elsif ($ARGV[0] eq '-jobs' && scalar @ARGV > 1)
    { shift (@ARGV); $args{NJOBS} = shift(@ARGV); }
    else
    { last; }
}

if (scalar @ARGV || !$args{DROPDIR} || !$args{DBNAME} || !$args{DBUSER}
    || !$args{DBPASS} || !$args{DBITYPE} || !$args{MYNODE}
    || !$args{RM_PATH_PREFIX} || !$args{NJOBS})
{
    print STDERR
	"usage: $me -node TMDB-NODE -prefix PATH-PREFIX-TO-REMOVE\n",
	"    -db NAME -dbuser USER -dbpass PASSWORD [-dbitype TYPE]\n",
	"    -state IN-DROP-BOX [-jobs NUMBER] [-wait SECS-TO-WAIT]\n",
	"    [-stagehost STAGE-HOST] [-stagepool POOL]\n";
    exit (1);
}

my $agent = new FileCastorChecksum (%args);
# Recapture interrupt signal, oracle swallows it.
$SIG{INT} = sub { system "touch $agent->{STOPFLAG}"; $agent->maybeStop (); };
$agent->process ();

######################################################################
# Routines specific to the agent.
package FileCastorChecksum; use strict; use warnings; use base 'UtilsAgent';
use File::Path;
use Data::Dumper;
use UtilsCommand;
use UtilsLogging;
use UtilsTiming;
use UtilsCatalogue;
use UtilsDB;

sub new
{
    my $proto = shift;
    my $class = ref($proto) || $proto;
    my $self = $class->SUPER::new(@_);
    my %params = (DBITYPE => undef,		# Database driver binding
    		  DBNAME => undef,		# Database name
	  	  DBUSER => undef,		# Database user name
	  	  DBPASS => undef,		# Database user password
	  	  MYNODE => undef,		# My TMDB node name
	  	  RM_PATH_PREFIX => undef,	# Prefix to remove from PFNs
	  	  AGENTID => "Checksum");	# Identity for activity logs
    my %args = (@_);
    map { $self->{$_} = $args{$_} || $params{$_} } keys %params;
    bless $self, $class;
    return $self;
}

# Start processing a file
sub fileStart
{
    my ($self, $guid, $filesize, $assigned, $catalogue, $hostkey) = @_;

    # Get the PFN for the GUID.
    my $now = &mytimeofday();
    my $pfn = &guidToPFN ($guid, $catalogue, $hostkey);
    do { &alert ("failed to look up pfn for $guid"); return 0; } if ! $pfn;
    $pfn =~ s|$self->{RM_PATH_PREFIX}||;

    my $lfn = $pfn; $lfn =~ s|.*/||;
    my $dir = "$self->{WORKDIR}/$guid";
    do { &alert ("$dir: exists already"); return 0 } if -d $dir;
    eval { &mkpath ($dir); };
    do { &alert ("$dir: cannot create: $@"); return 0 } if $@;

    my $file = {
	GUID		=> $guid,
	PFN		=> $pfn,
	LFN		=> $lfn,
	WORKDIR		=> $dir,
	FILESIZE	=> $filesize,
	TIME_ASSIGNED	=> $assigned,
	TIME_STARTED	=> $now
    };

    $self->{PENDING}{$guid} = 1;
    $self->addJob (sub { $self->fileDownloaded ($file, @_) },
	{}, "rfcp", $pfn, "$file->{WORKDIR}/$lfn");
    return 1;
}

# Fetch the file from mass storage to a local directory.
sub fileDownloaded
{
    my ($self, $file, $job) = @_;
    $file->{FAILURE} = "exit code $job->{STATUS} from @{$job->{CMD}}" if $job->{STATUS};
    return $self->completeFile ($file) if $file->{FAILURE};

    $self->addJob (sub { $self->fileChecksummed ($file, @_) },
	{ OUTPUT_FILE => "$file->{WORKDIR}/checksum" },
	"sh", "-c", "cd $file->{WORKDIR} && cksum $file->{LFN} > checksum");
}

# Calculate file checksum and size.
sub fileChecksummed
{
    my ($self, $file, $job) = @_;
    my $output = &input ($job->{OUTPUT_FILE});
    unlink ($job->{OUTPUT_FILE});
    chomp ($output);

    if ($job->{STATUS}) {
	$file->{FAILURE} = "exit code $job->{STATUS} from @{$job->{CMD}}";
    } elsif (! $output) {
	$file->{FAILURE} = "no output from @{$job->{CMD}}";
    } elsif ($output !~ /^(\d+) (\d+) (\S+)$/) {
	$file->{FAILURE} = "bad output from @{$job->{CMD}}";
    } else {
	$file->{CHECKSUM} = $1;
	$file->{NEWSIZE} = $2;
    }
    $self->fileComplete ($file);
}

# Update checksum in the database if the operation was successful.
sub fileComplete
{
    my ($self, $file) = @_;

    # Dig out the report.  Note that the checksum agent never fails,
    # it marks files bad if something goes wrong with the checksum.
    my $guid = $file->{GUID};
    my $success = $file->{FAILURE} ? 1 : 0;
    my $checksum = $file->{CHECKSUM};
    my $oldsize = $file->{FILESIZE};
    my $newsize = $file->{NEWSIZE};
    my $mynode = $self->{MYNODE};
    my $now = time();
    my $dbh = undef;
    my $op;

    # Update the checksum.
    eval
    {
	# Check preceding failures
	$op = "calculate checksum"; die $file->{FAILURE} if $file->{FAILURE};

	# Nuke working directory
	$op = "remove working directory";
	&rmtree ($file->{WORKDIR});

	# Check file size matches
	$op = "match file size"; die "$oldsize != $newsize" if $oldsize != $newsize;

	# Ok, it's worth talking to database.  Get connected.
	$op = "connect to the database";
	$dbh = &connectToDatabase ($self, 0) or die "failed to connect";

	# Check for an existing checksum; if there is one, make sure
	# it's the same we got this time, and then ignore this drop.
	# If there's isn't one, add it.
	$op = "match old checksum";
	my ($oldsum) = &dbexec($dbh, qq{
		select value from t_replica_metadata
		where guid = :guid and attribute = 'checksum'},
		":guid" => $guid)->fetchrow_array();
	die "$oldsum != $checksum" if defined $oldsum && $oldsum ne $checksum;

        # OK, update the checksum and reset local file state.
	$op = "update checksum";
	&dbexec($dbh, qq{
	  insert into t_replica_metadata
	    values (:guid, 'checksum', :checksum)},
	  ":guid" => $guid, ":checksum" => $checksum);

    	$op = "update file state";
	&dbexec($dbh, qq{
	  update t_replica_state
	  set local_state = 1, local_time_stamp = :now
	  where guid = :guid and node = :node and local_state = 20},
  	  ":guid" => $guid, ":node" => $mynode, ":now" => $now); 

  	$op = "commit";
	$dbh->commit();
    };
    do { &alert ("failed to $op for $guid: $@"); $dbh->rollback() if $dbh } if $@;

    # Disconnect from database
    $dbh->disconnect();
    undef $dbh;

    # Log transfer delay stats
    $now = &mytimeofday ();
    &logmsg ("xstats: $guid $mynode $success "
	     . sprintf ('%.2f %.2f',
	    		$now - $file->{TIME_ASSIGNED},
	    		$now - $file->{TIME_STARTED})
	     . " $file->{FILESIZE}");

     # Mark this file no longer known to us
     delete $self->{PENDING}{$guid};

     # FIXME: Back off on this file for a while?
}

# Get N guids that should be checksummed.  Returns a list of arrays
# with members GUID, FILESIZE, TIMESTAMP, CATALOGUE, HOST_KEY.
sub nextFiles
{
    my ($self, $dbh, $n) = @_;
    my @result = ();
    eval
    {
	# Select files that need to be checksummed.  This is everything
	# in local state 20 we don't already know about.
	my ($stmt) = &dbexec ($dbh, qq{
		select rs.guid,
		       m.value,
		       rs.local_time_stamp,
		       n.catalogue_contact,
		       n.host_string
		from t_replica_state rs
		left join t_replica_metadata m
		  on m.guid = rs.guid and m.attribute = 'filesize'
		left join t_nodes n
		  on n.node_name = rs.node
		where rs.node = :node
	  	  and rs.local_state = 20},
		":node" => $self->{MYNODE});
	while (my $row = $stmt->fetchrow_arrayref())
	{
	    next if $self->{PENDING}{$row->[0]};
	    last if ! $n--;
	    push (@result, [ @$row ]);
	}
    };
    &alert ("failed to select next files: $@") if $@;
    return @result;
}

# Called by agent main routine before sleeping.  Pick up work
# assignments from the database here and pass them to slaves.
sub idle
{
    my ($self, @pending) = @_;
    my $dbh = undef;
    my $more = 0;

    # Pump more files keeping moderate-size queue in each worker.
    eval
    {
	$dbh = &connectToDatabase ($self) or die "failed to connect";
        # FIXME: Pick up and process messages to me

	my @files = ();
	my $maxload = $self->{NJOBS} * 10;
        while (scalar @{$self->{JOBS}} < $self->{NJOBS})
        {
	    # Get more files if necessary
	    @files = $self->nextFiles ($dbh, $maxload) if ! @files;
	    last if ! @files;

	    # Start processing this one if possible
	    last if ! ($more = $self->fileStart (@{shift @files}));

	    # Move existing jobs
	    $self->maybeStop();
	    $self->pumpJobs ();
        }
    };
    do { &alert("database error: $@"); $dbh->rollback() if $dbh } if $@;

    # Disconnect from the database
    $dbh->disconnect() if $dbh;
    undef $dbh;

    # Keep working, resting a bit at a time.  If we have work to do
    # and can start more jobs, break out of this loop and initiate
    # new transfers.  Otherwise if we have exhausted files that can
    # be processed, just sleep here for a moment.
    my $target = time() + $self->{WAITTIME};
    while (time() < $target)
    {
        $self->maybeStop ();
        $self->pumpJobs ();
        my $njobs = scalar @{$self->{JOBS}};
        last if $more && $njobs < $self->{NJOBS};
        select (undef, undef, undef, .1);
    }
}
